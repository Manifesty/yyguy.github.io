<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Kubernetes</title>
    <url>/2022/06/25/Kubernetes/</url>
    <content><![CDATA[<h1 id="Kubernetes"><a href="#Kubernetes" class="headerlink" title="Kubernetes"></a>Kubernetes</h1><p>高可用集群副本数据最好是 &gt;=3 基数个  方便选举</p>
<p>在K8S中，由Master控制节点和Worker节点共同构成一个集群。</p>
<blockquote>
<p><strong>Master节点</strong>：</p>
<p>API Server：所有服务访问的统一入口，以restful风格进行操作，同时交给etcd存储（是唯一能访问etcd的组件），提供认证、授权、访问控制、API注册与发现等机制，可通过kubectl命令行工具、dashboard可视化面板访问。<br>Controller Manager：维持副本期望数目；处理集群中常规后台任务，一个资源对应一个控制器，同时监控集群状态，确保实际状态和最终状态一致。<br>Scheduler：节点的调度，选择合适的节点进行分配任务<br>etcd：键值对数据库，储存K8S集群所有重要信息（持久化）</p>
<p><strong>Worker节点</strong></p>
<p>Kubelet：直接跟容器引擎交互实现容器的生命周期管理；相当于Master节点派到node节点的代表，管理本机容器，上报数据到API Server。<br>Kube-proxy：负责写入规则至 IPTABLES、IPVS 实现服务映射访问；实现服务（service）抽象组件，屏蔽PodIP变化和负载均衡。<br>Container Runtime：容器运行时。K8S支持多个容器运行环境：Docker、Containerd、CRI-O、Rktlet以及任何实现Kubernetes CRI（容器运行环境接口）的软件。</p>
</blockquote>
<p>CoreDNS：可以为集群中的SVC创建一个域名IP的对应关系解析<br>Dashboard：给K8S集群提供一个B/S结构访问体系<br>Ingress Controller：官方只能实现四层代理，INGRESS可以实现七层代理<br>Federation：提供一个可以跨集群中心多K8S统一管理功能<br>Promethues：提供K8S集群的监控能力<br>ELK：提供K8S集群日志统一分析介入平台</p>
<p><strong>流程样例</strong></p>
<ol>
<li>通过kubectl命令行工具向API Server发送一个请求：创建ReplicaSet（用来确保容器应用的副本数始终保持在用户定义的副本数，支持集合式的selector；虽然ReplicaSet可独立使用，但还是建议使用Deployment来自动管理ReplicaSet，这样无需担心与其他机制不兼容问题，例如ReplicaSet不支持rolling-update但Deployment支持），API Server会将此请求存储在etcd中</li>
<li>Controller Manager会接收到一个通知</li>
<li>Controller Manager发现现在的集群状态和预期状态不一致，因此需要创建Pod，此信息会通知到Scheduler</li>
<li>Scheduler会选择空闲的Worker节点，然后通过API Server更新Pod定义</li>
<li>API Server会通知到Worker节点上的kubelet</li>
<li>kubelet指示当前节点上的Container Runtime运行对应的容器</li>
<li>Container Runtime下载镜像并启动容器</li>
</ol>
<h3 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h3><p><strong>Pod</strong></p>
<ul>
<li>Pod是最小调度单元</li>
<li>Pod里面会包含一个或多个容器（Container）</li>
<li>Pod内的容器共享存储及网络，可通过localhost通信</li>
</ul>
<p><strong>Deployment</strong></p>
<p>Deployment是在Pod这个抽象上更为上层的一个抽象，它可以定义一组Pod的副本数目以及这个Pod的版本。一般大家用Deployment这个抽象来做应用的真正的管理，而Pod是组成Deployment最小的单元</p>
<ul>
<li>定义一组Pod的副本数量、版本等</li>
<li>通过控制器维护Pod数目</li>
<li>自动恢复失败的Pod</li>
<li>通过控制器以指定的策略控制版本</li>
</ul>
<p><strong>Service</strong></p>
<p>Pod是不稳定的，IP是会变化的，所以需要一层抽象来屏蔽这种变化，这层抽象叫做Service</p>
<ul>
<li>提供访问一个或者多个Pod实例稳定的访问地址</li>
<li>支持多种访问方式<ul>
<li>ClusterIP（对集群内部访问）</li>
<li>NodePort（对集群外部访问）</li>
<li>LoadBalancer（集群外部负载均衡）</li>
</ul>
</li>
</ul>
<p><strong>Volume</strong></p>
<p>Volume就是存储卷，在Pod中可以声明卷来访问文件系统，同时Volume也是一个抽象层，其具体的后端存储可以是本地存储、NFS网络存储、云存储、分布式存储</p>
<ul>
<li>声明在Pod中容器可以访问的文件系统</li>
<li>可以被挂载在Pod中一个或多个容器的指定路径下</li>
<li>支持多种后端储存</li>
</ul>
<p><strong>Namespace</strong></p>
<p>Namespace（命名空间）是用来做资源的逻辑隔离的，比如上面的Pod、Deployment、Service都属于资源，不同Namespace下资源可以重名。同一Namespace下资源名需唯一</p>
<ul>
<li>一个集群内部的逻辑隔离机制</li>
<li>每个资源都属于一个NameSpace</li>
<li>同一个Namespace中资源命名唯一</li>
<li>不同Namespace中资源可重名</li>
</ul>
<p><strong>kubectl命令行工具</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl api-resources 显示K8S支持的资源类型</span></span><br><span class="line">NAME                   SHORTNAMES</span><br><span class="line">namespace               ns</span><br><span class="line">nodes                   no</span><br><span class="line">persistentvolumeclaims  pvc</span><br><span class="line">persistentvolumes       pv</span><br><span class="line">pods                    po</span><br><span class="line">statefulsets            sts</span><br><span class="line">services                svc</span><br><span class="line">deployments             deploy</span><br><span class="line"><span class="meta">#</span><span class="bash"> kubectl get pods  等价于   kubectl get po</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl create deployment web --image=nginx:1.14</span></span><br><span class="line">这句话表示创建一个deployment资源，取名叫web，指定镜像为nginx的1.14版本。一般不这么部署应用，不好复用，一般通过yaml文件来部署，如下</span><br><span class="line"><span class="meta">#</span><span class="bash"> kubectl create deployment web --image=nginx:1.14 --dry-run -o yaml &gt; web.yaml</span></span><br><span class="line">  --dry-run 表示试运行</span><br><span class="line">  -o yaml 表示以yaml格式输出</span><br><span class="line"><span class="meta">  &gt;</span><span class="bash"> web.yaml 表示将输出的内容重定向到web.yaml文件中</span></span><br><span class="line">用下面命令应用web.yaml，web.yaml声明了一个deployment和一个pod</span><br><span class="line"><span class="meta">#</span><span class="bash"> kubectl apply -f web.yaml   默认replicas=1</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kubectl get deploy,po -o wide  查看Deployment和Pod</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kubectl scale deploy web --replicas=10   扩容</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kubectl scale deploy web --replicas=1    缩容</span></span><br></pre></td></tr></table></figure>

<p><strong>节点污点</strong></p>
<p>Taint污点：节点不做普通分配调度，是节点属性，属性值有三个</p>
<ul>
<li>NoSchedule：一定不被调度</li>
<li>PreferNoSchedule：尽量不被调度（有被调度的几率）</li>
<li>NoExecute：不会调度，并且还会驱逐Node已有Pod</li>
</ul>
<p>也就是说，给节点打上污点，那么调度的时候就会根据上面的属性来调度，一般来说Master节点的污点值是NoSchedule</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl describe node my-master | grep Taints  查看my-master污点值</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kubectl taint node my-master node-role.kubernetes.io/master:NoSchedule-  去掉my-master节点的NoSchedule污点</span></span><br></pre></td></tr></table></figure>

<p><strong>Pod调度策略</strong></p>
<p>Pod调度策略会影响到Pod最终被调度到哪个节点上，Pod调度策略有三类</p>
<ul>
<li>Pod声明的<em>requests</em>和<em>limits</em>，前者就是Pod需要多少资源，后者表示Pod最多用多少资源（CPU内存等）</li>
<li>节点标签选择器，会选择符合标签的节点进行调度</li>
<li>节点亲和性，分为硬亲和和软亲和，前者必须满足，后者尝试满足，不强制</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl delete deploy web  删除之前部署的deploy</span></span><br></pre></td></tr></table></figure>

<p>web.yaml新增resources声明</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">     <span class="attr">app:</span> <span class="string">web</span></span><br><span class="line">   <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">	<span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">	<span class="attr">selector:</span></span><br><span class="line">		<span class="attr">matchLabels:</span></span><br><span class="line">			<span class="attr">app:</span> <span class="string">web</span></span><br><span class="line">	<span class="attr">strategy:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">	<span class="attr">template:</span></span><br><span class="line">		<span class="attr">metadata:</span></span><br><span class="line">			<span class="attr">labels:</span></span><br><span class="line">				<span class="attr">app:</span> <span class="string">web</span></span><br><span class="line">		<span class="attr">spec:</span></span><br><span class="line">			<span class="attr">containers:</span></span><br><span class="line">			<span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.14</span></span><br><span class="line">			<span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">			<span class="comment"># 方式一：secret挂载到容器</span></span><br><span class="line">			<span class="attr">volumeMounts:</span></span><br><span class="line">				<span class="bullet">-</span> <span class="attr">name:</span> <span class="string">secret-volume</span></span><br><span class="line">				 <span class="attr">mountPath:</span> <span class="string">/etc/secret-volume</span></span><br><span class="line">			<span class="attr">volumes:</span></span><br><span class="line">			<span class="bullet">-</span> <span class="attr">name:</span> <span class="string">secret-volume</span></span><br><span class="line">			  <span class="attr">secret:</span></span><br><span class="line">			  	<span class="attr">secretName:</span> <span class="string">test-secret</span></span><br><span class="line">			<span class="comment"># 方式二：环境变量声明secret</span></span><br><span class="line">			<span class="attr">env:</span></span><br><span class="line">			<span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SECRET_USERNAME</span></span><br><span class="line">				<span class="attr">valueFrom:</span></span><br><span class="line">					<span class="attr">secretKeyRef:</span></span><br><span class="line">						<span class="attr">name:</span> <span class="string">test-secret</span></span><br><span class="line">						<span class="attr">key:</span> <span class="string">username</span></span><br><span class="line">			<span class="comment">#requests和limits</span></span><br><span class="line">			<span class="attr">resources:</span></span><br><span class="line">				<span class="attr">requests:</span></span><br><span class="line">					<span class="attr">memory:</span> <span class="string">"3Gi"</span></span><br><span class="line">				<span class="attr">limits:</span></span><br><span class="line">					<span class="attr">memory:</span> <span class="string">"4Gi"</span></span><br><span class="line">			<span class="comment"># nodeSelector</span></span><br><span class="line">			<span class="attr">nodeSelector:</span></span><br><span class="line">				<span class="attr">test123_env:</span> <span class="string">prod</span></span><br><span class="line">			<span class="comment"># 节点亲和性</span></span><br><span class="line">			<span class="attr">affinity:</span></span><br><span class="line">				<span class="attr">nodeAffinity:</span></span><br><span class="line">					<span class="attr">requiredDuringSchedulingIgnoredDuringException:</span></span><br><span class="line">						<span class="attr">nodeSelectorTerms:</span></span><br><span class="line">							<span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">							<span class="bullet">-</span> <span class="attr">key:</span> <span class="string">test123_env</span></span><br><span class="line">							<span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">							<span class="attr">values:</span></span><br><span class="line">							<span class="bullet">-</span> <span class="string">dev</span></span><br><span class="line">							<span class="bullet">-</span> <span class="string">test</span></span><br><span class="line">					<span class="attr">preferreDuringSchedulingIgnoredDuringException:</span></span><br><span class="line">					<span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">					<span class="attr">preference:</span></span><br><span class="line">					<span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">						<span class="bullet">-</span> <span class="attr">key:</span> <span class="string">group</span></span><br><span class="line">						<span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">						<span class="attr">values:</span></span><br><span class="line">						<span class="bullet">-</span> <span class="string">ttttest</span></span><br><span class="line"><span class="attr">status:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl apply -f web.yaml  这里虚拟机内存如果就2G，Pod会在挂起状态，因为资源不满足</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除deploy并给master节点打上标签test123_env=prod，标签就是键值对，随便起名</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kubectl delete deploy web </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kubectl label node my-master test123_env=prod</span></span><br><span class="line">最后执行理论上所有Pod都应该被调度到master节点，但是发现所有Pod都被挂起了，因为master节点默认污点值是NoSchedule：节点污点值的优先级是高于节点标签的！</span><br><span class="line"><span class="meta">#</span><span class="bash"> requiredDuringSchedulingIgnoredDuringException: 硬亲和，test123_env等于dev或者<span class="built_in">test</span>，必须满足</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> preferreDuringSchedulingIgnoredDuringException: 软亲和，group等于ttttest，非必须满足</span></span><br></pre></td></tr></table></figure>

<h3 id="Secret和配置管理"><a href="#Secret和配置管理" class="headerlink" title="Secret和配置管理"></a>Secret和配置管理</h3><p><strong>Secret</strong></p>
<p>Secret在K8S中表示一个存储在etcd中的配置，这个配置是秘密、安全的，通常用Base64编码，此配置可通过挂载卷或者环境变量的方式供Pod访问。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 首先将明文转成base64编码</span></span><br><span class="line">echo -n 'root' | base64    结果是cm9vdA==</span><br><span class="line">echo -n '123456' | base64   结果是MTIzNDU2</span><br><span class="line">通过下面secret.yaml声明创建一个Secret</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">	name: test-secret</span><br><span class="line">data:</span><br><span class="line">	username: cm9vdA==</span><br><span class="line">	password: MTIzNDU2</span><br></pre></td></tr></table></figure>

<p>既然是Base64的编码方式（不是加密方式），为什么说Secret是安全的呢？此处的安全是K8S提供的，主要是以下几点：</p>
<ul>
<li>传输安全（K8S中与API Server的交互都是HTTPS的）</li>
<li>存储安全（Secret被挂载到容器时存储在tmpfs中，只存在于内存中而不是磁盘中，Pod销毁Secret随之消失）</li>
<li>访问安全（Pod间的Secret是隔离的，一个Pod不能访问另一个Pod的Secret）</li>
</ul>
<h3 id="ConfigMap"><a href="#ConfigMap" class="headerlink" title="ConfigMap"></a>ConfigMap</h3><p>ConfigMap可以看做是不需要加密，不需要安全属性的Secret，也是和配置相关的，创建ConfigMap的过程如下，首先创建一个配置文件例如redis.properties，包含以下内容</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis.port</span>=<span class="string">127.0.0.1</span></span><br><span class="line"><span class="meta">redis.port</span>=<span class="string">6379</span></span><br><span class="line"><span class="meta">redis.password</span>=<span class="string">123456</span></span><br></pre></td></tr></table></figure>

<p>以下命令从文件redis.properties创建了一个名为redis-config的ConfigMap</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl create configmap redis-config --from-file=redis.properties</span><br></pre></td></tr></table></figure>

<h3 id="存储编排"><a href="#存储编排" class="headerlink" title="存储编排"></a>存储编排</h3><p>PV： PersistentVolume，持久化卷<br>PVC：PersistentVolumeClaim，持久化卷声明</p>
<p>PV说白了就是一层存储的抽象，底层的存储可以是本地磁盘，也可以是网络磁盘比如NFS、Ceph之类。<br>PVC其实在Pod和PV之前又增加了一层抽象，这样做的目的在于将Pod的存储行为与具体的存储设备解耦，试想一下如果哪天NFS网络存储的IP地址变化了，若没有PVC就需要每个Pod改一下IP的声明。</p>
<p><strong>本地存储</strong></p>
<p>本地存储即对应K8S中的hostPath</p>
]]></content>
  </entry>
  <entry>
    <title>Spring</title>
    <url>/2022/06/25/Spring/</url>
    <content><![CDATA[<h2 id="Spring中bean的生命周期"><a href="#Spring中bean的生命周期" class="headerlink" title="Spring中bean的生命周期"></a>Spring中bean的生命周期</h2><ol>
<li>解析类得到BeanDefinition</li>
<li>如果有多个构造方法，推断构造方法，进而实例化对象</li>
<li>对对象中加了@Autowired注解的属性进行填充</li>
<li>回调Aware方法，例如BeanNameAware（可在运行时获取beanName），BeanFactoryAware（可在运行时获取BeanFactory实例）</li>
<li>调用BeanPostProcessor的初始化前方法</li>
<li>调用初始化方法</li>
<li>调用BeanPostProcessor初始化后的方法，这里会进行AOP</li>
<li>如果当前创建的bean是单例的则会吧bean放入单例池</li>
<li>使用bean</li>
<li>Spring容器关闭时调用DispossableBean中的destory方法</li>
</ol>
<h2 id="Spring循环依赖"><a href="#Spring循环依赖" class="headerlink" title="Spring循环依赖"></a>Spring循环依赖</h2><p>循环依赖在Spring容器中注入依赖的对象，有两种情况：</p>
<p>​    1、构造器方式注入依赖 （无法解决  例如new ServiceA(new ServiceB(new ServiceA(new …)))）</p>
<p>​    2、以set方式注入依赖 ( <font color="red"> spring内部通过3级缓存来解决循环依赖</font>)</p>
<p><font color="red">默认的单例（singleton）的场景是支持循环依赖的，不报错；原型（Prototype）的场景是不支持循环依赖的，会报错</font></p>
<h5 id="三级缓存"><a href="#三级缓存" class="headerlink" title="三级缓存"></a>三级缓存</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DefaultSingletonBeanRegistry</span> <span class="keyword">extends</span> <span class="title">SimpleAliasRegistry</span> <span class="keyword">implements</span> <span class="title">SingletonBeanRegistry</span></span>&#123;</span><br><span class="line">    <span class="comment">//一级缓存</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String,Object&gt; singletonObjects = <span class="keyword">new</span> ConcurrentHashMap&lt;&gt;(<span class="number">256</span>);</span><br><span class="line">    <span class="comment">//二级缓存</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String,Object&gt; earlySingletonObjects = <span class="keyword">new</span> HashMap&lt;&gt;(<span class="number">16</span>);</span><br><span class="line">    <span class="comment">//三级缓存</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String,ObjectFactory&lt;?&gt;&gt; singletonFactories = <span class="keyword">new</span> HashMap&lt;&gt;(<span class="number">16</span>);</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>实例化：内存中申请一块内存空间</p>
<p>初始化：完成属性的各种赋值</p>
<p>一级缓存singletonObjects：存放的是已经初始化好的bean</p>
<p>二级缓存earlySingletonObjects：存放早期暴露出来的bean对象，已实例化未初始化的bean</p>
<p>三级缓存Map&lt;String,ObjectFactory&lt;&gt;?&gt; singletonFactories，存放可以生成bean的工厂，存放的是FactoryBean，假如A类实现了FactoryBean，那么依赖注入的时候不是A类，而是A类产生的Bean，若要取A类的实例,getBean(“&amp;A的bean id”)</p>
<blockquote>
<p>FactoryBean和BeanFactory区别</p>
<p>BeanFactory是个spring容器中一个顶级接口 ，是IOC容器或者对象工厂，在spring中所有bean都是由BeanFactory管理的，spring容器给了很多实现ClasspathXmlApplicationContext等</p>
<p>FactoryBean是个接口  是一种工厂bean，可以产生bean的bean</p>
</blockquote>
<h4 id="A-B对象在三级缓存中的迁移说明"><a href="#A-B对象在三级缓存中的迁移说明" class="headerlink" title="A/B对象在三级缓存中的迁移说明"></a>A/B对象在三级缓存中的迁移说明</h4><ol>
<li>A创建过程中需要B，于是A将自己放到三级缓存中，去实例化B</li>
<li>B实例化的时候发现需要A，于是B先查一级缓存，没有再查二级缓存，还是没有再查三级缓存，找到A然后把三级缓存中的A放到二级缓存，并删除三级缓存中的A</li>
<li>B顺利初始化完毕，将自己放到一级缓存中（此时B里面的A依然是创建中的状态），然后接着回来创建A，此时B已经创建结束，直接从一级缓存里拿到B，然后完成创建，并将A自己放到一级缓存中。</li>
</ol>
<h3 id="为什么要三级缓存？"><a href="#为什么要三级缓存？" class="headerlink" title="为什么要三级缓存？"></a>为什么要三级缓存？</h3><p>一级、二级缓存用于IOC，三级缓存用于AOP</p>
<h5 id="一级缓存singletonObjects"><a href="#一级缓存singletonObjects" class="headerlink" title="一级缓存singletonObjects"></a>一级缓存singletonObjects</h5><p>实际上，一级缓存已经可以解决循环依赖问题，bean被实例化后即使没有初始化也不影响对象间引用持有；一级缓存关键点在于bean实例化与初始化的分离。</p>
<h5 id="三级缓存-singletonFactories"><a href="#三级缓存-singletonFactories" class="headerlink" title="三级缓存 singletonFactories"></a>三级缓存 singletonFactories</h5><p>仅使用一级缓存根本问题就是我们拿到的是bean的原始引用，如果需要的是bean的代理对象怎么办，spring中充斥着大量动态代理模式的架构，所以，spring在bean实例化后，将原始bean放入三级缓存中，三级缓存中实际存入的是ObjectFactory接口签名的回调实现，如果有动态代理需求，里面可以埋点进行处理，将原始bean包装后返回。通过三级缓存我们可以拿到可能经过包装的对象，解决对象代理封装的问题。</p>
<h5 id="二级缓存earlySingletonObjects"><a href="#二级缓存earlySingletonObjects" class="headerlink" title="二级缓存earlySingletonObjects"></a>二级缓存earlySingletonObjects</h5><p>从软件设计角度考虑，三个缓存代表三种不同职责，根据单一职责原理，从设计角度就需要分离三种职责的缓存。</p>
<p>一级缓存是完整的bean，可以被外界任意使用，不会有歧义。</p>
<p>二级缓存是不完整的bean，没有完成初始化，它与一级缓存的分离主要是职责的分离及边界的划分，可以试想一个Map缓存中既有完整可用的bean，也有不完整的只能持有引用的bean，在复杂度很高的架构中，很容易出现歧义，并带来一些不可预知的错误。</p>
<p>三级缓存其职责就是包装一个bean，有回调逻辑，所以它的作用非常清晰，并且只能处于第三层。</p>
<p>整个使用过程中，要获取一个bean，从一级缓存一直查找到三级缓存，缓存bean的时候是从三级缓存到一级缓存顺序保存，且在缓存过程中，三个缓存是互斥的，只会保持bean在一个缓存中，而且最终都会在一级缓存中。</p>
<h1 id="Spring-AOP"><a href="#Spring-AOP" class="headerlink" title="Spring AOP"></a>Spring AOP</h1><p>createBean()中的resolveBeforeInstantiation()方法在bean还没实例化前执行，提供bean后置处理器一个返回代理的机会，判断是否需要创建代理，不需要就直接创建bean，否则创建的是代理对象</p>
<p>resolveBeforeInstantiation(beanName,bdbToUse)方法里调用InstantiationAwareBeanPostProcessor这个bean的后置处理器方法，从类名字上看是拦截bean实例化阶段，通过调用postProcessBeforeInstantiation方法生成对象。</p>
<p>我们先来看一般怎么使用Spring AOP的：写一个@Aspect注解的切面类并使用@EnableAspectJAutoProxy注解启用代理，点进去发现它导入了一个AspectJAutoProxyRegistrar到Spring容器中，该类是一个ImportBeanDefinitionRegistrar类，会在解析配置类的时候调用registerBeanDefinitions方法，该方法会向容器中注入一个AnnotationAwareAspectJAutoProxyCreator类的bean定义，AnnotationAwareAspectJAutoProxyCreator是一个InstantiationAwareBeanPostProcessor。</p>
<p>这里就跟上面吻合了，实例化bean时先执行InstantiationAwareBeanPostProcessor，若有返回对象则使用该对象，否则才会去创建实例。所以@EnableAspectJAutoProxy注解的作用就是向容器中添加一个InstantiationAwareBeanPostProcessor类，拦截bean的创建并生成代理对象。postProcessBeforeInstantiation中的createProxy方法点进去可以发现动态代理创建有两种方式，如果该类是接口，则使用jdk动态代理，否则使用cglib动态代理。</p>
<h5 id="为什么JDK动态代理只能代理接口？"><a href="#为什么JDK动态代理只能代理接口？" class="headerlink" title="为什么JDK动态代理只能代理接口？"></a>为什么JDK动态代理只能代理接口？</h5><p>JDK动态代理在创建代理对象时，默认让代理对象继承了Proxy类，java不支持多继承，所以JDK只能通过接口实现动态代理。cglib实现动态代理的逻辑是用子类继承被代理类，没有单继承的限制了。</p>
]]></content>
  </entry>
  <entry>
    <title>一些问题</title>
    <url>/2022/06/25/%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>同步和异步、阻塞和非阻塞<br>    同步和异步关注的是消息通信机制，<br>    所谓同步，就是在发出调用时没得到结果前该调用就不返回，一旦调用返回就得到返回值<br>    异步：调用发出后就直接返回，没有返回结果；一个异步调用发出后，调用者不会立刻得到结果，被调用者通过状态、通知来通知调用者或者通过回调函数处理这个调用</p>
<pre><code>阻塞和非阻塞关注的是程序在等待调用结果时的状态
阻塞调用是指调用结果返回之前，当前线程会被挂起，调用线程只有在得到结果之后才会返回
非阻塞调用是指在不能立刻得到结果之前，该调用不会阻塞当前线程
这里阻塞非阻塞和是否同步异步无关</code></pre><p>​<br>NIO由原来的阻塞读写变成了单线程轮询事件，找到可读写的网络描述符进行读写，除了事件轮询是阻塞的，剩余都是纯cpu操作，没必要开启多线程，解决了线程切换问题<br>​    事件分发器，单线程选择就绪事件<br>​    IO处理器，conect\read\write等纯CPU操作，一般开启cpu核心个线程数<br>​    业务线程<br>​    </p>
<p>反射：通过类限定名获取到字节码，将字节码中方法、变量、构造函数映射为对应的Method\Filed\Constructor等类<br>    getMethods获取public的方法（包括父类）<br>    getDeclaredMethods获取当前类声明的所有方法<br>    getDeclaredMethods从缓存或JVM中获取该class声明的方法列表，searchMethods方法从返回的方法列表找到一个匹配名称和参数的方法对象，找到就copy一份返回，每次调用getDeclaredMethods返回的都是新对象；先从reflectionDate中获取declaredMethods，为空就到JVM获取并赋值给reflectionDate</p>
<pre><code>Class.forName 会初始化static块
ClassLoader.loadClass不会执行静态块

JDK动态代理Porxy  InvocationHandler  接口、实现类、代理类    代理类中有实现类的引用 </code></pre><p>cglib动态代理基于asm框架 无反射机制 不需要接口  空间换时间</p>
<p>常见线程池参数：<br>    corePoolSize：核心线程数         corePoolSize = tasks/taskTime<br>    queueCapacity:任务队列容量         queueCapacity = corePoolSize/taskTime  *  respTime<br>    maxPoolSize：最大线程数<br>    keepAliveTIme：线程空闲时间<br>    allowCoreThreadTimeout:是否允许核心线程空闲退出  默认false</p>
<p>常见tomcat参数：<br>内存：<br>    -server  :服务器模式<br>    -Xms    ：java虚拟机初始化最小内存<br>    -Xmx    ：java虚拟机可用最大内存<br>    -Xss    ：每个java线程堆栈大小<br>    -XX:NewSize    :堆区域新生代内存默认大小<br>    -XX:MaxNewSize    :堆区域新生代内存最大可分配大小<br>    -XX:PermSize    :内存永久保留区域<br>    -XX:MaxPermSize    :内存最大永久保留区域<br>    -XX:+UseParNewGC    :对新生代采用多线程并行回收<br>    -XX:BiasedLocking    ：优化线程</p>
<p>并发：<br>    minSpareThreads:初始化时创建的socket连接数<br>    maxSpareThreads:最大空闲socket连接数<br>    maxThreads：客户请求最大线程数<br>    acceptAccount：监听端口队列最大数<br>    enableLookups：是否反查域名  设为false<br>    disableUploadTimeout：是否使用上传超时机制<br>    connectionUploadTimeout：上传超时时间<br>    keepAliveTimeout: 长连接最大保持时间<br>    URIEncoding：指定tomcat容器URL编码格式<br>    connectionTimeout：网络连接超时</p>
<p>工厂模式、策略模式、代理模式、单例模式、装饰类模式</p>
<p>代理：<br>    代理类和目标类实现同一接口，代理类持有目标类引用<br>策略：<br>    配置类配置多种策略类，策略类实现同一接口，context环境类取策略类处理<br>装饰类：<br>    装饰类持有目标类引用，目标类作为参数传入装饰类得到增强<br>单例：<br>    实例化bean后，只暴露一个获取bean的方法<br>工厂：<br>    大量产品需要创建且具有共同接口时使用，一般使用静态工厂</p>
<p>Spring的IOC、AOP<br>IOC：控制反转，将创建对象的控制权交给IOC容器，由主动创建变为被动接收；<br>DI：依赖注入，外部容器动态将依赖对象注入到组件中<br>    注入方式：构造、set、接口注入</p>
<p>bean实例化的几种方式：有参构造、无参构造、静态工厂、实例工厂<br>bean的生命周期：spring容器创建对象、执行init方法、调用自己方法、spring容器关闭时执行destory方法<br>spring加载流程：listener加载配置文件，读取信息到context，context按需动态创建、注入bean,</p>
<p>Spring事务传播机制：<br>    required（默认）：当前无事务就新建一个事务，有就加入那个事务<br>    supports：支持当前事务，若当前无事务就以非事务运行<br>    mandatory：使用当前事务，没有事务抛出异常<br>    requires_new：新建事务，若当前存在事务，把当前事务挂起<br>    not_supported：以非事务运行，存在事务则把当前事务挂起<br>    never：以非事务运行，存在事务则抛异常<br>    nested：存在事务就嵌套在事务内运行，没有则跟required一样</p>
<p>实验：ServiceA中调用serviceB中的方法，在不同传播机制下的表现（以下异常都为插入后进行by/zero运算）<br>                    ServiceA                    ServiceB                            场景<br>Transaction            required                    required                            A、B共用一个事务，有一个异常全部回滚<br>                    required                    requires_new                        B异常AB都回滚，A异常A回滚B提交<br>                    required                    supports                            AB异常都全部回滚<br>                    required                    mandatory                            AB异常都全部回滚<br>                    required                    not_supported                        AB异常都会导致A回滚、B提交<br>                    required                    never                                运行时会抛出存在事务异常<br>                    required                    nested                                AB异常都全部回滚</p>
<pre><code>never/not_supported            required/requires_new/nested        A异常AB都提交，B异常A提交B回滚</code></pre><p>nested和required的区别：required是合并为一个事务，B抛异常就算被A捕获也都会回滚；nested嵌套事务，B异常被A捕获A可以插入B回滚    </p>
<p>spring的事务超时=事务开始时到最后一个statement创建时间 + 最后一个statement执行超时时间<br>isolation事务隔离级别<br>数据库事务隔离级别：Oracle只支持已提交读和串行化，MySQL支持四种：未提交读，已提交读，可重复读，串行化。<br>若spring+oracle，配置隔离级别为Read UnCommited/Repeatable，不起效果。</p>
<p>系统之间交互时事务超时问题：可以不使用事务包裹交互时的操作，将交互前后的数据库操作拆成两个事务<br>并发时事务问题：使用Synchronized修饰的方法也被@Transactional修饰时，可能出现代码执行完了锁被释放但事务正要提交时其他线程进入读取到数据库的数据然后操作，<br>但是之后前一个线程操作提交了，当前线程的操作都是基于旧数据会有问题。</p>
<p>SpringMVC工作流程：<br>    1、用户发送请求到前端控制器DispatcherServlet<br>    2、DispatcherServlet收到请求调用HandlerMapping处理器映射器<br>    3、处理器映射器找到具体处理器（根据xml配置、注解等方式），生成处理器对象及处理器拦截器（如果有则生成）返回给DispatcherServlet<br>    4、DispatcherServlet调用HandlerAdapter处理器适配器<br>    5、HandlerAdapter经过适配调用具体处理器（Controller）<br>    6、Controller执行完返回ModelAndView<br>    7、HandlerAdapter将Controller执行结果ModelAndView返回给DispatcherServlet<br>    8、DispatcherServlet将ModelAndView传给ViewResolver视图解析器<br>    9、ViewResolver解析后返回具体view<br>    10、DispatcherServlet根据view进行渲染视图（将模型数据填充至视图）<br>    11、DispatcherServlet响应用户</p>
<p>Java8新特性<br>    1、Lambda表达式，增加函数式接口概念（），在可以使用Lambda表达式的地方，方法声明时必须包含一个函数式接口，任何函数式接口都可被Lambda表达式替换。如Comparator<br>    2、新的日期API，原API非线程安全、时区处理麻烦；新的java.time包涵盖了所有处理日期的操作<br>    3、optional，不用显式进行空值检测<br>    4、构造器和方法引用<br>    5、接口新增默认方法<br>    6、Stream流式操作</p>
<p>​    </p>
]]></content>
  </entry>
  <entry>
    <title>Zookeeper</title>
    <url>/2022/06/25/Zookeeper/</url>
    <content><![CDATA[<p>Zookeeper=文件系统+监听通知机制</p>
<p>文件系统： 节点可以存储数据  1M<br>监听通知机制： 客户端注册监听节点，节点发生变化（节点数据改变、被删除、子目录节点增加和删除）时，Zookeeper会通知客户端</p>
<p>zookeeper四种数据节点</p>
<p>persistent–持久化节点<br>  客户端与zookeeper断开连接后 该节点依然存在<br>persitent_sequential 持久有序节点<br>  客户端与zookeeper断开连接后，该节点依旧存在，只是zookeeper给该节点名称进行顺序编号<br>ephemeral–临时节点<br>  客户端与zookeeper断开连接后 该节点被删除<br>ephemeral_sequential 临时有序节点<br>  客户端与zookeeper断开连接后 该节点被删除 只是zookeeper给该节点名称进行顺序编号</p>
<p>利用临时节点即可实现分布式锁   独占锁<br>开始–&gt;创建临时节点/lock –&gt; 创建失败则监听/lock节点并等待;创建成功则获取锁，执行完逻辑然后删除/lock，释放锁，此事件就会被监听到并再次尝试创建临时节点;<br>上面的操作删除节点的同时会通知所有客户端<br>可使用临时有序节点优化：   时序锁<br>开始–&gt;在/locks下创建临时有序节点–&gt;获取/locks下所有子节点–&gt;将子节点按序由小到大排序–&gt;当前节点序号是否最小？<br>不是则阻塞，监听比自己序号小1的节点的删除事件;是则获取锁，执行完逻辑后删除节点释放锁，此事件就会被监听到并重复“获取/locks下所有子节点。。。”等系列操作；</p>
<p>zookeeper作为分布式锁的优缺点：<br>  优点：不依靠超时时间释放锁，可靠性高<br>  缺点：性能略低  因为要频繁创建删除节点</p>
<h5 id="Zookeeper选举投票机制"><a href="#Zookeeper选举投票机制" class="headerlink" title="Zookeeper选举投票机制"></a>Zookeeper选举投票机制</h5><ol>
<li>只有启动了的zk节点才能参与投票</li>
<li>每个zk服务启动时，接受一轮对自己的投票</li>
<li>leader角色决策条件，当启动后，如果自身接受投票数超过zk集群节点个数的一半，立刻变为leader</li>
<li>投票操作需要竞争，myid编号-权重</li>
</ol>
<p>流程：</p>
<ol>
<li>启动zk21：接受投票，集群中只有zk21，有1票投给自己</li>
<li>启动zk22：接受投票，自己投给自己，zk21投给自己，通过myid竞争得1票，共2票</li>
<li>启动zk23：自己投自己，通过myid竞争 zk21，zk22投给zk23，共3票，票数过半晋升为leader</li>
<li>启动zk24：已存在leader 只能为follower</li>
<li>启动zk25：已存在leader 只能为follower</li>
</ol>
<p>决定最终leader因素： myid权重 + 启动顺序</p>
<p>重新选举：先比较zxid（事务ID）再比较myid，票数过半及晋升为leader</p>
]]></content>
  </entry>
  <entry>
    <title>xxl-job</title>
    <url>/2022/06/25/xxl-job/</url>
    <content><![CDATA[<p>原生定时任务框架先天缺陷：<br> 1、不支持分片任务：处理有序数据时，多机器分片执行任务处理不同数据<br> 2、不支持生命周期统一管理：不重启服务情况下关闭、启动任务<br> 3、不支持集群：存在任务重复执行问题<br> 4、不支持失败重试：出现异常后任务终结、不能根据任务状态控制任务重新执行<br> 5、不支持动态调整：不重启服务的情况下修改任务参数<br> 6、无报警机制：任务失败后没有报警机制<br> 7、任务数据统计难以统计：任务数据量大时，对于任务执行情况无法高效的统计执行情况</p>
<p>xxl-job<br>   调度器、触发器、通讯<br>   执行器、通讯</p>
<p>运行模式一般选bean模式  其他GLUE是直接使用当前调度器作为执行器解析输入的源代码去执行</p>
<p>分片任务：<br>   路由策略选分片广播，输入参数，代码获取参数识别自己要从哪执行</p>
<p>执行器自动注册会有心跳保活，手动录入不会有心跳保活了；手动录入要慎重选择路由策略，例如路由策略为 第一个 时，手动录入的第一台机器挂了任务会执行失败</p>
<p>appName相同为同一个执行器组</p>
<p>为避免多个服务器同时调度任务，通过mysql悲观锁实现分布式锁（for update语句）<br>admin启动：<br>    查询自动注册的执行器，移除90s内没注册的，每30s检查一次<br>    失败任务监测，根据对应设置进行告警、重试操作</p>
<p>XxljobDynamicScheduler初始化时：<br>  JobRegistryMonitor.getInstance.start();//调度中心注册守护线程  维持和执行器间的心跳<br>  JobFaileMonitorHelper.getInstance.start();//任务失败处理的守护线程<br>  NetComServerFactory.putService(Admin.class,XxljobDynamicScheduler.adminBiz);//初始化本地调度中心服务<br>  NetComServerFactory.setAccessToken(accessToken);<br>  initI18n();//国际化</p>
<p>1、JobRegistryMonitor.getInstance.start();<br>   开启一个单独线程，每30s轮训数据库，如果某个执行器的注册信号在近90s没有写入数据库表xxl_job_qrtz_trigger_registry，那么调度中心认为该执行器已死，<br>会更新数据库表xxl_job_qrtz_trigger_group，使每个执行器组只保留活着的执行器，这里的执行器按调度中心来区分的。每个执行器组都有一个唯一的appName，<br>执行器向调度中心注册时就是通过这个appName标志来区分属于哪个执行器组</p>
<p>2、JobFaileMonitorHelper.getInstance.start();<br>   每隔10s执行一下逻辑。数据库表xxl_job_qrtz_trigger_log里存着每个任务每次的执行记录，这里面记录着任务执行状态，若某条任务状态码为500，<br>那么这条执行记录是以失败告终的。那么失败守护线程就会根据这个任务的executorFailRetryCount（失败重试次数，前端新增任务时配置）是否大于0，若大于0，<br>会尝试再执行下这个任务，并相应的在数据库该条执行日志将executorFailRetryCount值减一，最后发出失败告警。</p>
<p>3、初始化本地调度中心的服务Map一级accessToken值，调度中心实例用HashMap对象存了起来。<br>4、国际化，支持中英文</p>
<p>如何触发：<br>timewheel时间轮 本质是Map&lt;Integer,List&gt;<br>触发算法：<br>JobScheduleHelper<br> scheduleThread死循环 首先利用for update进行获取任务的资格锁定 再拿到距now 5s内的任务列表数据：scheduleList 分三中情况处理：<br> for循环遍历scheduleList集合<br> 1、当前任务触发时间超时5s以上（任务下一次触发时间+5s &lt; now）：直接跳过不执行，重置trigger_next_time<br> 2、（任务下一次触发时间&lt; now &lt;= 下一次触发时间+5s）：线程执行触发逻辑，若任务下一次触发时间在5s内，<br> 则放到时间轮内（Map&lt;Integer,List&gt;秒数(0-59)=&gt;任务id列表），再重置trigger_next_time<br> 3、（now &lt;= 任务下一次触发时间）：对触发时间秒数进行60取模直接放到时间轮内，重置trigger_next_time</p>
<p> ringData的处理逻辑在第二个守护线程ringThread中<br>  ringThread死循环 取当前秒数刻度和前一个刻度，在ringData中获取要执行的任务</p>
<p>不管是scheduleThread还是ringThread，最后完成任务调度的都是JobTriggerPoolHelper，此类有两个线程池fastTriggerPool和slowTriggerPool<br>调度线程池隔离，拆分为fast和slow，1分钟窗口期内任务耗时达500ms超过10次，该窗口期内判定为慢任务，慢任务自动降级进入slow线程池，避免耗尽调度线程，提高系统稳定性<br>triggerPool.execute{<br>  …<br>  XxlJobTrigger.trigger —-&gt; processTrigger—&gt; runExecutor –&gt; XxljobScheduler.getExecutorBiz这里的executorBiz是XxlRpcReference.getObject()获取到的代理类<br>  executorBiz.run 此处执行的就是XxlRpcReference的invoke方法 发起远程调用<br>  …<br>  }</p>
<p>执行器：<br>    XxlJobExecutorApplication –&gt; XxlJobSpringExecutor(其中adminAddress为调度中心地址) 实现了ApplicationContextAware保存上下文信息–&gt; start<br>–&gt; 调用本类私有方法取出JobHandler实现类，再调用registJobHandler(name,handler)进行注册  维护了一个Map –&gt;调用父类start方法 大部分业务逻辑在此处理<br>–&gt; 日志处理器初始化、向adminBizList字段中放入XxlRpcReferenceBean返回的代理类、任务日志清除、任务结果回调处理线程、启动XxlRpcProviderFactory</p>
<p>XxlRpcProviderFactory 可以返回Rpc调用服务提供端的工厂类，启动了一个以netty作为通讯模型，hessian作为序列化方式的，ExecutorServiceRegistry作为注册逻辑<br>实现类的服务提供端，接着我们向其添加一个服务ExecutorBiz，处理请求的实现类为ExecutorBizImpl 调用start完成执行器端的服务暴露， ExecutorServiceRegistry<br>调用其start 以30s的间隔和调度中心进行心跳通知，然后调用server的start方法 此时server为NettyHttpServer<br>整个代码结构就是用netty启动了个服务， ChannelHandler，NettyHttpServerHandler 调用私有方法process 这里调用了xxlRpcProviderFactory的invokeService方法完成<br>服务实现的反射调用</p>
<p>ExecutorBizImpl<br>XxlJobExecutor内部会有个以jobId为key，执行这个任务的线程为value的字段jobThreadRepository，我们首先去尝试获取当前正在执行这个任务的线程，<br>如果有就根据任务设置的运行模式进行处理，如果没有正在执行此任务的线程，就调用XxlJobExecutor.registJobThread启动一个线程，最后将任务数据推送给这个可能<br>是从jobThreadRepository获取到的也可能是新创建的线程  JobThread的run方法会从triggerQueue里poll出任务，然后用之前设置的handler进行execute方法调用并利用<br>idleTimes字段进行无任务空转的次数控制，至此执行器完成了启动，暴露ExecutorBiz服务，接收任务调度数据TriggerParam并在JobThread线程中完成任务配置的业务<br>handler的执行</p>
<p>轮询：不能按机器性能充分利用资源<br>权重：可按机器性能分配任务<br>一致性hash：整个空间按顺时针方向组织，圆环上的点从0到2的32次方，将各个服务器使用hash进行哈希，具体可选服务器IP或主机名，确定服务器在哈希环的位置，将<br>数据key使用相同的hash计算出哈希值，从此位置顺时针第一台遇到的服务器就是其该定位到的服务器。使用虚拟节点避免数据倾斜问题。<br>实际应用通常将虚拟节点数设为32甚至更大。  TreeMap<br>LRU：最近最少使用，淘汰最长时间未被使用的    看最后一次被使用到发生调度的时间长短<br>LFU：最少访问算法，淘汰一定时间内访问次数最少的  看一定时间段内被使用的频率</p>
]]></content>
  </entry>
  <entry>
    <title>Sql优化</title>
    <url>/2022/06/25/Sql%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<p>数据库sql优化：<br>    1、避免全表扫描，应考虑在where和order by后的字段建立索引<br>    2、尽量避免在where子句中对字段进行null值判断，否则会放弃索引使用全表扫描<br>    3、尽量避免在where子句使用！= 或 &lt;&gt; 否则会放弃索引使用全表扫描<br>    4、尽量避免在where子句使用or来连接，否则会放弃索引使用全表扫描，可使用union all<br>    5、in和not in要慎用，否则会放弃索引使用全表扫描，连续的值推荐使用between<br>    6、通配符（%）不要放在索引字段词首，否则会放弃索引使用全表扫描<br>    7、尽量避免在where子句对字段进行函数操作。否则会放弃索引使用全表扫描<br>    8、尽量避免在where子句对字段进行表达式操作，否则会放弃索引使用全表扫描<br>    9、不要在where子句“=”左边进行函数或其他运算，否则可能会导致系统无法正确使用索引<br>    10、若使用索引字段为条件，且该索引为复合索引，那么必须使用到该索引中第一个字段作为索引条件时才能保证系统使用该索引，并应尽可能让字段顺序与索引顺序一致<br>    11、并非所有索引都对查询有效，当索引列有大量数据重复时，sql可能不会去利用索引<br>    12、索引不是越多越好，提高select效率，降低了insert、update效率，因为insert/update可能会重建索引，一个表索引最好不超过6个<br>    13、一般char比varchar2效率高，但varchar2更节省空间，在节省很多空间情况下varchar2效率更高；含中文字符用nchar/nvarchar2,纯英文和数字用char/varchar2<br>    14、尽可能使用varchar代替char，节省空间<br>    15、不要使用select * from  t，解析时会将<em>转化为列名，降低效率<br>    16、避免频繁创建删除临时表<br>    17、避免大事务操作<br>    18、尽量避免向客户端返回大数据量<br>    19、新建临时表数据量量很大时采用select into代替create table 避免大量log<br>    20、多表查询时数据量少的表放在后面，因为oracle解析器按照从右到左的顺序处理from后的表名<br>    21、一般count（一个索引字段）&gt;count（</em>）&gt;count（一个非索引字段）<br>    22、IN和EXISTS<br>        IN：子查询先产生结果集  select * form tableA where x in (select y from tableB); 适合tableB记录少，tableA记录多且有索引的情况<br>        EXISTS：先主查询    select * from tableA where exists(select * from tableB b where b.id=a.id) 适合tableA记录少，tableB记录多且有索引的情况<br>    23、decode：避免重复扫描相同记录<br>        decode(k ,v1, v2 ,v3): 当k值为v1时返回v2 否则返回v3<br>        decode(k,v1,v2,v3,v4): 当k值为v1时返回v2，为v3时返回v4<br>    24、高效删除重复记录： delete from emp e where e.rowid &gt; (select min(m.rowid) from emp m where m.emp_no=e.emp_no);</p>
<pre><code>explain plan for &lt;sql&gt;

ID：序号，不是执行先后顺序，执行先后根据缩进判断
operation：操作内容
rows：估计当前操作返回的结果集
cost：sql执行代价
time：估计当前操作时间
Access：通过某种方式定位了需要的数据，表示这个谓词条件的值将会影响数据访问路径
filter：把所有数据访问了，过滤不需要的，表示谓词条件的值不会影响数据访问路径</code></pre><p>truncate和delete<br>truncate table 表名 速度快效率高；功能上与不带where的deete相同，truncate不能带条件<br>对于有外键的表不能用truncate而应使用delete，truncate不能用于参与了索引视图的表<br>若有rollback，delete会被撤销truncate不会。</p>
<p>数据库范式<br>    第一范式：1、列不可再分 2、同一列中不可有多个值 3、不可有重复的列<br>    第二范式：1、满足第一范式 2、没有部分函数依赖<br>    第三范式：1、满足第二范式 2、没有传递依赖</p>
<p>尽量不要用外键，极大影响性能；</p>
]]></content>
  </entry>
  <entry>
    <title>Sharding-Sphere</title>
    <url>/2022/06/25/Sharding-Sphere/</url>
    <content><![CDATA[<p>为什么要分库分表：<br>    业务越开越大，单表数据超出数据库支持的容量；持久化磁盘IO，传统的数据库性能瓶颈<br>    1、换数据库（缓存）<br>    2、Sql、索引、字段优化<br>    3、读写分离（业务有关优化）<br>    4、分库分表（业务）<br>    5、分区<br>读写分离：我们应用程序访问数据库无非是CRUD   分开 –&gt;分库  前提条件： master -&gt;slave 主从同步架构  一般用于读多写少</p>
<p>分库分表方式： 垂直/水平<br>垂直：<br>    通俗说法叫大表拆小表，拆分是基于关系型数据库中的列（字段）进行的<br>    特点：1、每个库（表）的结构都不一样<br>          2、每个库（表）的数据至少有一列一样<br>          3、每个库（表）的并集是全量数据<br>    优点：拆分后业务逻辑清晰（专库专用按业务拆分）<br>          实现动静分离、冷热数据分离设计体现  冷库：发布说说信息  热库：说说点赞和评论信息<br>          数据维护简单，按业务不同业务放到不同机器<br>    缺点：如果单表数据量大，读写压力大<br>          受某种业务来决定或限制，一个业务往往会影响到数据库瓶颈<br>          部分业务无法关联join，只能通过java程序，提高了开发复杂度</p>
<p>水平：<br>    以某个字段按照一定规律（取模）将一个表的数据分到多个库中<br>    特点：1、每个库（表）的结构都一样<br>          2、每个库（表）的数据都不一样<br>          3、每个库（表）的并集是全量数据<br>    优点：单库（表）的数据保持在一定量，有助于性能提高<br>          提高了系统的稳定性和负载能力<br>          切分的表的结构相同，程序改造较少<br>    缺点：数据的扩容很有难度维护量大<br>          拆分规则很难抽象出来<br>          分片事务的一致性问题部分业务无法关联join，只能通过java程序</p>
<p>读写分离：主从同步、数据一致性、网络延迟的问题<br>分库分表：增加维护成本、分布式事务（跨库事务）、跨库join、分布式全局唯一id等问题</p>
<p>分库分表算法：<br>    取模（Hash）：通过userid进行123%3=xxx 数据分散均衡 但是扩容时间复杂度为O(N)<br>            一致性Hash：假设某个哈希函数H的值空间为0-2^32 -1，整个空间按顺时针方向组织，0和2^32 -1在零点方向重合，下一步将各个服务器使用Hash，具体可<br>            选择服务器ip或主机名，确定其在哈希环上的位置，将数据key使用相同的函数hash计算出哈希值，从此位置顺时针行走，第一台遇到的服务器就是其应该<br>            定位到的服务器。<br>            一致性哈希算法对于节点的增减都只需重定位环空间中一小部分数据，具有较好的容错性和扩展性。<br>            另外，一致性哈希算法在节点过少时，容易因节点分布不均导致数据倾斜问题，为解决这种问题，一致性哈希算法引入虚拟节点机制，对每一个节点计算多<br>            个hash，每个计算结果位置都放置一个此服务节点。 实际应用中通常将虚拟节点数设为32甚至更大。<br>    范围区分（range）：例如 按月、按省     会有热点数据问题<br>    预定义（list）：预计数据量，先设计好分多少库  （100W-1亿数据  10库）</p>
<p>常见中间件：sharding-sphere、atlas<br>Proxy代理：mycat（重）、mysql-proxy、atlas、sharding-proxy（sharding-sphere）<br>        连接请求发给代理，由代理选择连接数据库<br>JDBC直连：TDDL（淘宝  半开源）、sharding-jdbc（sharding-sphere）<br>        在应用层选择连接的数据库</p>
<p>Sharding-Sphere：<br>    LogicTable逻辑表：数据分片的逻辑表，对于水平拆分的数据（库）表，同一类表的总称  例如t_order_0、t_order_1逻辑表为t_order<br>    ActualTable真实表：在分片的数据库中真实存在的物理表，如t_order_0、t_order_1<br>    DataNode数据节点表：数据分片的最小单元，由数据源名称和数据表组成。例：ds_1.t_order_0，配置时默认各个分片数据库的表结构均相同，<br>        直接配置逻辑表和真实表对应关系即可，如果各数据库表结构不同，可使用ds.actual_table配置<br>    BindingTable绑定表：指在任何场景下分片规则均一致的主表和字表。例如订单表和订单项表。BindingTable关系的多表关联查询不会出现笛卡尔积关联，<br>        关联查询效率大大提升<br>    ShardingColumn分片字段：用于将数据库（表）水平拆分的关键字段，例如订单表订单ID取模分片，则订单ID为分片字段，SQL中若无分片字段将执行全路由，性能较差<br>        Sharding-JDBC支持多分片字段<br>    BroadcastTable广播表：指所有分片数据源中都存在的表，表结构和表中数据在每个数据库中完全一致，适用于数据量不大但需要与海量数据表关联查询的场景，<br>        例如字典表<br>    LogicIndex逻辑索引：某些数据库（如PostgreSQL）不允许同一个库存在名称相同的索引，某些数据库（如Mysql）则允许只要同一个表中不存在名称相同的索引即可。<br>        逻辑索引用于同一个库不允许出现相同索引名称的分表场景，需要将同库不同表的索引名称改写为索引名+表名，改写之前的索引名称为逻辑索引</p>
]]></content>
  </entry>
  <entry>
    <title>Redis</title>
    <url>/2022/06/25/Redis/</url>
    <content><![CDATA[<p>Redis：<br>    数据结构：<br>        String:<br>            set k1 qwer ,   get k1<br>            del k1<br>            append k1 123 (qwer123)<br>            incr/decr/incrby/decrby  必须是数字<br>            getrange/setrange   getrange k1 0 2 (qwe)<br>            setex 设置过期时间 setex k2 10 v2<br>            setnx    不存在就set成功，存在就返回0<br>            mset/mget/msetnx</p>
<pre><code>    List:
        rpush mylist 1 2 3 4 5          rpush list 1 2 3
        lpush rpush lpop rpop
        lrem key n val 删除n个val
        ltrim key start end 截取指定范围值赋给key
        rpoplpush mylist list   (5123)
        lset key index value  
        linsert key before/after v1 v2 在v1前/后 插入v2

    Set：
        sadd、smembers、sismember
        scard 获取元素个数
        srem key val 
        srandmember key n 随机列出n个元素
        spop key 随机出栈
        smove k1 k2 v1 将k1的值v1给k2
        sdiff k1 k2 在k1不在k2的元素
        sinter k1 k2 : k1 k2的交集
        sunion k1 k2 : 并集

    Hash：
        kv模式不变 v为键值对
        hmset customer id 1 name zz age 20、 hmget customer id name age
        hgetall customer
        hdel 
        hlen
        hexists customer id
        hkeys、hvals
        hsetnx

    Zset
        zadd zset01 60 v1 70 v2 80 v3
        zscore key val 
        zrank key val
        zrevrank key val


Maxmemory-policy：
    volatile-lru：使用LRU算法移除key 只对设置了过期时间的key
    allkeys-lru：使用LRU算法移除key
    volatile-random：在过期集合中移除随机的key
    allkeys-random：移除随机的key
    volatile-ttl：移除ttl值最小的key，即最近要过期的key
    noeviction：不进行移除，针对写操作，只返回错误信息


持久化机制：
    RDB：
        手动触发：    
            save:阻塞当前redis服务器直到RDB过程完成，线上环境一般不使用
            bgsave：redis进程执行fork操作创建子进程，持久化由子进程负责，阻塞只发生在fork阶段，一般使用bgsave
        自动触发：
            1、使用save相关配置   save m n 表示m秒内数据集存在n次修改时，自动触发bgsave
            2、从节点执行全量复制操作时主节点自动执行bgsave生成RDB文件发送给从节点
            3、执行debug reload重新加载redis时也会触发save操作
            4、默认执行shutdown时，若没开启AOF则自动执行bgsave
        优点：是一个紧凑的二进制文件，代表redis在某一个时间点上的数据快照，非常适合用于备份、全量复制等，redis加载RDB文件远远快于AOF方式
        缺点：RDB没法做到秒级持久化，因为bgsave每次运行需要fork创建子进程，属于重量级操作；redis演进过程中有多个格式的RDB版本

    AOF：
        以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中的命令；目前是redis主流持久化方式
        开启AOF需设置 appendonly yes   默认不开启 AOF文件通过appendfilename配置设置  默认文件名为appendonly.aof 保存路径与RDB持久化方式一致 通过dir配置
    流程：
        1、命令写入缓冲区
        2、缓冲区根据对应策略向硬盘做同步操作
        3、随着AOF文件变大，需定期重写AOF文件  达到压缩的目的
        4、当redis重启时 加载AOF文件恢复数据

    为什么命令追加到缓冲区？
    reids使用单线程响应，若每次写AOF文件命令都直接追加到硬盘，性能就取决于硬盘负载，先写入缓冲区，reids可提供多种缓冲区同步硬盘策略

    随着命令不断写入，AOF文件越来越大，为解决这个问题redis引入AOF重写机制压缩文件
    1、进程内已超时的文件不会再写文件
    2、旧的AOF文件包含无效命令，如del k1 ,set a 111 ,set a 222等
    3、多条命令合并  如 lpush list a,lpush list b,  lpush list a b

    AOF持久化开启且存在AOF文件时优先加载AOF，否则加载RDB；加载完成后redis启动成功，AOF/RDB存在错误 redis启动失败

Redis事务：
    可一次执行多个命令，本质是一组命令的集合，一个事务中命令被序列化
    multi：开启事务
    exec：执行
    discard：放弃事务
    watch：监视一个或多个key  此key被改动事务被打断   （类似乐观锁）
    unwatch：取消watch对所有key的监控

    redis的事务是部分支持；出现set key这样严重错误时会直接报error但还是可以继续往队列添加命令，只是所有命令都不会成功执行，但是出现incr key（其中key所对应value不为数字时），不会报错，执行时只有这条命令不会成功执行


Redis主从复制：
    1、配从不配主
    2、从库配置：slaveof 主库ip 主库端口  每次与master断开连接后都需重新连接，除非配置进redis.conf文件

    常用：
        一主二仆：一个master两个slave  slave只要一连接就会把master所有数据都记录
                读写分离：只有master能读写，slave只能读不能写
                master挂掉后slave保留之前数据，角色仍是slave，master重新连接后可继续正常工作
                slave挂掉后重新连接后角色为master，也就没有之前的数据了，需重新连接，除非配置进redis.conf文件

        薪火相传：上一个slave可以是下一个slave的master，slave同样可以接受其他slave的连接和同步请求，那么该slave作为链条中下一个的master可有效减轻master的压力；中途变更转向：会清除之前数据，重新拷贝最新的

        反客为主：slaveof no one 使当前数据库停止与其他数据库的同步，角色转为master保留之前的数据


    哨兵模式：
        反客为主需手动将slave转为master  在 sentinel.conf添加 sentinel monitor redis-6379(自己起的数据库名) 127.0.0.1 6379 1
        会监控6379端口的master，master挂了会在剩下slave自动选出一个转为master并将其他slave连接到新的master，若挂掉的master重新连接会被转为slave连接到新的master</code></pre><p>一些常见问题</p>
<pre><code>缓存雪崩：高并发下某一时间同时生成很多缓存并且过期时间在同一时刻
    解决：将缓存失效的时间分散开，在原有失效时间上增加随机值

缓存穿透：查询一个一定不存在的数据导致一直请求DB
    解决：1、若查询一个key不存在则以空结果进行缓存，设置过期时间短一点（几分钟）
          2、布隆过滤器(可看成一个bit数组，映射一个值到布隆过滤器需要使用多个不同的hash函数生成多个hash值，检查某个值对应的多个bit位上的值均为1只能说明可能存在而不是一定存在)

缓存击穿：一个存在的key在过期的同一刻有大量请求
    解决：访问key之前采用setnx设置一个短期key锁住当前key的访问

缓存并发：一个缓存若失效可能多个进程同时查DB同时设置缓存
    解决：对缓存查询加锁，key不存在就加锁，然后查DB入缓存 解锁

热点key：缓存中某些key存储在集群中同一台机器，所有流量涌向同一台机器
    解决：将热点key缓存到本地并设置失效时间，每次请求先检查key是否在本地，不存在再访问缓存机器

Redis是单线程还是多线程？
    Redis中IO多路复用器模块是单线程执行，时间处理器也是单线程执行，两个线程不一样，依靠队列保证顺序；不会上下文切换
    单线程只是针对redis中的模块来说，比如接收请求和响应是单线程，处理事件也是单线程，但是不是同一个。</code></pre>]]></content>
  </entry>
  <entry>
    <title>Nginx</title>
    <url>/2022/06/25/Nginx/</url>
    <content><![CDATA[<p>Nginx：<br>    负载均衡算法：<br>        1、Random随机算法：最简单的随机算法；缺点：数量足够大时才能保证均匀分配<br>        2、Round Robin轮询算法：依次转发；缺点：集群中服务器硬件配置不同无法区别对待<br>        3、随机轮询：随机选择一个节点开始依次轮询<br>        4、加权轮询：为了解决简单轮询的不足。（Nginx默认负载均衡算法）<br>            一般算法可能为：<br>                1、轮询所有节点找到最大权重节点<br>                2、选中节点权重减1<br>                3、直到减到0，恢复节点原始权重，继续轮询<br>            Nginx加权轮询：<br>                weight：约定权重， effectiveWeight：有效权重 初始为weight 调用成功+1  异常-1   currentWeight：当前权重 初始为0<br>                1、轮询所有节点，计算当前所有节点effectiveWeight之和totalWeight<br>                2、currentWeight = currentWeight + effectiveWeight 选中所有节点中currentWeight最大的节点<br>                3、选中节点的 currentWeight = currentWeight - totalWeight<br>        5、加权随机：按权重随机选取服务器<br>        6、最少连接：记录每台服务器正在处理的连接数，将新来请求转发到连接最少的那台<br>        7、Latebcy-Aware：动态选择最低延迟的节点处理当前请求<br>        8、源地址散列：根据源ip进行hash</p>
<p>正向代理（客户端对于服务端来说不可见）：<br>    客户端向代理服务器发送请求并指定目标服务器，代理向目标服务器转交并将获得内容返回给客户端</p>
<p>反向代理（服务端对客户端不可见）：<br>    客户端向反向代理发送请求，反向代理内部自动根据访问内容进行跳转和返回</p>
<p>负载均衡：<br>http {<br>    //负载均衡<br>    upstream  test.com{<br>        server 192.168.196.10:80 weight=10;<br>        server 192.168.196.11:80 weight=5;<br>    }</p>
<pre><code>upstream  platform-login{
    ip_hash;
    server 192.168.196.12:80;
    server 192.168.196.13:80;
}

server { 
    listen 80;
    server_name 192.168.10.112
    location / {
        xxx
    }
    //反向代理
    location /platform-login/ {
        proxy_pass http://platform-login;
    }

    location /test.com/ {
        proxy_pass http://test.com;
    }
}</code></pre><p>}</p>
]]></content>
  </entry>
  <entry>
    <title>Nacos</title>
    <url>/2022/06/25/Nacos/</url>
    <content><![CDATA[<h1 id="Nacos：针对微服务架构中服务发现、配置管理、服务治理的综合型解决方案"><a href="#Nacos：针对微服务架构中服务发现、配置管理、服务治理的综合型解决方案" class="headerlink" title="Nacos：针对微服务架构中服务发现、配置管理、服务治理的综合型解决方案"></a>Nacos：针对微服务架构中服务发现、配置管理、服务治理的综合型解决方案</h1><h2 id="配置中心"><a href="#配置中心" class="headerlink" title="配置中心"></a>配置中心</h2><p>配置中心：在微服务架构中，当系统从一个单体应用，被拆分成分布式系统上一个个服务节点后，配置文件也必须跟着迁移（分割），这样配置就分散了，不仅如此，分散中还包含着冗余。配置中心将配置从各应用中剥离出来，对配置进行统一管理。</p>
<ol>
<li>在配置中心发布/修改配置</li>
<li>配置中心将配置更新通知到各客户端</li>
<li>客户端从配置中心获取最新配置</li>
</ol>
<p>主流配置中心对比：从配置中心角度看，性能方面Nacos读写性能最高，Apollo次之，SpringCloud Config依赖git场景不适合开放大规模自动化运维API，功能方面Apollo最为完善，Nacos具有Apollo大部分配置管理功能（Nacos不支持灰度发布和权限管理），而SpringCloud Config不带运维管理界面。Nacos一大优势是整合了注册中心、配置中心功能，部署和操作相比Apollo都要直观简单。</p>
<h2 id="Nacos特性"><a href="#Nacos特性" class="headerlink" title="Nacos特性"></a>Nacos特性</h2><p>Nacos主要提供以下四大功能：</p>
<ol>
<li><p>服务发现与服务健康检查</p>
<p>Nacos使服务更容易注册，并通过DNS或Http接口发现其他服务，Nacos还提供服务的实时健康检查，以防止向不健康的主机或服务实例发送请求 </p>
</li>
<li><p>动态配置管理</p>
<p>动态配置服务允许在所有环境中以集中和动态的方式管理所有服务的配置，Nacos消除了在更新配置时重新部署应用程序，这使配置的更改更加高效和灵活</p>
</li>
<li><p>动态DNS服务</p>
<p>Nacos提供基于DNS协议的服务发现能力，旨在支持异构语言的服务发现，支持将注册在Nacos上的服务以域名的方式暴露端点，让三方应用方便的查阅及发现</p>
</li>
<li><p>服务和元数据管理</p>
<p>Nacos从微服务平台建设的视角管理数据中心的所有服务及元数据，包括管理服务的描述，生命周期，服务的静态依赖分析，服务的健康状态，服务的流量管理、路由及安全策略。</p>
</li>
</ol>
<p>单机模式时Nacos默认使用嵌入式数据库实现数据的存储，若想使用外部mysql存储Nacos数据：</p>
<ol>
<li>安装数据库 5.6.5+  mysql8以下</li>
<li>初始化mysql数据库，新建数据库nacos_config，数据库初始化文件：${nacoshome}/conf/nacos-mysql.sql</li>
<li>修改${nacoshome}/conf/application.properties文件，增加mysql数据源配置</li>
</ol>
<h5 id="Nacos配置"><a href="#Nacos配置" class="headerlink" title="Nacos配置"></a>Nacos配置</h5><p>​    发布配置： dataId、group、配置格式（text/json/xml/yaml/html/properties）、配置内容</p>
<h5 id="Nacos客户端获取配置"><a href="#Nacos客户端获取配置" class="headerlink" title="Nacos客户端获取配置"></a>Nacos客户端获取配置</h5><p>​    通过Nacos服务地址端口及dataId和group可通过Nacos的API获取配置<code>NacosFactory.createConfigService(properties).getConfig(dataId,group,5000);</code><br>​    监听配置<br><code>NacosFactory.createConfigService(properties).addListener(dataId,group,new Listener(){</code><br>​    <code>public Executor getExecutor(){</code><br>​          <code>return null;    
​    }</code><br>​    <code>public void receiveConfigInfo(String s){</code><br>​         <code>System.out.println(s);</code><br>​    <code>}</code><br><code>});</code></p>
<p>})</p>
<h4 id="Nacos配置管理模型"><a href="#Nacos配置管理模型" class="headerlink" title="Nacos配置管理模型"></a>Nacos配置管理模型</h4><p>​    通过Namespace、group、Data ID能够定位到一个配置集</p>
<h6 id="配置集（Data-ID）"><a href="#配置集（Data-ID）" class="headerlink" title="配置集（Data ID）"></a>配置集（Data ID）</h6><p>​    在系统中，一个配置文件通常就是一个配置集，一个配置集可以包含系统的各种配置信息，例如一个配置集可能包含了数据源、线程池、日志级别等配置项，每个配置集都可以定义一个有意义的名称，就是配置集的ID即Data ID。</p>
<h6 id="配置项"><a href="#配置项" class="headerlink" title="配置项"></a>配置项</h6><p>​    配置集中包含的一个个配置内容即配置项，代表一个具体的可配置的参数与其值域，通常以key=value的形式存在</p>
<h6 id="配置分组（group）"><a href="#配置分组（group）" class="headerlink" title="配置分组（group）"></a>配置分组（group）</h6><p>​    对配置集进行分组，通过一个有意义的字符串来表示，不同配置费分组下可以有相同配置集。默认采用DEFAULT_GROUP。常用来区分不同的项目或应用</p>
<h6 id="命名空间（Namespace）"><a href="#命名空间（Namespace）" class="headerlink" title="命名空间（Namespace）"></a>命名空间（Namespace）</h6><p>​    可用于进行不同环境的配置隔离，例如可以隔开开发环境、测试环境和生产环境，或者隔离不同用户，不同开发人员使用同一nacos管理各自配置，通过namespace隔离，不同namespace下可存在相同名称的配置分组或配置集。默认有一个public命名空间。</p>
<h6 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h6><p>Namespace：代表不同环境<br>Group：代表不同项目<br>Data ID：每个项目下往往有若干工程，每个配置集（Data ID）是一个工程的主配置文件</p>
<p>支持配置的动态刷新：<br>    客户端配置nacos配置中心的地址后，直接使用@value注解获取配置文件的配置，但无法动态刷新，需注入配置文件上下文<br><code>@Autowired</code><br><code>private ConfigurableApplicationContext applicationContext；</code><br><code>applicationContext.getEnvironment().getProperty(&quot;xxx.xx&quot;);</code><br>类上加@RefreshScope注解时使用@Value也可动态刷新</p>
<p>Nacos客户端resources下新建bootstrap.yaml，<font color="red">dataId的名称就是application的name + file-extension</font></p>
<h6 id="自定义扩展dataId"><a href="#自定义扩展dataId" class="headerlink" title="自定义扩展dataId"></a>自定义扩展dataId</h6><p>对于一个项目需多个配置文件的情况可自定义扩展dataId<br><code>ext-config[0]:</code><br>    <code>data-id: test1.properties  (默认DEFAULT_GROUP，namespace即当前配置文件中的namespace)</code><br><code>ext-config[1]:</code><br>    <code>data-id: test2.properties</code><br>    <code>group: group2</code><br><code>ext-config[2]:</code><br>    <code>data-id: test3.properties</code><br>    <code>group: group3</code><br>    <code>refresh: true  (上面两种都不支持动态刷新)</code></p>
<p>或者使用以下方式更为方便：但是此种方法只认DEFAULT_GROUP的dataid</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">spring:</span><br><span class="line">	cloud:</span><br><span class="line">		nacos:</span><br><span class="line">			config:</span><br><span class="line">				shared-dataids: test1.properties,test2.properties,test3.properties</span><br><span class="line">				refreshable-dataids: test3.properties</span><br></pre></td></tr></table></figure>

<p>配置的优先级： C&gt;B&gt;A<br>A：通过<code>spring.cloud.nacos.config.shared-dataids</code>支持多个共享Dataid的配置<br>B：通过<code>spring.cloud.nacos.config.ext-config[n].data-id</code>方式支持多个扩展data id，多个Data Id同时配置时，config[n]的n越大，优先级越高<br>C：通过内部相关规则（应用名+扩展名）自动获取相关的Data Id配置</p>
<h6 id="完全关闭配置"><a href="#完全关闭配置" class="headerlink" title="完全关闭配置"></a>完全关闭配置</h6><p>通过设置<code>spring.cloud.nacos.config.enabled=false</code>来完全关闭Nacos Config</p>
<h4 id="Nacos集群部署"><a href="#Nacos集群部署" class="headerlink" title="Nacos集群部署"></a>Nacos集群部署</h4><pre><code>1. 安装3个以上的Nacos服务
 2. 在所有Nacos目录的conf目录下，将文件cluster.conf.example重命名为cluster.conf，将所有机器以ip：port格式配置进去
 3. 所有客户端分别指定nacos集群中的若干节点
 spring.cloud.nacos.config.server-addr: xx.xx.xx.xx:8848,xx.xx.xx.xx:8849,xx.xx.xx.xx:8850</code></pre><p>生产环境部署建议：<br>      通过域名+VIP（虚拟IP）模式来实现，一个域名对应一个VIP，一个VIP对应多个Nacos节点。当Nacos集群迁移时，客户端无需修改。数据库，生产环境下建议至少主备模式，通过修改${nacoshome}/conf/application.properties文件，使nacos拥有多个数据源。</p>
<h2 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h2><p>微服务架构中，通过服务间的协作来实现业务目标，代码中免不了远程调用。服务消费方获取服务提供方的地址及端口就是服务发现。</p>
<p>Ribbon：客户端负载均衡<br>Feign：远程调用<br>客户端启动类添加@EnableDiscoveryClient、@EnableFeignClients</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">spring:</span><br><span class="line">	application:</span><br><span class="line">		name: xxx</span><br><span class="line">	cloud:</span><br><span class="line">		nacos:</span><br><span class="line">			discovery:</span><br><span class="line">				server-addr: xx.xx.xx.xx:8848</span><br><span class="line">				namespace: dev_test</span><br><span class="line">				cluster-name: DEFAULT</span><br></pre></td></tr></table></figure>

<p>Provider实现</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProviderController</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(ProviderController.calss);</span><br><span class="line">    <span class="meta">@Getmapping</span>(<span class="string">"/service"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">service</span><span class="params">()</span></span>&#123;</span><br><span class="line">        LOG.info(<span class="string">"provider invoke"</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"provider invoke"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Consumer实现</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@FeignClient</span>(value=<span class="string">"xxx"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ServiceAgent</span></span>&#123;</span><br><span class="line">    <span class="meta">@Getmapping</span>(value=<span class="string">"/service"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">service</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerController</span></span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span>  ServiceAgent serviceAgent;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@GetMapping</span>(<span class="string">"/service"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">service</span><span class="params">()</span></span>&#123;</span><br><span class="line">        String result = serviceAgent.service();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>服务根据name分组，同一服务可有多个实例，即集群</p>
<h2 id="Nacos原理"><a href="#Nacos原理" class="headerlink" title="Nacos原理"></a>Nacos原理</h2><h4 id="Nacos配置中心原理"><a href="#Nacos配置中心原理" class="headerlink" title="Nacos配置中心原理"></a>Nacos配置中心原理</h4><p>Nacos通过推+拉的方式解决长轮询时间间隔问题。</p>
<p>拉的优势：如果用推的方式，服务端需维持与客户端的长连接，需消耗大量资源，还要考虑连接的有效性。例如需心跳保活，而用拉的方式客户端只需通过一个无状态的http请求即可获取到服务端的数据。</p>
<p>在长轮询任务中，当服务端配置信息发生变更时，客户端将最新数据拉取下来后保存在CacheData中，同时更新了该CacheData的md5值，当下次触发checkListenerMd5方法时，会发现当前listener所持有的md5值和CacheData的md5值不一样了，即意味着服务端配置发生变更，这时就需将最新数据通知给Listener的持有者。</p>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>Nacos服务端创建了相关配置项后，客户端就可以进行监听了，客户端是通过一个定时任务来检查自己监听的配置项数据的，一旦服务端数据发生变化时，客户端将会获取最新的数据，并将最新的数据保存在一个CacheData对象中，然后重新计算CacheData中的md5属性值，此时就会对该CacheData所绑定的Listener触发receiveConfigInfo回调。</p>
<p>1、先从本地磁盘加载配置，因为应用启动时会加载远程配置到本地，如果本地文件的内容不为空，直接返回；<br>2、如果本地文件内容为空，则调用worker.getServiceConfig加载远程配置<br>3、如果出现异常，则调用本地快照文件加载配置</p>
<p>客户端长轮询主要做两件事：</p>
<ol>
<li><p>检查本地配置checkLocalConfig<br>a. 如果isUseLocalConfigInfo为false，但本地缓存路径的文件是存在的，则将           isUseLocalConfigInfo设为true，并更新cacheData的内容及文件的更新时间</p>
<p>b. 如果isUseLocalConfigInfo为true，但本地缓存文件不存在则设为false，不通知监听器<br>c. 如果isUseLocalConfigInfo为true，本地缓存文件也存在，但是缓存时间与文件更新时间不一致，则更新cacheData中的内容，isUseLocalConfigInfo设为true。<br>若isUseLocalConfigInfo为true，则检查本地文件缓存的md5与cacheData的md5是否一致，不一致则会触发safeNotifyListener回调方法，listener.receiveConfigInfo(contentTmp)  listener的使用者就能接收到最新的配置信息了。</p>
<ol start="2">
<li>检查服务端配置checkUpdateDataIds:获取远程服务器上数据变更的dataId，遍历变化的集合，通过getServerConfig从远程服务器获取相应内容，更新本地cache为服务器端返回的内容，最后遍历cacheDatas，找到变化的数据进行通知。</li>
</ol>
</li>
</ol>
<p>服务端：</p>
<p>客户端发起长轮询请求，服务端收到请求后，先比较客户端请求过来的md5和服务端是否一致，如果不同则直接返回，如果相同则通过schedule延迟29.5s后再比较，为了保证服务端在29.5s内数据变化能及时通知客户端，服务端采用事件订阅的方式来监听服务端本地数据变化的事件，一旦收到事件，则触发DataChangeTask的通知，并遍历allSubs队列中的ClientLongPolling(客户端的长轮询任务)，将结果写回客户端，就完成了一次数据的推送。如果DataChangeTask完成数据“推送”后，ClientLongPolling中的调度任务又开始执行了怎么办？在”推送“前将原等待执行的调度任务取消就可以了，所以在ClientLongPolling方法中最开始的一个步骤就是删除订阅事件。</p>
<h4 id="选举机制"><a href="#选举机制" class="headerlink" title="选举机制"></a>选举机制</h4><p>角色：</p>
<pre><code>1. leader：所有请求处理者，leader副本接受client的更新请求，本地处理后再同步至其他多个副本
 2. follower：请求的被动更新者，从leader接受更新请求，然后写入本地日志文件
 3. candidate：如果follower副本在一段时间内没有收到leader副本的心跳，则判断leader副本可能已经故障，此时启动选举过程，此时副本会变为candidate状态，直到选举结束
 4. term：每一届新的履职期称之为一届任期</code></pre><p>每隔500ms发起一次选举任务和心跳任务</p>
<p>选举过程：</p>
<pre><code>1. 系统刚启动，所有节点任期为0，大家的role都为follower
 2. 一个启动的节点第一个触发未检测到心跳超时，自增任期为1，并且重新计时，给自己投一票，然后向所有其他节点发起投票
 3. 其他节点当前任期为0，收到candidate的投票选举，清零自己的心跳空白等待时间，未超时前不会发起投票，从而避免多重投票导致无效投票的可能性。
 4. 第一个发起投票的节点收到半数投票，成为leader</code></pre><ol>
<li>每次follower收到leader的一次heartbeat，都会清零自己的心跳计时，如果当前心跳计时超时了，仍未收到leader心跳，就会从follower变成candidate</li>
<li>自增当前任期且开始计时，向其它节点发起投票</li>
<li>其它节点会比较任期和日志的序号，至少不能比自己的数据旧才会投票给第一个发起投票的节点</li>
<li>超过半数节点投票成功才会成为leader，否则等待选举超时，再发起第二轮投票</li>
</ol>
<p>在leaderDue内自己是不会发起选举的，只有到期后才会重置leaderDue和heartbeatDue,然后发送投票。每个节点的leaderDusMs设的是随机值，即每个节点的leader任期不一样，从而避免大家同时发起投票，提高选举成功率。某个节点leaderDusMs先减为0, 先自增term，然后发起投票，该节点term+1比其它节点term大，从而成功成为leader。</p>
<p>发起投票的过程为投票发起方向不包含自己的其它节点发起投票请求，其它节点收到请求后，看term是否比自己term大，大则投给他，然后将自己term设为投票发起方的term，重置leaderDueMs（避免自己再发起一轮投票），最后将投票结果返回投票发起方，根据结果有半数投票的leader成为真正的leader。</p>
<p>心跳过程：</p>
<p>​    和选举类似，只有heartBeatDueMs到期后才会发起心跳处理，这里心跳周期远远小于选举的term周期，而且在心跳处理过程中心跳发起方和接收方都会重置选举时间，通过时间的延长阻止各节点发起投票请求。某一节点成为leader后，通过心跳的方式将leader信息传给其他节点。</p>
<p>follower超时：<br>    自身会重新发起选举，如果与其它节点不通，会一直处于选举状态，如果超时一段时间后恢复，会通过选举成为新的leader或者成为原leader的follower（发选举请求前收到了心跳消息），此时有两个leader，但由于旧leader的term较小，最终被新leader同步为follower（为分析结果，待验证）</p>
<p>leader超时：<br>    leader超时重新选举，产生新leader，旧leader恢复后会通过心跳被同步为follower</p>
<h4 id="服务发现-1"><a href="#服务发现-1" class="headerlink" title="服务发现"></a>服务发现</h4><p>​    服务注册：服务提供者会通过轮询配置的注册中心集群地址进行服务的注册，失败则请求下一个节点；nacos client这边在spring容器启动后执行一个服务订阅操作的延时任务，这个任务执行时先拉取nacos server最新的服务列表，然后与本地缓存的服务列表进行比较，取消订阅下线的服务，然后向nacos server发起订阅操作，订阅所有服务。</p>
<p>服务消费者订阅后会执行一个轮训任务（每10s一次）用来拉取最新的服务提供者信息并实时更新，服务提供者注册时nacos服务端也会有一个相应的心跳检测，当心跳检测超时也就是未及时收到服务提供者的心跳包，nacos server判定该服务状态异常，随后通过UDP推送服务信息来告知对应的服务消费者，服务消费者通过PushReceiver来处理udp协议，HostReactor.processServiceJson(String json)来更新本地服务列表。</p>
]]></content>
  </entry>
  <entry>
    <title>Mysql索引</title>
    <url>/2022/06/25/Mysql%E7%B4%A2%E5%BC%95/</url>
    <content><![CDATA[<p>磁盘存取原理：<br>    寻道时间（速度慢、费时）<br>    旋转时间（速度较快）<br>不使用索引效率低下</p>
<p>索引结构<br>    二叉树：极端情况下（索引列递增）效率跟顺序查无差别<br>    红黑树：不会出现二叉树那种极端情况，但数据量大时深度也很深，效率也会降低<br>    HASH：无法范围查询<br>BTree：<br>    节点既存key也存data<br>    度/阶（Degree）-节点的数据存储个数<br>    叶节点具有相同的深度<br>    叶节点的指针为空<br>    节点中的数据key从左到右递增排列<br>硬盘和内存交互以页为单位，1页大约16K，内存读取硬盘数据每次N页，若Degree设的很大，数据放在一层，仍然会导致多次IO（数据大小/N）。</p>
<p>B+Tree（Mysql使用的索引结构）：<br>    非叶子节点不存储data，只存储key，可以增大度<br>    叶子节点不存储指针<br>    顺序访问指针，提高区间访问的性能</p>
<p>B+Tree索引性能分析<br>    一般使用磁盘IO次数评价索引结构优劣<br>    预读：磁盘一般会顺序向后读取一定长度的数据（页的整数倍）放入内存<br>    局部性原理：当一个数据被使用到时，其附近的数据也通常会马上被使用<br>    B+Tree节点的大小设为等于一个页，每次新建节点直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，就实现了一个节点的载入只需一次IO<br>    B+Tree的度d一般会超过100，因此h非常小（一般在3到5之间）</p>
<p>Mysql存储引擎是表级别的（MyISAM 非聚集索引，InnoDB 聚集索引）<br>    MyISAM索引文件和数据文件是分离的，data存的是数据指针（地址）<br>    主键索引和非主键索引实现相同</p>
<pre><code>InnoDB索引实现
    数据文件本身就是索引文件
    表数据文件本身就是按B+Tree组织的一个索引结构文件
    聚集索引-叶节点包含了完整的数据记录
    主键索引叶子节点存储索引和数据，非主键索引叶子节点存储主键的值

为什么InnoDB表必须有主键，并且推荐使用整型自增主键？
    因为InnoDB查询都是根据主键查的，非主键索引都会查到主键然后根据主键去查数据；
    若没有主键，InnoDB会默认选择一列(无重复数据)作为主键，若无满足条件的列则会自己生成主键
    假设使用UUID作为主键，与自增整型主键比，会浪费一些存储空间，UUID用ASCII值比较不如整型的比较大小效率高
    使用UUID主键不连续，插入时可能会导致已有节点分裂和移动，影响性能
为什么非主键叶子节点存储的是主键值？（一致性和节省空间，若增加数据，不用维护多份索引）</code></pre><p>MyISAM和InnoDB<br>    InnoDB支持事务，MyISAM不支持<br>    InnoDB支持外键，MyISAM不支持<br>    都是B+Tree索引结构，InnoDB是聚集索引，数据和索引在一起，MyISAM数据和索引分开<br>    InnoDB必须有主键，MyISAM可以没有<br>    InnoDB不保存表的具体行数（因为事务特性，同一时刻表中行数对不同事务而言是不一样的），MyISAM用变量保存了表的行数<br>    InnoDB支持表/行级锁，MyISAM支持表级锁<br>    InnoDN存储文件frm,ibd  MyISAM存储文件frm,MYD,MYI<br>    frm是表定义文件，ibd是数据文件；myd是数据文件，myi是索引文件</p>
<p>explain extended <sql> 会在explain的基础上额外提供一些查询优化信息，紧随其后使用show warnings可得到优化后的查询语句<br>explain中每个列的信息：<br>    id列：select的序列号，id的顺序按select出现的顺序增长，id越大执行优先级越高，id相同则从上往下执行，id为null最后执行<br>    select type列：表示查询类型<br>        simple：简单查询，查询不包含子查询和union<br>        primary：复杂查询中最外层的select<br>        subquery：包含在select中的子查询<br>        derived：包含在from子句中的子查询<br>        union：在union中第二个和紧随其后的select<br>        union result：从union临时表检索的select<br>    table列：表示explain的一行正在访问哪个表<br>        当from子句中有子查询时，table列是<derivedn>格式，表示当前查询依赖id=N的查询，于是先执行id=N的查询<br>        当有union时，union result的table值为&lt;union 1,2&gt; 1和2表示参与union的select行id<br>    type列：表示关联类型或访问类型，即Mysql如何查找表中的行<br>            依次从最优到最差：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL<br>            一般来说得保证查询达到range级别，最好达到ref<br>        NULL：mysql能在优化阶段分解查询语句，执行阶段用不着再访问表或索引，例如在索引列选取最小值<br>        const，system：mysql能对查询的某部分进行优化并将其转化为一个常量，system是const的一个特例，表里只有一条元素匹配时为system<br>        eq_ref：primary key或unique key索引的所有部分被连接使用，最多返回一条符条件的记录。<br>        ref：相比eq_ref，不使用唯一索引，而是使用普通索引或唯一索引的部分前缀，可能会找到多个符合条件的行<br>        range：范围扫描通常出现在in(),between,&gt;,&lt;,&gt;=等操作中，使用一个索引来检索给定范围的行<br>        index：扫描全表索引，通常比ALL快一些（index从索引读取，ALL从硬盘读取）<br>        ALL：全表扫描，意味着mysql需要从头到尾查所需要的行。<br>    possible keys列：可能使用哪些索引来查找；<br>        可能出现possible keys有值，key列为NULL的情况，这是因为表中数据不多，mysql认为索引对查询帮助不大，选择全表查询<br>        若这列为空，则没有相关索引<br>    key列：mysql实际采用哪个索引来优化对该表的访问，若想强制mysql使用possible keys中的索引，查询中使用force index<br>    key_len列：显示mysql在索引中使用的字节数，通过这个值可算出具体使用索引中哪些列<br>        计算规则：<br>            字符串：<br>                char(n)：n字节长度<br>                varchar(n):2字节存储字符串长度，如果是utf-8，则长度3n+2<br>            数值类型：<br>                tinyint：1字节<br>                smallint：2字节<br>                int：4字节<br>                bigint：8字节<br>            时间类型：<br>                date：3字节<br>                timestamp：4字节<br>                datetime：8字节<br>            如果字段允许为空，需要1字节记录是否为NULL<br>            索引最大长度768字节，当字符串过长，mysql会做一个类似左前缀索引的处理，将前半部分的字符提取出来做索引<br>    ref列：这一列显示key列记录的索引中，表查找值所用到的列或常量<br>    rows列：这一列是mysql估计要读取并检测的行数，注意这个不是结果集里的行数<br>    Extra列：<br>        Using index：查询的列被索引覆盖（索引包含查询的列），并且where筛选条件是索引的前导列，是性能高的表现<br>        Using where：查询的列未被索引覆盖，where筛选条件非索引的前导列<br>        Using where Using index：查询的列被索引覆盖，且where筛选条件是索引列之一但是不是索引的前导列<br>        NULL：查询的列未被索引覆盖，并且where筛选条件是索引的前导列，意味着用到了索引但部分字段未被索引覆盖，必须通过‘回表’来实现<br>        Using index condition：与Using where类似，查询的列不完全被索引覆盖，where条件中是一个前导列的范围<br>        Using temporary：mysql创建一张临时表来处理查询，出现这种情况一般要通过索引来优化<br>        Using filesort：mysql会对结果进行一个外部索引排序，而不是按索引次序从表里读取，这种情况也要用索引来优化</derivedn></sql></p>
<p>索引的最佳实践<br>    1、全值匹配:条件字段中用到联合索引字段时最好按索引定义的顺序全部用到（若全部使用到但是未按顺序排，mysql会自动优化）。<br>    2、最左前缀法则：如果是联合索引，查询从最左前列开始并且不跳过联合索引中的列<br>        如果最左前列（带头大哥）的索引失效（不是使用‘=’而是用‘&gt;’等范围），则（联合索引中）后面的索引都失效<br>    3、不在索引列上做任何操作（计算、函数、自动or手动类型转换），会导致索引失效而全表扫描<br>    4、存储引擎不能使用索引中范围条件右边的列<br>        explain select * from employees where name=’Rose’ and age=22 and position=’manager’;（name、age、position为联合索引） 走联合索引<br>        explain select * from employees where name=’Rose’ and age&gt;22 and position=’manager’;  position字段不走索引<br>    5、尽量使用覆盖索引（索引列包含查询列），减少select *语句<br>    6、mysql在使用（!=或&lt;&gt;）的时候无法使用索引导致全表扫描<br>    7、is null,is not null也不会使用索引<br>    8、like以通配符开头‘%xxx’ mysql索引会失效导致全表扫描<br>        解决like ‘%字符串%’不被使用的方法：<br>            a.使用覆盖索引，查询字段必须是建立覆盖索引字段<br>            b.当覆盖索引指向的字段时varchar(380)及380以上的字段时，覆盖索引会失效<br>    9、字符串不加单引号索引会失效<br>    10、少用or或in，非主键字段的索引会失效，主键索引是否生效与数据量有关，得看mysql查询优化结果<br>    11、使用join时应该小表在前，大表在后（小表驱动大表），左连接建右表索引，因为左表所有数据都要用到，右表中查找匹配左表的数据</p>
<p>Mysql的锁与事务隔离级别<br>锁的分类：<br>    从性能上分为乐观锁（用版本对比来实现）和悲观锁<br>    从对数据库操作的类型分，分为读锁和写锁（都属于悲观锁）<br>        读锁（共享锁）：针对同一份数据，多个读操作可以同时进行而不会互相影响<br>        写锁（排他锁）：当前写操作没完成前，它会阻断其他读锁和写锁<br>    从对数据操作粒度分，分为表锁和行锁</p>
<p>表锁<br>表锁（偏读），偏向MyISAM存储引擎，开销小，加锁快，无死锁，锁粒度大，发生锁冲突的概率最高，并发度最低<br>MyISAM在执行查询语句前，会自动给涉及的所有表加读锁，在执行增删改操作前，会自动给涉及的表加写锁<br>1、对MyISAM表的读操作（加读锁），不会阻塞其他进程对同一张表的读请求，但会阻塞同一表的写请求（自己当前session也不能写），只有当读锁释放后，才会执行其它进程的写操作<br>2、对MyISAM表的写操作（加写锁），会阻塞其他进程对同一张表的读和写操作，只有当写锁释放后，才会执行其它进程的读写操作<br>简而言之就是  读锁会阻塞写，但是不会阻塞读，而写锁则会把读和写都阻塞</p>
<p>行锁<br>行锁偏向InnoDB存储引擎，开销大，加锁慢，会出现死锁，锁定粒度小，发生锁冲突概率最低，并发度也最高<br>事务是由一组SQL组成的逻辑处理单元<br>Atomicity：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行<br>Consistent：在事务开始和完成时，数据都必须保持一致状态<br>Isolation：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的‘独立’环境执行。意味着事务处理过程中的中间状态对外部不可见，反之亦然<br>Durable：事务完成之后，它对数据的修改是永久性的，即使出现系统故障也能保持。</p>
<p>并发事务处理带来的问题<br>更新丢失：当两个或多个事务选择同一行进行更新，最后的事务更新覆盖了之前事务的更新操作 （可用乐观锁解决）<br>脏读：一个事务读取到另一个事务修改了但未提交的数据  （解决：事务隔离级别设为已提交读）<br>不可重复读：事务A中两次执行同一条查询sql结果不一致（数据被其他事务修改）  （解决：事务隔离级别设为可重复读）<br>幻读：事务A读到了事务B提交的新增数据</p>
<p>查看当前数据库事务隔离级别： show variables like ‘tx_isolation’;<br>设置事务隔离级别： set tx_isolation=‘REPEATABLE-READ’；<br>可重复读   MVCC机制：select操作不会更新版本号，是快照读，增删改会更新版本号，是当前版本。</p>
<p>Oracle默认隔离级别为已提交读，Mysql默认隔离级别为可重复读<br>Spring设置的隔离级别与数据库默认级别不一致，以Spring为准，若Spring设置的隔离级别数据库本身不支持，则以数据库为准<br>Oracle支持两种：已提交读和串行化<br>Mysql四种都支持</p>
]]></content>
  </entry>
  <entry>
    <title>Kafka</title>
    <url>/2022/06/25/Kafka/</url>
    <content><![CDATA[<p>Kafka：<br>    一个分布式的基于 发布/订阅 模式的消息队列  主要用于大数据实时处理领域</p>
<p>使用消息队列的好处：<br>    1、解耦，允许独立扩展和修改两边的处理过程<br>    2、可恢复性，系统一部分组件失效时不会影响到整个系统<br>    3、缓冲，优化数据流经过系统的速度<br>    4、削峰</p>
<p>运用场景：<br>    1、异步处理：<br>        例如用户注册后需发注册邮件和注册短信，传统作法有串行和并行两种，串行：注册信息入库后发送注册邮件、注册短信后返回给用户；并行：信息入库后并行发送邮件和短信，成功后返回。使用消息队列后：信息入库后邮件、短信信息写入消息队列后直接返回。<br>    2、应用解耦：<br>        例如用户下单后订单系统调用库存系统接口，假如库存系统无法访问就会导致下单失败；使用消息队列：订单系统持久化信息后写入消息队列返回下单成功，库存系统拉取消息扣减库存。<br>    3、流量削峰：<br>        例如秒杀活动，服务器收到请求后写入消息队列，秒杀业务根据队列中信息做后续处理<br>    4、日志处理：<br>        日志采集客户端写入kafka队列，日志处理应用消费队列中数据<br>    5、消息通讯：<br>        点对点通讯：A、B使用同一队列 聊天室：多个客户端订阅同一主题；</p>
<p>消息队列的两种模式：<br>    1、点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）<br>    2、发布/订阅模式（消费者消费数据后不会清除数据）</p>
<p>一个kafka集群中有多个broker（每台机器一个broker），一个broker中多个topic，一个topic中有多个分区partition，每个partition可有多个副本，副本必须分布在不同机器否则无意义，副本中有一个leader，其他为follower；只对leader进行读写，follower只是备份；</p>
<p>消息存储：逻辑上每个partition分为多个segment，每个segment中有存储文件索引的index文件和存储数据的log文件。物理表现为每个partition都有一个文件夹，其中有各个分区的log和index文件，命名规则为当前文件首条消息的offset；</p>
<p>如何定位到指定offset的消息：通过二分法查找到小于等于指定offset的最大offset文件，用 N=（指定offse - 此文件offset）即可找到指定offset消息的索引，即在此index索引文件中第N条消息在log数据文件中的偏移量，从对应log文件中此偏移量位置开始读取，<br>消息结构包含offset和消息大小，所以可以确定读到哪里截止。</p>
<p>producer生产消息存放：<br>    1、指定partition、key、value，存到指定分区<br>    2、指定key、value，通过key的hash值与topic的partition取余存到对应分区<br>    3、指定value，第一次调用随机生成一个整数（后续递增），将此值与partition取余得到对应分区，即轮询</p>
<p>数据可靠性保证：topic每个partition收到producer发送的数据后，都需向producer发送ack，若没收到会重新发送</p>
<p>何时发送ack?<br>    确保有follower和leader同步完成，leader再发送ack，这样才能保证leader挂掉后能在follower中选出新的leader<br>多少个follower同步完成后发送ack？<br>    方案1、半数以上完成。优点：延迟低  缺点：选举leader时，容忍n台机器故障需要2n+1个副本<br>    方案2、全部完成同步。优点：选举新leader时，容忍n台故障需要n+1个副本  缺点：延迟高<br>Kafka选择了第二种，因为：<br>    1、同样为了容忍n台节点故障，方案1需要多出n个副本，而kafka每个分区都有大量数据，方案一会造成大量数据冗余<br>    2、网络延迟对kafka影响较小</p>
<p>ISR<br>    方案2当有一个follower因某种故障迟迟不能与leader同步那么leader就会一直等下去，直到同步才会发送ack。怎么解决这个问题？<br>    leader维护了一个动态的in-sync-replica set（ISR），意为和leader保持同步的follower集合，当ISR中follower完成数据同步后leader就会发送ack，若有follower迟迟不能同步，则将该follower踢出ISR，该事件阀值由replica.lag.time.max.ms参数设定，leader故障就会从ISR选举新leader</p>
<p>ack应答机制（可靠性级别）<br>    0：producer不等待broker的ack，broker一接收到没落盘就返回。beoker故障可能数据丢失。<br>    1：等待ack，leader落盘成功后返回ack，若在follower同步成功前leader故障会导致数据丢失。<br>    -1：等待ack，leader和follower全部落盘成功才返回。若在follower同步后，broker发送ack之前，leader故障会导致数据重复。</p>
<p>Log文件中的LEO和HW<br>    LEO：log end offse，每个副本最后一个offset<br>    HW：high watermark，所有副本中最小的LEO，消费者能见到的最大offset</p>
<p>1、follower故障<br>    故障后会被临时踢出ISR，待该follower恢复后。会读取磁盘上次记录的HW，将高于HW部分截掉，从HW开始向leader同步，等该follower的LEO大于等于该partition的HW，及即follower追上leader后，重新加入ISR</p>
<p>2、leader故障<br>    leader故障后会从ISR选出新的leader，为保证多个副本数据一致性，其余follower会先将各自log文件高于HW部分截掉，然后从新的leader同步数据<br>    （只能保证副本间数据一致性，不保证数据不丢失或不重复）</p>
<p>Exactly Once语义<br>    Ack级别设为,-1,保证不会丢失数据，即At Least Once<br>    Ack级别设为0，保证生产者只发送一次，即At Most Once<br>    Kafka0.11版本之前不能保证既不重复也不丢失，0.11后增加幂等性，At Least Once + 幂等性 = Exactly Once<br>启用幂等性只需将producer参数中enable.idompotence设为true即可，开启后producer会在初始化时分配一个PID，发往同一partition的消息会带上sequence Number，而Broker端会对&lt;PID,Partition,SeqNumber&gt;缓存，当相同主键消息提交时broker只会持久化一条</p>
<p>消费者：<br>    消费方式：Kafka采用pull拉模式从broker中读取数据<br>    push推模式很难适应消费速率不同的消费者，因为发送速率由broker决定<br>    pull模式缺点是无数据时也会循环取空数据；针对这点Kafka在消费时会传入一个timeout参数，无数据时会等上timeout的时间再返回。</p>
<p>消费者分区分配：<br>    1、Range（默认）：假如有10个分区0-9 3个消费者C1 C2 C3 则C1：0,1,2,3 C2:4,5,6 C3:7,8,9<br>        基于主题，同一个消费者组哪些成员指定了相同的主题则由这些成员去消费该主题分区。如有一个主题分区为0-6这7个分区，同组两个消费者B、D消费该主题，则B被分配0-3这4个分区，D被分配4-6这三个。<br>        当同组多个消费者消费主题相同且数量较多时，可能会导致B消费20个，D消费15个，消费不平衡。<br>    2、RoundRobin: 轮询  3个消费者C0 C1 C2 集群中三个主题t0,t1,t2 这三个主题分别有1、2、3个分区，即t0p0,t1p0,t1p1,t2p0,t2p1,t2p2这6个分区<br>        C0订阅主题t0，消费者C1订阅了主题t0和t1，C2订阅了t0 t1 t2<br>        C0：t0p0     C1:t1p0     C2:t1p1、t2p0、t2p1、t2p2</p>
<pre><code>3、Sticky：黏性分区  1、轮询  2、最优配置 3、分配尽可能和上次分配的保持相同
    C0：t0p0     C1:t1p0、t1p1    C2:t2p0、t2p1、t2p2</code></pre><p>Rebalance触发时机:<br>    1、组成员个数发生变化<br>    2、订阅topic个数发生变化<br>    3、订阅topic的分区数发生变化</p>
<p>消费者offset维护：<br>    0.9之前默认将offset保存在Zookeeper中，0.9之后默认将offset保存在Kafka一个内置的topic中_consumer_offsets<br>    消费者组G+主题T+分区P来确定offset</p>
<p>reset：若存在已提交的offset，不管设置为earliest或者latest都会从已提交的offset处开始消费；若不存在已提交的offset，earliest表示从头开始消费，latest表示消费最新数据。<br>none:topic各分区都存在已提交的offset时从offset开始消费，只要有一个分区不存在已提交的offset抛出异常</p>
<p>Kafka事务<br>    Producer事务：PID和Transaction ID绑定，producer重启后可通过Transaction ID获取原来的PID；Transaction Coordinator会将事务状态保存到Kafka的一个内部topic</p>
<pre><code>Consumer事务：
事务机制主要从Producer方面考虑，对于Consumer而言无法保证commit的信息被精确消费，由于Consumer可通过offset访问任意信息，而且不同Segment File生命周期不同，同一事务消息可能出现重启后被删除的情况</code></pre><p>Kafka API<br>    Producer发送消息：异步发送，main线程将消息发送给RecordAccumulator，Sender线程不断从中拉取消息发送到Kafka broker<br>    batch.size：数据累积到batch.size后sender才会发送数据<br>    linger.ms：如果数据迟迟未达到batch.size,sender等待linger.ms之后就会发送数据。</p>
<p>自定义分区 Partition</p>
<p>自定义存储offset：ConsumerRebalanceListener<br>    自动提交/手动提交可能会导致漏消费数据/重复消费数据，可自定义存储offset</p>
<p>自定义拦截器  ProducerInterceptor</p>
]]></content>
  </entry>
  <entry>
    <title>JVM</title>
    <url>/2022/06/25/JVM/</url>
    <content><![CDATA[<p>运行时数据区：<br>    线程共享：堆（存放对象实例）、方法区（类型信息、常量、静态变量、运行时常量池，方法区是一种规范，永久代是一种实现;JDK7以后常量池被移动到堆中，逻辑上还是属于方法区）<br>    线程隔离：虚拟机栈（存储局部变量表、操作数栈、动态连接、方法出口等）、本地方法栈、程序计数器（执行java方法记录的是正在执行的虚拟机字节码指令的地址，执行本地方法计数器值为空）</p>
<p>对象的创建：<br>    分配内存方式<br>        指针碰撞（内存规整时）：使用过的内存放在一边，未使用的内存放在另一边中间放着一个指针作为指示器<br>        空闲列表（内存不规整时）：记录哪些内存块可用<br>    选择哪种分配方式取决于垃圾收集器是否具有空间压缩整理功能<br>    线程安全的分配内存：1、CAS + 失败重试 2、TLAB 本地线程分配缓冲：每个线程先在Java堆中分配一小块内存</p>
<p>对象在堆内存布局：<br>    1、对象头<br>        ①存储对象自身运行时数据（哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳）<br>        ②类型指针<br>    2、实例数据（对象真正存储的有效信息）<br>    3、对齐填充（任何对象的大小必须是8字节的整数倍）</p>
<p>对象的访问定位：<br>    1、使用句柄访问   栈 ref –&gt; 堆中句柄池 –&gt; 实例池/方法区<br>    2、使用直接指针（HotSpot）   栈 ref –&gt; 实例池/方法区<br>第一种好处是对象被移动（垃圾收集）只会改变句柄中的实例数据指针，不需改ref<br>第二种好处是访问速度快</p>
<p>OutOfMemoryError:<br>    堆溢出：不断创建对象，保证GC Roots到对象之间有可达路径避免垃圾回收机制清除这些对象<br>    栈溢出：<br>            1、线程请求栈深度大于虚拟机允许最大深度（无限调用自己） StackOverflowError<br>            2、虚拟机栈内存允许动态扩展（定义大量本地变量）(HotSpot选择不支持扩展)，当扩展栈容量无法申请到足够内存时，OutOfMemoryError<br>    方法区和运行时常量池溢出：<br>        无限String.intern、CGLib生成大量动态类 （JDK8之后方法区挪到元空间，元空间不在虚拟机中，而是使用本地内存，很难出现这种异常）<br>    直接内存溢出特征：内存溢出后生成的dump文件很小 且直接或间接使用DirectMemory（例如NIO） 考虑检查直接内存</p>
<p>垃圾回收：<br>        引用计数法：对象中添加一个计数器，每当有一个地方引用它，计数器值+1，引用失效时-1 （无法解决循环引用问题，Java主流虚拟机都未使用此方法）<br>        可达性分析：从GC Roots开始，根据引用关系向下搜索，从GC Roots到对象无引用链即判定为可回收对象<br>        GC Roots：<br>            1、在虚拟机栈（本地变量表）中引用的对象<br>            2、方法区中类静态属性引用的对象<br>            3、方法区中常量引用的对象<br>            4、本地方法栈中JNI引用的对象<br>            5、虚拟机内部的引用（常驻异常对象、系统类加载器、基本数据对应的Class对象）<br>            6、被同步锁持有的对象<br>            7、分代收集、局部回收时关联区域的对象临时性的加入</p>
<p>引用：<br>    强引用：程序中普遍存在的引用赋值 Obj obj=new Obj（）；强引用关系还存在永远不会被回收<br>    软引用：SoftReference接口，在系统将要发生内存溢出前，会回收这些对象，回收后还是无足够内存，抛出内存溢出异常<br>    弱引用：WeakReference接口，只能生存到下一次垃圾回收发生为止，不管内存是否足够，都会回收弱引用关联的对象<br>    虚引用：PlantomReference接口，不会对对象生存时间构成影响，也无法通过虚引用取得对象实例，只是为了在对象被回收时收到系统通知。必须和引用队列（ReferenceQueue）联合使用。</p>
<p>如果对象在进行可达性分析后没有与GC Roots的引用链，会被第一次标记，随后会进行筛选是否需要执行finalize方法，<br>若对象没有覆盖finalize或者已被虚拟机调用过，则都不会执行finalize方法，（执行是指虚拟机会触发这个方法开始运行，并不保证等待它结束，防止某个对象此方法死循环造成系统崩溃）finalize方法是对象逃脱死亡的最后一次机会，只要与引用链上任一对象建立关联即可</p>
<p>回收方法区：<br>    主要回收两部分：废弃的常量和不再使用的类型<br>    常量回收：已经没有任何对象引用常量池中该常量<br>    不再使用的类：<br>      1、该类所有实例都已被回收<br>      2、加载该类的类加载器已被回收<br>      3、该类对应的Class对象没有在任何地方被引用</p>
<p>分代收集理论：建立在两个假说之上<br>  弱分代假说：绝大多数对象都是朝生夕灭的<br>  强分代假说：熬过多次垃圾收集过程的对象就越难以消亡<br>  跨代引用假说：跨代引用相对于同代引用来说仅占极少数<br>根据跨代引用假说，不必为了少量跨代引用扫描整个老年代，只需在新生代建立一个全局数据结构（记忆集），把老年代划分为若干小块，标识出老年代哪块内存会存在跨代引用，发生Minor GC时包含了跨代引用的小块内存对象才会被加入到GC Roots扫描，此法虽然在对象改变引用关系时维护数据的正确性会增加一些运行时开销，比起扫描整个老年代仍是划算的。</p>
<p>Partial GC:指目标不是完整收集整个Java堆的垃圾收集<br>    Minor GC：指目标只是新生代的垃圾收集<br>    Major GC：指目标只是老年代的垃圾收集（CMS）<br>    Mixed GC：指目标收集整个新生代及部分老年代的垃圾收集<br>Full GC：收集整个Java堆和方法区的垃圾收集</p>
<p>标记-清除算法：最基础的收集算法<br>    缺点：1、执行效率不稳定，若Java堆中包含大量对象，其中大部分需要被回收，此时必须进行大量标记和清除动作<br>          2、内存碎片化问题，会产生大量不连续内存碎片导致需要分配较大对象时无法找到足够连续内存而提前出发垃圾收集<br>标记-复制算法：将内存按容量划分为大小相等的两块，每次只使用其中一块，当这块内存用完会将活着的对象复制到另一块上，再把已使用过的内存空间一次性清理掉<br>    缺点：1、如果内存中多数对象存活，会产生大量内存间复制开销<br>          2、将可用内存缩小为原来的一半<br>    现在Java虚拟机大多优先采用标记-复制算法去回收新生代，新生代对象98%熬不过第一轮收集，所以Eden:Survivor是8:1    若survivor不够存放上一次新生代收集的存活对象，这些对象便将通过分配担保机制直接进入老年代<br>标记-整理算法：让所有存活对象都向内存空间的一端移动，然后直接清理掉边界以外的内存<br>    移动对象：尤其在老年代这种每次回收都有大量对象存活的区域，移动并更新引用是极为负重的操作，会STW<br>    不移动对象：弥散于堆中的存活对象导致空间碎片化问题只能依赖更复杂的内存分配器和内存访问器来解决，譬如“分区空闲分配链表”<br>    基于以上两点，从垃圾收集停顿时间看，不移动对象时间停顿会更短，但从整个程序吞吐量看，移动对象会更划算<br>    还有一种和稀泥式的解决方案，大多数时间采用标记-清除算法，直到碎片化大到影响对象分配时，采用标记-整理算法收集一次。基于标记-清除的CMS收集器面临碎片过多时采用的就是这种。</p>
<p>Hotspot算法细节实现：<br>    OopMap数据结构：一旦类加载动作完成，Hotspot就会把对象内什么偏移量上是什么类型的数据计算出来，在即时编译过程中也会在特定位置记录下栈里和寄存器哪些位置是引用，<br>    这样收集器在扫描是就可直接得知这些信息，不必真正的一个不漏地从方法区等GCRoots开始查找。<br>    导致OopMap内容变化的指令非常多，若为每条指令都生成对应OopMap将需要大量额外存储空间，因此只在特定位置记录这些信息，这些位置被称为安全点。<br>    强制要求必须执行达到安全点才能暂停，安全点的选定基本是以是否具有让程序长时间执行的特征为标准来选定的，例如 方法调用、循环跳转、异常跳转等<br>   如何在垃圾收集时所有线程都跑到最近安全点：<br>        抢先式中断（现在几乎不用）：发生垃圾收集时，系统首先将所有用户线程全部中断，若发现中断地方不在安全点就恢复这条线程执行，让它一会再重新中断直到跑到安全点。<br>        主动式中断：当垃圾收集需要中断线程时，不直接对线程操作，仅单独设置一个标志位，各线程执行时不断主动去轮询这个标志，一旦发现中断标志为真就在自己最近的安全点主动中断挂起。<br>    轮询标志的地方与安全点是重合的，另外还要加上所有创建对象和其他需要在Java堆分配内存的地方，这是为了检查是否即将要发生垃圾收集，避免没有足够内存分配新对象<br>    用户线程处于sleep/blocked状态时无法响应虚拟机中断请求，对于这种情况必须引入安全区来解决<br>    安全区：指能够确保在某段代码片段中引用关系不会变化，此区域中任何地方开始垃圾收集都是正常的。</p>
<pre><code>记忆集与卡表：
    垃圾收集器在新生代中建立了名为记忆集的数据结构，用于避免把整个老年代加进GC Roots扫描范围。
    事实上不止新生代、老年代，所有涉及部分区域收集行为的垃圾收集器，如G1、ZGC、Shenandoah等都会面临相同问题。    </code></pre><p>JVM常用参数</p>
<p>-Xms：初始内存大小，默认为物理内存1/64  等价于-XX：InitialHeapSize<br>-Xmx：最大分配内存，默认为物理内存1/4 等价于 -XX：MaxHeapSize<br>-Xss：设置单个线程栈的大小，一般默认为512k~1024k 等价于 -XX：ThreadStackSize</p>
]]></content>
  </entry>
  <entry>
    <title>Java中的锁</title>
    <url>/2020/05/31/Java%E4%B8%AD%E7%9A%84%E9%94%81/</url>
    <content><![CDATA[<h1 id="Java中的锁"><a href="#Java中的锁" class="headerlink" title="Java中的锁"></a>Java中的锁</h1><h2 id="锁的类型"><a href="#锁的类型" class="headerlink" title="锁的类型"></a>锁的类型</h2><p>锁从宏观上分类，分为悲观锁与乐观锁。</p>
<h3 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h3><p>乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样则更新），如果失败则要重复读-比较-写的操作。</p>
<p>java中的乐观锁基本都是通过CAS操作实现的，CAS是一种更新的原子操作，比较当前值跟传入值是否一样，一样则更新，否则失败。</p>
<h3 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h3><p>悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会block直到拿到锁。java中的悲观锁就是Synchronized,AQS框架下的锁则是先尝试cas乐观锁去获取锁，获取不到，才会转换为悲观锁，如RetreenLock。</p>
<h2 id="java线程阻塞的代价"><a href="#java线程阻塞的代价" class="headerlink" title="java线程阻塞的代价"></a>java线程阻塞的代价</h2><p>java的线程是映射到操作系统原生线程之上的，如果要阻塞或唤醒一个线程就需要操作系统介入，需要在户态与核心态之间切换，这种切换会消耗大量的系统资源，因为用户态与内核态都有各自专用的内存空间，专用的寄存器等，用户态切换至内核态需要传递给许多变量、参数给内核，内核也需要保护好用户态在切换时的一些寄存器值、变量等，以便内核态调用结束后切换回用户态继续工作。</p>
<ol>
<li><p>如果线程状态切换是一个高频操作时，这将会消耗很多CPU处理时间；</p>
</li>
<li><p>如果对于那些需要同步的简单的代码块，获取锁挂起操作消耗的时间比用户代码执行的时间还要长，这种同步策略显然非常糟糕的。</p>
<p>synchronized会导致争用不到锁的线程进入阻塞状态，所以说它是java语言中一个重量级的同步操纵，被称为重量级锁，为了缓解上述性能问题，JVM从1.5开始，引入了轻量锁与偏向锁，默认启用了自旋锁，他们都属于乐观锁。</p>
</li>
</ol>
<h2 id="markword"><a href="#markword" class="headerlink" title="markword"></a>markword</h2><p>markword数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit，它的最后2bit是锁状态标志位，用来标记当前对象的状态，对象的所处的状态，决定了markword存储的内容，如下表所示:</p>
<table>
<thead>
<tr>
<th>状态</th>
<th>标志位</th>
<th>存储内容</th>
</tr>
</thead>
<tbody><tr>
<td>未锁定</td>
<td>01</td>
<td>对象哈希码、对象分代年龄</td>
</tr>
<tr>
<td>可偏向</td>
<td>01</td>
<td>偏向线程ID、偏向时间戳、对象分代年龄</td>
</tr>
<tr>
<td>轻量级锁定</td>
<td>00</td>
<td>指向锁记录的指针</td>
</tr>
<tr>
<td>膨胀(重量级锁定)</td>
<td>10</td>
<td>执行重量级锁定的指针</td>
</tr>
<tr>
<td>GC标记</td>
<td>11</td>
<td>空(不需要记录信息)</td>
</tr>
</tbody></table>
<h2 id="Java中的锁-1"><a href="#Java中的锁-1" class="headerlink" title="Java中的锁"></a>Java中的锁</h2><p>无锁—–&gt;偏向锁—–&gt;轻量级锁—–&gt;自旋锁（过渡态）—–&gt;重量级锁</p>
<h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><ol>
<li><p>检查对象头中markWord标志位是否01 可偏向</p>
</li>
<li><p>是则判断线程id是否指向当前线程，若是则执行同步代码。否则CAS获取锁，获取成功执行同步代码，失败表示有竞争，当达到全局安全点时获取偏向锁的线程会挂起 偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续向下执行同步代码（会STW）</p>
<p>适用场景：始终只有一个线程执行同步块，执行期间一旦有竞争就升级为轻量级锁同时撤销偏向锁（会STW），有锁竞争时关闭偏向锁</p>
</li>
</ol>
<h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><pre><code>1. 拷贝锁对象MarWord到LockRecord，使用CAS尝试将对象的MarkWord更新为指向LockRecord的指针，并将LockRecord的owner指向对象的MarkWord,更新成功则表示拥有该对象锁，并将MarkWord标志位设为轻量级锁00 ，更新失败就检查对象MarkWord是否指向当前线程栈帧，是就说明已有当前对象的锁，否则说明多个线程竞争锁，膨胀为重量级锁标志位改为10 后面等待锁的线程也会进入阻塞状态，当前线程自旋来获取锁</code></pre><h3 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h3><pre><code>1. 尝试获取锁的线程在没有获取锁的时候，去执行一个空循环，即自旋，若干次自旋后还没获取到锁，才被挂起，获取到则执行同步代码</code></pre><h2 id="Synchronized的执行过程"><a href="#Synchronized的执行过程" class="headerlink" title="Synchronized的执行过程"></a>Synchronized的执行过程</h2><pre><code>1. 检测MarkWord是否是当前线程ID，是则处于偏向锁
 2. 不是则CAS将当前线程ID替换为MarkWord，成功则获得偏向锁，失败则表明有竞争，升级为轻量级锁
 3. 当前线程使用CAS将MarkWord替换为锁记录指针，成功则获取到锁，失败表示其他线程竞争锁，当前线程尝试用自旋来获取锁
 4. 自旋成功依然处于轻量级状态，失败则膨胀为重量级锁</code></pre><p>以上几种锁都是JVM的内部实现</p>
<h2 id="锁优化"><a href="#锁优化" class="headerlink" title="锁优化"></a>锁优化</h2><pre><code>1. 减少锁的时间：不需同步的代码块，能不放在同步块就不要放在同步块
 2. 减少锁的粒度：用空间换时间，例如JAVA8之前的ConcurrenthashMap中的分段锁
 3. 锁粗化：循环内的操作需加锁，则应将锁放到循环外
 4. 使用读写锁：ReentrantReadWriteLock  读加锁并发读，写加锁单线程写
 5. 读写分离：CopyOnWriteArrayList 读多写少， 读不加锁，写加锁
 6. 使用CAS：使用volatile + cas  并发少的情况用
 7. 清楚缓存行的伪共享：32位和64位操作系统缓存32bit/64bit缓存行，可能缓存行中包含除所需同步数据外的其他数据，由于被加锁，其他数据访问时也需经历阻塞获取锁等过程，JDK1.8通过加Contended注解（需在jvm添加-XX：-RestrictContended）</code></pre><p>​    </p>
]]></content>
  </entry>
  <entry>
    <title>Java8 Stream</title>
    <url>/2020/05/01/Java8%20Stream/</url>
    <content><![CDATA[<h2 id="Lambda表达式基本语法"><a href="#Lambda表达式基本语法" class="headerlink" title="Lambda表达式基本语法"></a>Lambda表达式基本语法</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> java8_01.Stream;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"><span class="keyword">import</span> java.util.Comparator;</span><br><span class="line"><span class="keyword">import</span> java.util.TreeSet;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *   Lambda表达式基本语法：</span></span><br><span class="line"><span class="comment"> *          parameters -&gt; expression</span></span><br><span class="line"><span class="comment"> *  一、 无参  无返回值</span></span><br><span class="line"><span class="comment"> *       () -&gt; System.out.println("Hello Lambda");</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  二、 有参  无返回值</span></span><br><span class="line"><span class="comment"> *       x -&gt; System.out.println(x);</span></span><br><span class="line"><span class="comment"> *       (x,y) -&gt; System.out.println(x +y);</span></span><br><span class="line"><span class="comment"> *  三、 有参  有返回值 Lambda体有多条语句</span></span><br><span class="line"><span class="comment"> *       (x,y) -&gt; &#123;System.out.println(x +y); return x+y;&#125;</span></span><br><span class="line"><span class="comment"> *       若Lambda体只有一条语句可省略&#123;&#125;和return</span></span><br><span class="line"><span class="comment"> *       (x,y) -&gt; x+y</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  Java8 内置四大核心函数式接口</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  Consumer&lt;T&gt;: 消费型接口</span></span><br><span class="line"><span class="comment"> *      void accept(T t);</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  Supplier&lt;T&gt;: 供给型接口</span></span><br><span class="line"><span class="comment"> *      T get();</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  Function&lt;T,R&gt;: 函数型接口</span></span><br><span class="line"><span class="comment"> *      R apply(T t);</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  Predicate&lt;T&gt;: 断言型接口</span></span><br><span class="line"><span class="comment"> *      boolean test(T t);</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  方法引用：若Lambda体中内容有方法已经实现，可以使用方法引用</span></span><br><span class="line"><span class="comment"> *  主要有三种语法格式：</span></span><br><span class="line"><span class="comment"> *      对象::实例方法名</span></span><br><span class="line"><span class="comment"> *      类::静态方法名</span></span><br><span class="line"><span class="comment"> *      类::实例方法名</span></span><br><span class="line"><span class="comment"> *  注意：</span></span><br><span class="line"><span class="comment"> *      ①Lambda体中调用方法的参数列表和返回值类型要与函数式接口中参数列表和返回值类型保持一致</span></span><br><span class="line"><span class="comment"> *      ②若Lambda参数列表中第一参数是方法调用者，第二参数是实例方法的参数，可以使用ClassName::method</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  构造器引用： ClassName::new</span></span><br><span class="line"><span class="comment"> *      需要调用的构造器参数列表与函数式接口中抽象方法参数列表保持一致</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  数组引用：Type[]::new</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestLambda</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test1</span><span class="params">()</span></span>&#123;</span><br><span class="line">        Comparator&lt;Integer&gt; com = <span class="keyword">new</span> Comparator&lt;Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Integer o1, Integer o2)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> Integer.compare(o1,o2);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        TreeSet&lt;Integer&gt; tree =<span class="keyword">new</span> TreeSet&lt;&gt;(com);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Lambda表达式</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test2</span><span class="params">()</span></span>&#123;</span><br><span class="line">        TreeSet&lt;Integer&gt; tree = <span class="keyword">new</span> TreeSet&lt;&gt;((x,y) -&gt; Integer.compare(x,y));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Stream流式操作"><a href="#Stream流式操作" class="headerlink" title="Stream流式操作"></a>Stream流式操作</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> java8_01.Stream;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">import</span> java.util.stream.Collectors;</span><br><span class="line"><span class="keyword">import</span> java.util.stream.Stream;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Stream的三个步骤</span></span><br><span class="line"><span class="comment"> * 1、创建Stream</span></span><br><span class="line"><span class="comment"> * 2、中间操作</span></span><br><span class="line"><span class="comment"> * 3、终止操作</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StreamDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 一、创建Stream</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test1</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">//1、通过Collection系列集合提供的stream()或parallelStream()</span></span><br><span class="line">        List&lt;String&gt; list=<span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        Stream&lt;String&gt; stream = list.stream();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2、通过Arrays中的静态方法stream()获取数组流</span></span><br><span class="line">        User[] users=<span class="keyword">new</span> User[<span class="number">10</span>];</span><br><span class="line">        Stream&lt;User&gt; stream1 = Arrays.stream(users);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3、通过Stream中的静态方法of()</span></span><br><span class="line">        Stream&lt;String&gt; ss = Stream.of(<span class="string">"aa"</span>, <span class="string">"bb"</span>, <span class="string">"cc"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4、创建无限流</span></span><br><span class="line">        <span class="comment">//迭代</span></span><br><span class="line">        Stream.iterate(<span class="number">0</span>,x -&gt; x+<span class="number">2</span>).limit(<span class="number">10</span>).forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//生成</span></span><br><span class="line">        Stream.generate(() -&gt; Math.random()).limit(<span class="number">5</span>).forEach(System.out::println);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 二、中间操作</span></span><br><span class="line"><span class="comment">     * 筛选与切片</span></span><br><span class="line"><span class="comment">     * filter--接收Lambda  从流中过滤某些元素</span></span><br><span class="line"><span class="comment">     * limit--截断流，使其元素不超过给定数量</span></span><br><span class="line"><span class="comment">     * skip(n)--跳过元素，返回一个跳过了前n个元素的流，若流中元素不足n个，则返回一个空流</span></span><br><span class="line"><span class="comment">     * distinct--通过流中元素的hashCode和equals去重元素</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * filter</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span>  <span class="title">test2</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        List&lt;User&gt; userList = User.getUserList();</span><br><span class="line">        <span class="comment">//中间操作</span></span><br><span class="line">        <span class="comment">//中间操作不会执行任何操作，只有执行终止操作，中间操作才会被全部执行 “惰性求值”</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 内部迭代:迭代操作由StreamAPI完成</span></span><br><span class="line"><span class="comment">         * 这里 “Stream的中间操作” 会输出userList.size()次</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        Stream&lt;User&gt; userStream = userList.stream().filter(e -&gt;</span><br><span class="line">        &#123;</span><br><span class="line">            System.out.println(<span class="string">"Stream的中间操作"</span>);</span><br><span class="line">            <span class="keyword">return</span> e.getAge() &gt; <span class="number">30</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//终止操作  一次性执行全部内容</span></span><br><span class="line">        userStream.forEach(System.out::println);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * limit</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test3</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 这里 “断路” 不一定会输出userList.size()次 找到两条符合条件记录就不会再遍历</span></span><br><span class="line"><span class="comment">         * 短路操作</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        List&lt;User&gt; userList = User.getUserList();</span><br><span class="line">        userList.stream().filter(e -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">"短路"</span>);</span><br><span class="line">            <span class="keyword">return</span> e.getAge() &gt; <span class="number">22</span>;</span><br><span class="line">        &#125;).limit(<span class="number">2</span>).forEach(System.out::println);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * skip</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test4</span><span class="params">()</span></span>&#123;</span><br><span class="line">        List&lt;User&gt; userList = User.getUserList();</span><br><span class="line">        <span class="comment">//满足filter条件的结果集跳过两个元素后输出</span></span><br><span class="line">        userList.stream().filter(e -&gt; e.getAge() &gt; <span class="number">20</span>).skip(<span class="number">2</span>).forEach(System.out::println);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * distinct</span></span><br><span class="line"><span class="comment">     * 注意：distinct 是通过流中元素的hashCode和equals去重元素，必要时需重写hashCode和equals</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test5</span><span class="params">()</span></span>&#123;</span><br><span class="line">        List&lt;User&gt; userList = User.getUserList();</span><br><span class="line">        userList.stream().distinct().forEach(System.out::println);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 映射</span></span><br><span class="line"><span class="comment">     * map--接受Lambda，将元素转换为其他形式或提取信息。</span></span><br><span class="line"><span class="comment">     *      接收一个函数作为参数，该函数会被应用到每个元素上，并将其映射为一个新元素</span></span><br><span class="line"><span class="comment">     * flatMap--接收一个函数作为参数，将流中每个值都换成另一个流，然后把所有流连接成一个流</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test6</span><span class="params">()</span></span>&#123;</span><br><span class="line">        List&lt;String&gt; list = Arrays.asList(<span class="string">"aaa"</span>, <span class="string">"bbb"</span>, <span class="string">"ccc"</span>, <span class="string">"ddd"</span>, <span class="string">"eee"</span>);</span><br><span class="line">        list.stream().map((str) -&gt; str.toUpperCase()).forEach(System.out::println);</span><br><span class="line">        System.out.println(<span class="string">"----------------------------"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*Stream&lt;Stream&lt;Character&gt;&gt; streamStream = list.stream().map(StreamDemo::filterCharacter);</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">        streamStream.forEach(sm -&gt; &#123;sm.forEach(System.out::println);&#125;);*/</span></span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"----------------------------"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//flatMap</span></span><br><span class="line">        Stream&lt;Character&gt; characterStream = list.stream().flatMap(StreamDemo::filterCharacter);</span><br><span class="line">        characterStream.forEach(System.out::println);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Stream&lt;Character&gt; <span class="title">filterCharacter</span><span class="params">(String str)</span></span>&#123;</span><br><span class="line">        List&lt;Character&gt; list =<span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(Character ch:str.toCharArray())&#123;</span><br><span class="line">                list.add(ch);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> list.stream();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 排序</span></span><br><span class="line"><span class="comment">     * sorted--自然排序（comparable）</span></span><br><span class="line"><span class="comment">     * sorted（comparator）--定制排序（Comparator）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sortTest</span><span class="params">()</span></span>&#123;</span><br><span class="line">        List&lt;String&gt; list = Arrays.asList(<span class="string">"ccc"</span>, <span class="string">"aaa"</span>, <span class="string">"abc"</span>, <span class="string">"cbd"</span>);</span><br><span class="line">        list.stream().sorted().forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------"</span>);</span><br><span class="line"></span><br><span class="line">        List&lt;User&gt; userList = User.getUserList();</span><br><span class="line">        userList.stream().sorted((e1,e2) -&gt;</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(e1.getAge()==e2.getAge())&#123;</span><br><span class="line">                <span class="keyword">return</span> e1.getName().compareTo(e2.getName());</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">return</span>  e1.getAge() - e2.getAge();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;).forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 终止操作</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line"></span><br><span class="line">     <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *查找与匹配</span></span><br><span class="line"><span class="comment">     * allMatch--检查是否匹配所有元素</span></span><br><span class="line"><span class="comment">     * anyMatch--检查是否至少匹配一个元素</span></span><br><span class="line"><span class="comment">     * noneMatch--检查是否没有匹配所有元素</span></span><br><span class="line"><span class="comment">     * findFirst--返回第一个元素</span></span><br><span class="line"><span class="comment">     * findAny--返回当前流中任意元素</span></span><br><span class="line"><span class="comment">     * count--返回流中元素总个数</span></span><br><span class="line"><span class="comment">     * max--返回流中最大值</span></span><br><span class="line"><span class="comment">     * min--返回流中最小值</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span></span>&#123;</span><br><span class="line">        List&lt;User&gt; users = Arrays.asList(</span><br><span class="line">                <span class="keyword">new</span> User(<span class="string">"001"</span>, <span class="number">38</span>, User.Status.VOCATION),</span><br><span class="line">                <span class="keyword">new</span> User(<span class="string">"003"</span>, <span class="number">20</span>, User.Status.BUSY),</span><br><span class="line">                <span class="keyword">new</span> User(<span class="string">"005"</span>, <span class="number">18</span>, User.Status.FREE),</span><br><span class="line">                <span class="keyword">new</span> User(<span class="string">"004"</span>, <span class="number">35</span>, User.Status.BUSY),</span><br><span class="line">                <span class="keyword">new</span> User(<span class="string">"002"</span>, <span class="number">27</span>, User.Status.FREE)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="keyword">boolean</span> b1 = users.stream().allMatch(e -&gt; e.getStatus().equals(User.Status.BUSY));</span><br><span class="line">        System.out.println(b1);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">boolean</span> b2 = users.stream().anyMatch(e -&gt; e.getStatus().equals(User.Status.BUSY));</span><br><span class="line">        System.out.println(b2);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">boolean</span> b3 = users.stream().noneMatch(e -&gt; e.getStatus().equals(User.Status.BUSY));</span><br><span class="line">        System.out.println(b3);</span><br><span class="line"></span><br><span class="line">        Optional&lt;User&gt; first = users.stream().sorted((e1, e2) -&gt; Integer.compare(e1.getAge(), e2.getAge()))</span><br><span class="line">                .findFirst();</span><br><span class="line">        System.out.println(first.get());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//parallelStream  并行</span></span><br><span class="line">        Optional&lt;User&gt; any = users.parallelStream().filter(e -&gt; e.getStatus().equals(User.Status.FREE))</span><br><span class="line">                .findAny();</span><br><span class="line">        System.out.println(any.get());</span><br><span class="line"></span><br><span class="line">        System.out.println(users.stream().count());</span><br><span class="line"></span><br><span class="line">        Optional&lt;User&gt; max = users.stream().max((e1, e2) -&gt; Integer.compare(e1.getAge(), e2.getAge()));</span><br><span class="line">        System.out.println(max.get());</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 归约</span></span><br><span class="line"><span class="comment">     * reduce(T,BinaryOperator) / reduce(BinaryOperator)  可将流中元素反复结合起来，得到一个值</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduceTest</span><span class="params">()</span></span>&#123;</span><br><span class="line">        List&lt;Integer&gt; list = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>);</span><br><span class="line">        Integer sum = list.stream().reduce(<span class="number">0</span>, (x, y) -&gt; x + y);</span><br><span class="line">        System.out.println(sum);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 收集</span></span><br><span class="line"><span class="comment">     * collect--将流转换为其他形式，接收一个Collect接口的实现 用于给Stream中元素做汇总的方法</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">collectTest</span><span class="params">()</span></span>&#123;</span><br><span class="line">        List&lt;User&gt; users = Arrays.asList(</span><br><span class="line">                <span class="keyword">new</span> User(<span class="string">"001"</span>, <span class="number">38</span>, User.Status.VOCATION),</span><br><span class="line">                <span class="keyword">new</span> User(<span class="string">"003"</span>, <span class="number">20</span>, User.Status.BUSY),</span><br><span class="line">                <span class="keyword">new</span> User(<span class="string">"005"</span>, <span class="number">18</span>, User.Status.FREE),</span><br><span class="line">                <span class="keyword">new</span> User(<span class="string">"004"</span>, <span class="number">35</span>, User.Status.BUSY),</span><br><span class="line">                <span class="keyword">new</span> User(<span class="string">"002"</span>, <span class="number">27</span>, User.Status.FREE)</span><br><span class="line">        );</span><br><span class="line">        users.stream().map(User::getName).collect(Collectors.toList()).forEach(System.out::println);</span><br><span class="line">        users.stream().map(User::getName).collect(Collectors.toSet()).forEach(System.out::println);</span><br><span class="line">        users.stream().map(User::getName).collect(Collectors.toCollection(HashSet::<span class="keyword">new</span>)).forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="并行流"><a href="#并行流" class="headerlink" title="并行流"></a>并行流</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> java8_01.parallelStream;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.RecursiveTask;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ForkJoinCaculate</span> <span class="keyword">extends</span> <span class="title">RecursiveTask</span>&lt;<span class="title">Long</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> start;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> end;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> THRESHOLD=<span class="number">10000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ForkJoinCaculate</span><span class="params">(<span class="keyword">long</span> start, <span class="keyword">long</span> end)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.start = start;</span><br><span class="line">        <span class="keyword">this</span>.end = end;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> Long <span class="title">compute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> length=end -start;</span><br><span class="line">        <span class="keyword">if</span>(length&lt;=THRESHOLD)&#123;</span><br><span class="line">            <span class="keyword">long</span> sum=<span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">long</span> i=start;i&lt;=end;i++)&#123;</span><br><span class="line">                sum+=i;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> sum;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">long</span> middle = (start + end) /<span class="number">2</span>;</span><br><span class="line">            ForkJoinCaculate left=<span class="keyword">new</span> ForkJoinCaculate(start,middle);</span><br><span class="line">            left.fork();</span><br><span class="line"></span><br><span class="line">            ForkJoinCaculate right=<span class="keyword">new</span> ForkJoinCaculate(middle+<span class="number">1</span>,end);</span><br><span class="line">            right.fork();</span><br><span class="line">            <span class="keyword">return</span> left.join() + right.join();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> java8_01.parallelStream;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.time.Instant;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ForkJoinPool;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ForkJoinTask;</span><br><span class="line"><span class="keyword">import</span> java.util.stream.LongStream;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestForkJoin</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test1</span><span class="params">()</span></span>&#123;</span><br><span class="line">        Instant start = Instant.now();</span><br><span class="line"></span><br><span class="line">        ForkJoinPool pool=<span class="keyword">new</span> ForkJoinPool();</span><br><span class="line">        ForkJoinTask&lt;Long&gt; task=<span class="keyword">new</span> ForkJoinCaculate(<span class="number">0</span>,<span class="number">100000000000L</span>);</span><br><span class="line">        Long sum=pool.invoke(task);</span><br><span class="line">        System.out.println(sum);</span><br><span class="line"></span><br><span class="line">        Instant end = Instant.now();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"耗时（ms）："</span>+ Duration.between(start,end).toMillis());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test2</span><span class="params">()</span></span>&#123;</span><br><span class="line">        Instant start = Instant.now();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> sum=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">long</span> i=<span class="number">0</span>;i&lt;=<span class="number">100000000000L</span>;i++)&#123;</span><br><span class="line">            sum+=i;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sum);</span><br><span class="line">        Instant end = Instant.now();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"耗时（ms）："</span>+ Duration.between(start,end).toMillis());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Java8并行流</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test3</span><span class="params">()</span></span>&#123;</span><br><span class="line">        Instant start = Instant.now();</span><br><span class="line"></span><br><span class="line">        LongStream.rangeClosed(<span class="number">0</span>,<span class="number">100000000000L</span>)</span><br><span class="line">                .parallel()</span><br><span class="line">                .reduce(<span class="number">0</span>,Long::sum);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//System.out.println(sum);</span></span><br><span class="line">        Instant end = Instant.now();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"耗时（ms）："</span>+ Duration.between(start,end).toMillis());</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Java8日期API"><a href="#Java8日期API" class="headerlink" title="Java8日期API"></a>Java8日期API</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> java8_01.optional;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"><span class="keyword">import</span> java.text.DateFormat;</span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">import</span> java.time.*;</span><br><span class="line"><span class="keyword">import</span> java.time.format.DateTimeFormatter;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestSimpleDateFormat</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test1</span><span class="params">()</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line">        SimpleDateFormat dateFormat=<span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyyMMdd"</span>);</span><br><span class="line"></span><br><span class="line">        Callable&lt;Date&gt; task=<span class="keyword">new</span> Callable&lt;Date&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Date <span class="title">call</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> dateFormat.parse(<span class="string">"20200425"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        ExecutorService pool = Executors.newFixedThreadPool(<span class="number">10</span>);</span><br><span class="line">        List&lt;Future&gt; results = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">            results.add(pool.submit(task));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(Future&lt;Date&gt; future: results)&#123;</span><br><span class="line">            System.out.println(future.get());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        pool.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test2</span><span class="params">()</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">       ThreadLocal&lt;DateFormat&gt; df = <span class="keyword">new</span> ThreadLocal&lt;DateFormat&gt;()&#123;</span><br><span class="line">           <span class="function"><span class="keyword">protected</span> DateFormat <span class="title">initialValue</span><span class="params">()</span></span>&#123;</span><br><span class="line">               <span class="keyword">return</span> <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyyMMdd"</span>);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;;</span><br><span class="line"></span><br><span class="line">        Callable&lt;Date&gt; task=<span class="keyword">new</span> Callable&lt;Date&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Date <span class="title">call</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> df.get().parse(<span class="string">"20200425"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        ExecutorService pool = Executors.newFixedThreadPool(<span class="number">10</span>);</span><br><span class="line">        List&lt;Future&gt; results = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">            results.add(pool.submit(task));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(Future&lt;Date&gt; future: results)&#123;</span><br><span class="line">            System.out.println(future.get());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        pool.shutdown();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test3</span><span class="params">()</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line">        DateTimeFormatter dtf=DateTimeFormatter.ofPattern(<span class="string">"yyyyMMdd"</span>);</span><br><span class="line"></span><br><span class="line">        Callable&lt;LocalDate&gt; task=<span class="keyword">new</span> Callable&lt;LocalDate&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> LocalDate <span class="title">call</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> LocalDate.parse(<span class="string">"20200425"</span>,dtf);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        ExecutorService pool = Executors.newFixedThreadPool(<span class="number">10</span>);</span><br><span class="line">        List&lt;Future&gt; results = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">            results.add(pool.submit(task));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(Future&lt;Date&gt; future: results)&#123;</span><br><span class="line">            System.out.println(future.get());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        pool.shutdown();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test4</span><span class="params">()</span></span>&#123;</span><br><span class="line">        LocalDateTime ldt =LocalDateTime.now();</span><br><span class="line">        System.out.println(ldt);</span><br><span class="line"></span><br><span class="line">        LocalDateTime ldt2 =LocalDateTime.of(<span class="number">2020</span>,<span class="number">04</span>,<span class="number">25</span>,<span class="number">23</span>,<span class="number">00</span>,<span class="number">18</span>);</span><br><span class="line">        System.out.println(ldt2);</span><br><span class="line"></span><br><span class="line">        LocalDateTime ldt3 =ldt2.plusYears(<span class="number">2</span>);</span><br><span class="line">        System.out.println(ldt3);</span><br><span class="line"></span><br><span class="line">        LocalDateTime ldt4 =ldt2.minusMonths(<span class="number">2</span>);</span><br><span class="line">        System.out.println(ldt4);</span><br><span class="line"></span><br><span class="line">        System.out.println(ldt2.getYear());</span><br><span class="line">        System.out.println(ldt2.getMonthValue());</span><br><span class="line">        System.out.println(ldt2.getDayOfMonth());</span><br><span class="line">        System.out.println(ldt2.getMinute());</span><br><span class="line">        System.out.println(ldt2.getSecond());</span><br><span class="line"></span><br><span class="line">        System.out.println(LocalDateTime.parse(<span class="string">"2020-04-25T23:00:18"</span>).</span><br><span class="line">                format(DateTimeFormatter.ofPattern(<span class="string">"yyyyMMdd"</span>)));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test5</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        Instant in1=Instant.now();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">        &#125;<span class="keyword">catch</span>(InterruptedException e)&#123;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Instant in2=Instant.now();</span><br><span class="line">        Duration duration =Duration.between(in1,in2);</span><br><span class="line">        System.out.println(duration.toMillis());</span><br><span class="line"></span><br><span class="line">        LocalDate ld1=LocalDate.of(<span class="number">2018</span>,<span class="number">07</span>,<span class="number">01</span>);</span><br><span class="line">        LocalDate ld2=LocalDate.now();</span><br><span class="line"></span><br><span class="line">        Period p=Period.between(ld1,ld2);</span><br><span class="line"></span><br><span class="line">        System.out.println(p);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test6</span><span class="params">()</span></span>&#123;</span><br><span class="line">        Instant instant =Instant.now();</span><br><span class="line">        LocalDateTime ld=LocalDateTime.ofInstant(instant,ZoneId.of(<span class="string">"Asia/Shanghai"</span>));</span><br><span class="line">        System.out.println(ld);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
  </entry>
  <entry>
    <title>Spring事务</title>
    <url>/2020/04/07/Spring%E4%BA%8B%E5%8A%A1/</url>
    <content><![CDATA[<a id="more"></a>

<h2 style="margin-left:0cm;"> </h2>

<h2 style="margin-left:0cm;"><strong>一、数据库的事物的基本特性</strong></h2>

<div>
<p style="margin-left:0cm;">事物是区分文件存储系统与Nosql数据库重要特性之一，其存在的意义是为了保证即使在并发情况下也能正确的执行crud操作。怎样才算是正确的呢？这时提出了事物需要保证的四个特性即ACID：</p>
</div>

<ol><li>A: 原子性(atomicity)
    <ul><li><span style="color:#a5a5a5;">事物中各项操作，要么全做要么全不做，任何一项操作的失败都会导致整个事物的失败；</span></li>
    </ul></li>
    <li>C: 一致性(consistency)
    <ul><li><span style="color:#a5a5a5;">事物结束后系统状态是一致的；</span></li>
    </ul></li>
    <li>I:  隔离性(isolation)
    <ul><li><span style="color:#a5a5a5;">并发执行的事物彼此无法看到对方的中间状态；</span></li>
    </ul></li>
    <li>D: 持久性(durability)
    <ul><li><span style="color:#a5a5a5;">事物完成后所做的改动都会被持久化，即使发生灾难性的失败。</span></li>
    </ul></li>
</ol><p style="margin-left:0cm;">在高并发的情况下，要完全保证其ACID特性是非常困难的，除非把所有的事物串行化执行，但带来的负面的影响将是性能大打折扣。很多时候我们有些业务对事物的要求是不一样的，所以数据库中设计了四种隔离级别，供用户基于业务进行选择。</p>

<table border="1" cellspacing="0" style="margin-left:.5pt;width:412.7pt;"><tbody><tr><td style="width:113.9pt;">
            <p style="margin-left:0cm;"><strong><span style="color:#4f4f4f;">隔离级别</span></strong></p>
            </td>
            <td style="width:77.05pt;">
            <p style="margin-left:0cm;"><strong><span style="color:#4f4f4f;">脏读（Dirty Read）</span></strong></p>
            </td>
            <td style="width:131.3pt;">
            <p style="margin-left:0cm;"><strong><span style="color:#4f4f4f;">不可重复读（NonRepeatable Read）</span></strong></p>
            </td>
            <td style="width:90.45pt;">
            <p style="margin-left:0cm;"><strong><span style="color:#4f4f4f;">幻读（Phantom Read）</span></strong></p>
            </td>
        </tr><tr><td style="width:113.9pt;">
            <p style="margin-left:0cm;"><span style="color:#4f4f4f;">未提交读（Read uncommitted）</span></p>
            </td>
            <td style="width:77.05pt;">
            <p style="margin-left:0cm;"><span style="color:#ff0000;">可能</span></p>
            </td>
            <td style="width:131.3pt;">
            <p style="margin-left:0cm;"><span style="color:#ff0000;">可能</span></p>
            </td>
            <td style="width:90.45pt;">
            <p style="margin-left:0cm;"><span style="color:#ff0000;">可能</span></p>
            </td>
        </tr><tr><td style="width:113.9pt;">
            <p style="margin-left:0cm;"><span style="color:#4f4f4f;">已提交读（Read committed）</span></p>
            </td>
            <td style="width:77.05pt;">
            <p style="margin-left:0cm;"><span style="color:#1c7231;">不可能</span></p>
            </td>
            <td style="width:131.3pt;">
            <p style="margin-left:0cm;"><span style="color:#ff0000;">可能</span></p>
            </td>
            <td style="width:90.45pt;">
            <p style="margin-left:0cm;"><span style="color:#ff0000;">可能</span></p>
            </td>
        </tr><tr><td style="width:113.9pt;">
            <p style="margin-left:0cm;"><span style="color:#4f4f4f;">可重复读（Repeatable read）</span></p>
            </td>
            <td style="width:77.05pt;">
            <p style="margin-left:0cm;"><span style="color:#1c7231;">不可能</span></p>
            </td>
            <td style="width:131.3pt;">
            <p style="margin-left:0cm;"><span style="color:#1c7231;">不可能</span></p>
            </td>
            <td style="width:90.45pt;">
            <p style="margin-left:0cm;"><span style="color:#ff0000;">可能</span></p>
            </td>
        </tr><tr><td style="width:113.9pt;">
            <p style="margin-left:0cm;"><span style="color:#4f4f4f;">可串行化（SERIALIZABLE）</span></p>
            </td>
            <td style="width:77.05pt;">
            <p style="margin-left:0cm;"><span style="color:#1c7231;">不可能</span></p>
            </td>
            <td style="width:131.3pt;">
            <p style="margin-left:0cm;"><span style="color:#1c7231;">不可能</span></p>
            </td>
            <td style="width:90.45pt;">
            <p style="margin-left:0cm;"><span style="color:#1c7231;">不可能</span></p>
            </td>
        </tr></tbody></table><p> </p>

<p style="margin-left:0cm;"><strong>脏读 :</strong></p>

<p style="margin-left:0cm;"><span style="color:#a5a5a5;">一个事物读取到另一事物未提交的更新数据</span></p>

<p style="margin-left:0cm;"><strong>不可重复读 : </strong></p>

<p style="margin-left:0cm;"><span style="color:#a5a5a5;">在同一事物中,多次读取同一数据返回的结果有所不同, 换句话说, 后续读取可以读到另一事物已提交的更新数据. 相反, “可重复读”在同一事物中多次读取数据时, 能够保证所读数据一样, 也就是后续读取不能读到另一事物已提交的更新数据。</span></p>

<p style="margin-left:0cm;"><strong>幻读 :</strong></p>

<p style="margin-left:0cm;"><span style="color:#a5a5a5;">在同一事物中,多次读取同一表数据条数返回的结果有所不同,</span></p>

<p style="margin-left:0cm;"> <span style="color:#a5a5a5;">查询表中一条数据如果不存在就插入一条，并发的时候却发现，里面居然有两条相同的数据。这就幻读的问题。</span></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><strong>数据库默认隔离级别：</strong></p>

<p style="margin-left:0cm;">Oracle中默认级别是 Read committed</p>

<p style="margin-left:0cm;">mysql 中默认级别 Repeatable read。另外要注意的是mysql 执行一条查询语句默认是一个独立的事物，所以看上去效果跟Read committed一样。</p>

<p style="margin-left:0cm;"># 查看mysql 的默认隔离级别</p>

<p style="margin-left:0cm;">SELECT @@tx_isolation</p>

<p style="margin-left:0cm;"> </p>

<div>
<h2 style="margin-left:0cm;"><strong>二、Sring 对事物的支持与使用</strong></h2>

<p style="margin-left:0cm;"><strong>1、spring 事物相关API说明</strong></p>

<p style="margin-left:0cm;">spring 事物是在数据库事物的基础上进行封装扩展 其主要特性如下：</p>

<ol><li>
    <ol><li>支持原有的数据事物的隔离级别</li>
        <li>加入了事物传播的概念 提供多个事物的和并或隔离的功能</li>
        <li>提供声明式事物，让业务代码与事物分离，事物变得更易用。</li>
    </ol></li>
</ol><p style="margin-left:0cm;">怎么样去使用Spring事物呢？spring 提供了三个接口供使用事物。分别是：</p>

<p style="margin-left:0cm;"> </p>

<ol><li>TransactionDefinition
    <ul><li><span style="color:#a5a5a5;">事物定义</span></li>
    </ul></li>
    <li>PlatformTransactionManager
    <ul><li><span style="color:#a5a5a5;">事物管理</span></li>
    </ul></li>
    <li>TransactionStatus
    <ul><li><span style="color:#a5a5a5;">事物运行时状态</span></li>
    </ul></li>
</ol><p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><strong>接口结构图：</strong></p>

<p style="margin-left:0cm;"><img alt height="241" src="https://img-blog.csdnimg.cn/2020040722121591.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzQ0Njk1,size_16,color_FFFFFF,t_70" width="547"></p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><strong>API说明：</strong></p>

<pre>
<code class="language-java">public class SpringTransactionExample {
    private static String url = "jdbc:mysql://192.168.0.147:3306/test";
    private static String user = "root";
    private static String password = "123456";

    public static Connection openConnection() throws ClassNotFoundException, SQLException {
        Class.forName("com.mysql.jdbc.Driver");
        Connection conn = DriverManager.getConnection("jdbc:mysql://192.168.0.147:3306/test", "root", "123456");
        return conn;
    }

    public static void main(String[] args) {
        final DataSource ds = new DriverManagerDataSource(url, user, password);
        final TransactionTemplate template = new TransactionTemplate();
        template.setTransactionManager(new DataSourceTransactionManager(ds));
        template.execute(new TransactionCallback&lt;Object&gt;() {
            @Override
            public Object doInTransaction(TransactionStatus status) {
                Connection conn = DataSourceUtils.getConnection(ds);
                Object savePoint = null;
                try {
                    {
                        // 插入
                        PreparedStatement prepare = conn.
                                prepareStatement("insert INTO account (accountName,user,money) VALUES (?,?,?)");
                        prepare.setString(1, "111");
                        prepare.setString(2, "aaaa");
                        prepare.setInt(3, 10000);
                        prepare.executeUpdate();
                    }
                    // 设置保存点
                    savePoint = status.createSavepoint();
                    {
                        // 插入
                        PreparedStatement prepare = conn.
                                prepareStatement("insert INTO account (accountName,user,money) VALUES (?,?,?)");
                        prepare.setString(1, "222");
                        prepare.setString(2, "bbb");
                        prepare.setInt(3, 10000);
                        prepare.executeUpdate();
                    }
                    {
                        // 更新
                        PreparedStatement prepare = conn.
                                prepareStatement("UPDATE account SET money= money+1 where user=?");
                        prepare.setString(1, "asdflkjaf");
                        Assert.isTrue(prepare.executeUpdate() &gt; 0, "");
                    }
                } catch (SQLException e) {
                    e.printStackTrace();
                } catch (Exception e) {
                    System.out.println("更新失败");
                    if (savePoint != null) {
                        status.rollbackToSavepoint(savePoint);
                    } else {
                        status.setRollbackOnly();
                    }
                }
                return null;
            }
        });
    }
}
</code></pre>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"><strong>2、声明示事物</strong></p>

<p style="margin-left:0cm;">我们前面是通过调用API来实现对事物的控制，这非常的繁琐，与直接操作JDBC事物并没有太多的改善，所以Spring提出了声明示事物，使我们对事物的操作变得非常简单，甚至不需要关心它。</p>

<p style="margin-left:0cm;">配置spring.xml</p>

<pre>
<code class="language-java">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:aop="http://www.springframework.org/schema/aop"
       xmlns:tx="http://www.springframework.org/schema/tx"
       xmlns:context="http://www.springframework.org/schema/context"
       xsi:schemaLocation="
        http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans.xsd
        http://www.springframework.org/schema/tx
        http://www.springframework.org/schema/tx/spring-tx.xsd
        http://www.springframework.org/schema/context
        http://www.springframework.org/schema/context/spring-context.xsd
        http://www.springframework.org/schema/aop
        http://www.springframework.org/schema/aop/spring-aop.xsd"&gt;

    &lt;context:annotation-config/&gt;
    &lt;context:component-scan base-package="com.test.service.**"&gt;
    &lt;/context:component-scan&gt;

    &lt;bean class="org.springframework.jdbc.core.JdbcTemplate"&gt;
        &lt;property name="dataSource" ref="dataSource"/&gt;
    &lt;/bean&gt;

    &lt;!-- similarly, don't forget the PlatformTransactionManager --&gt;
    &lt;bean id="txManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt;
        &lt;property name="dataSource" ref="dataSource"/&gt;
    &lt;/bean&gt;
    &lt;!-- don't forget the DataSource --&gt;
    &lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt;
        &lt;constructor-arg name="url" value="jdbc:mysql://192.168.0.147/test"/&gt;
        &lt;constructor-arg name="username" value="root"/&gt;
        &lt;constructor-arg name="password" value="123456"/&gt;
    &lt;/bean&gt;
    &lt;tx:annotation-driven transaction-manager="txManager"&gt;&lt;/tx:annotation-driven&gt;
&lt;/beans&gt;
</code></pre>

<p style="margin-left:0cm;">编写服务类</p>

<pre>
<code class="language-java">@Transactional
public void addAccount(String name, int initMenoy) {
    String accountid = new SimpleDateFormat("yyyyMMddhhmmss").format(new Date());
    jdbcTemplate.update("insert INTO account (accountName,user,money) VALUES (?,?,?)", accountid, name, initMenoy);
    // 人为报错
    int i = 1 / 0;
}
</code></pre>

<p style="margin-left:0cm;"><strong>3、事物传播机制</strong></p>

<p style="margin-left:0cm;"> </p>

<table border="1" cellspacing="0" style="margin-left:.5pt;width:412.7pt;"><tbody><tr><td style="width:75pt;">
            <p style="margin-left:0cm;"><strong><span style="color:#ffffff;">类别</span></strong></p>
            </td>
            <td style="width:173.5pt;">
            <p style="margin-left:0cm;"><strong><span style="color:#ffffff;">事物传播类型</span></strong></p>
            </td>
            <td style="width:164.15pt;">
            <p style="margin-left:0cm;"><strong><span style="color:#ffffff;">说明</span></strong></p>
            </td>
        </tr><tr><td rowspan="3" style="width:75pt;">
            <p style="margin-left:0cm;">支持当前事物</p>
            </td>
            <td style="width:173.5pt;">
            <p style="margin-left:0cm;"><span style="color:#ff0000;">PROPAGATION_REQUIRED</span></p>

<pre><code>    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;（必须的）&lt;/span&gt;&lt;/p&gt;
    &lt;/td&gt;
    &lt;td style=&quot;width:164.15pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;如果当前没有事物，就新建一个事物，如果已经存在一个事物中，加入到这个事物中。这是最常见的选择。&lt;/span&gt;&lt;/p&gt;
    &lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width:173.5pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;PROPAGATION_SUPPORTS&lt;/span&gt;&lt;/p&gt;

    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;（支持）&lt;/span&gt;&lt;/p&gt;
    &lt;/td&gt;
    &lt;td style=&quot;width:164.15pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;支持当前事物，如果当前没有事物，就以非事物方式执行。&lt;/span&gt;&lt;/p&gt;
    &lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width:173.5pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;PROPAGATION_MANDATORY&lt;/span&gt;&lt;/p&gt;

    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;（强制）&lt;/span&gt;&lt;/p&gt;
    &lt;/td&gt;
    &lt;td style=&quot;width:164.15pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;使用当前的事物，如果当前没有事物，就抛出异常。&lt;/span&gt;&lt;/p&gt;
    &lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; style=&quot;width:75pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;不支持当前事物&lt;/p&gt;
    &lt;/td&gt;
    &lt;td style=&quot;width:173.5pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;PROPAGATION_REQUIRES_NEW&lt;/span&gt;&lt;/p&gt;

    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color:#000000;&quot;&gt;隔离)&lt;/span&gt;&lt;/p&gt;
    &lt;/td&gt;
    &lt;td style=&quot;width:164.15pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;新建事物，如果当前存在事物，把当前事物挂起。&lt;/span&gt;&lt;/p&gt;
    &lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width:173.5pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;PROPAGATION_NOT_SUPPORTED&lt;/span&gt;&lt;/p&gt;

    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color:#000000;&quot;&gt;不支持)&lt;/span&gt;&lt;/p&gt;
    &lt;/td&gt;
    &lt;td style=&quot;width:164.15pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;以非事物方式执行操作，如果当前存在事物，就把当前事物挂起。&lt;/span&gt;&lt;/p&gt;
    &lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width:173.5pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;PROPAGATION_NEVER&lt;/span&gt;&lt;/p&gt;

    &lt;p style=&quot;margin-left:0cm;&quot;&gt;(强制非事物)&lt;/p&gt;
    &lt;/td&gt;
    &lt;td style=&quot;width:164.15pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;以非事物方式执行，如果当前存在事物，则抛出异常。&lt;/span&gt;&lt;/p&gt;
    &lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width:75pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;套事物&lt;/span&gt;&lt;/p&gt;
    &lt;/td&gt;
    &lt;td style=&quot;width:173.5pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;PROPAGATION_NESTED&lt;/span&gt;&lt;/p&gt;

    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;（嵌套事物）&lt;/span&gt;&lt;/p&gt;
    &lt;/td&gt;
    &lt;td style=&quot;width:164.15pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;如果当前存在事物，则在嵌套事物内执行。如果当前没有事物，则执行与PROPAGATION_REQUIRED类似的操作。&lt;/span&gt;&lt;/p&gt;
    &lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;strong&gt;常用事物传播机制：&lt;/strong&gt;&lt;/p&gt;</code></pre><ol><li>PROPAGATION_REQUIRED，
    <ul><li><span style="color:#a5a5a5;">这个也是默认的传播机制；</span></li>
    </ul></li>
    <li>PROPAGATION_NOT_SUPPORTED
    <ul><li><span style="color:#a5a5a5;">可以用于发送提示消息，站内信、短信、邮件提示等。不属于并且不应当影响主体业务逻辑，即使发送失败也不应该对主体业务逻辑回滚。</span></li>
    </ul></li>
    <li>PROPAGATION_REQUIRES_NEW
    <ul><li><span style="color:#a5a5a5;">总是新启一个事物，这个传播机制适用于不受父方法事物影响的操作，比如某些业务场景下需要记录业务日志，用于异步反查，那么不管主体业务逻辑是否完成，日志都需要记录下来，不能因为主体业务逻辑报错而丢失日志；</span></li>
    </ul></li>
</ol><p style="margin-left:0cm;"><strong>用例1:</strong></p>

<p style="margin-left:0cm;">创建用户时初始化一个帐户，表结构和服务类如下。</p>

<table border="1" cellspacing="0" style="margin-left:.5pt;width:387.9pt;"><tbody><tr><td style="width:103.15pt;">
            <p style="margin-left:0cm;"><strong><span style="color:#ffffff;">表结构</span></strong></p>
            </td>
            <td style="width:103.15pt;">
            <p style="margin-left:0cm;"><strong><span style="color:#ffffff;">服务类</span></strong></p>
            </td>
            <td style="width:181.55pt;">
            <p style="margin-left:0cm;"><strong><span style="color:#ffffff;">功能描述</span></strong></p>
            </td>
        </tr><tr><td style="vertical-align:top;width:103.15pt;">
            <p style="margin-left:0cm;">user</p>
            </td>
            <td style="vertical-align:top;width:103.15pt;">
            <p style="margin-left:0cm;">UserSerivce</p>
            </td>
            <td style="vertical-align:top;width:181.55pt;">
            <p style="margin-left:0cm;">创建用户，并添加帐户</p>
            </td>
        </tr><tr><td style="vertical-align:top;width:103.15pt;">
            <p style="margin-left:0cm;">account</p>
            </td>
            <td style="vertical-align:top;width:103.15pt;">
            <p style="margin-left:0cm;">AccountService</p>
            </td>
            <td style="vertical-align:top;width:181.55pt;">
            <p style="margin-left:0cm;">添加帐户</p>
            </td>
        </tr></tbody></table><p style="margin-left:0cm;">UserSerivce.createUser(name) 实现代码</p>

<pre>
<code class="language-java">@Transactional
public void createUser(String name) {
    // 新增用户基本信息
    jdbcTemplate.update("INSERT INTO `user` (name) VALUES(?)", name);
    //调用accountService添加帐户
    accountService.addAccount(name, 10000);
 ｝

AccountService.addAccount(name,initMoney) 实现代码（方法的最后有一个异常）
@Transactional(propagation = Propagation.REQUIRED)
public void addAccount(String name, int initMoney) {
    String accountid = new SimpleDateFormat("yyyyMMddhhmmss").format(new Date());
    jdbcTemplate.update("insert INTO account (accountName,user,money) VALUES (?,?,?)", accountid, name, initMenoy);
    // 出现分母为零的异常
    int i = 1 / 0;
}
</code></pre>

<p style="margin-left:0cm;">实验预测一：</p>

<table border="1" cellspacing="0" style="margin-left:.5pt;width:412.7pt;"><tbody><tr><td style="vertical-align:top;width:54.9pt;">
            <p style="margin-left:0cm;"> </p>
            </td>
            <td style="width:120.6pt;">
            <p style="margin-left:0cm;">createUser</p>
            </td>
            <td style="width:113.9pt;">
            <p style="margin-left:0cm;">addAccount<span style="color:#ff0000;">(</span><span style="color:#ff0000;">异常)</span></p>
            </td>
            <td style="width:123.25pt;">
            <p style="margin-left:0cm;">预测结果</p>
            </td>
        </tr><tr><td style="width:54.9pt;">
            <p style="margin-left:0cm;">场景一</p>
            </td>
            <td style="vertical-align:top;width:120.6pt;">
            <p style="margin-left:0cm;">无事物</p>
            </td>
            <td style="vertical-align:top;width:113.9pt;">
            <p style="margin-left:0cm;">required</p>
            </td>
            <td style="vertical-align:top;width:123.25pt;">
            <p style="margin-left:0cm;">user （成功） Account（不成功） <span style="color:#1c7231;">正确</span></p>
            </td>
        </tr><tr><td style="width:54.9pt;">
            <p style="margin-left:0cm;">场景二</p>
            </td>
            <td style="vertical-align:top;width:120.6pt;">
            <p style="margin-left:0cm;">required</p>
            </td>
            <td style="vertical-align:top;width:113.9pt;">
            <p style="margin-left:0cm;">无事物</p>
            </td>
            <td style="vertical-align:top;width:123.25pt;">
            <p style="margin-left:0cm;">user （不成功） Account（不成功） <span style="color:#1c7231;">正确</span></p>
            </td>
        </tr><tr><td style="width:54.9pt;">
            <p style="margin-left:0cm;">场景三</p>
            </td>
            <td style="vertical-align:top;width:120.6pt;">
            <p style="margin-left:0cm;">required</p>
            </td>
            <td style="vertical-align:top;width:113.9pt;">
            <p style="margin-left:0cm;">not_supported</p>
            </td>
            <td style="vertical-align:top;width:123.25pt;">
            <p style="margin-left:0cm;">user （不成功） Account（成功）<span style="color:#1c7231;">正确</span></p>
            </td>
        </tr><tr><td style="width:54.9pt;">
            <p style="margin-left:0cm;">场景四</p>
            </td>
            <td style="vertical-align:top;width:120.6pt;">
            <p style="margin-left:0cm;">required</p>
            </td>
            <td style="vertical-align:top;width:113.9pt;">
            <p style="margin-left:0cm;">required_new</p>
            </td>
            <td style="vertical-align:top;width:123.25pt;">
            <p style="margin-left:0cm;">user （不成功） Account（不成功）<span style="color:#1c7231;">正确</span></p>
            </td>
        </tr><tr><td style="width:54.9pt;">
            <p style="margin-left:0cm;">场景五</p>
            </td>
            <td style="vertical-align:top;width:120.6pt;">
            <p style="margin-left:0cm;">required</p>

<pre><code>    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#ff0000;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color:#ff0000;&quot;&gt;异常移至createUser方法未尾)&lt;/span&gt;&lt;/p&gt;

    &lt;p style=&quot;margin-left:0cm;&quot;&gt; &lt;/p&gt;
    &lt;/td&gt;
    &lt;td style=&quot;vertical-align:top;width:113.9pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;required_new&lt;/p&gt;
    &lt;/td&gt;
    &lt;td style=&quot;vertical-align:top;width:123.25pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;user （不成功） Account（成功）&lt;span style=&quot;color:#1c7231;&quot;&gt;正确&lt;/span&gt;&lt;/p&gt;
    &lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width:54.9pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;场景六&lt;/p&gt;
    &lt;/td&gt;
    &lt;td style=&quot;vertical-align:top;width:120.6pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;required&lt;/p&gt;

    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#ff0000;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color:#ff0000;&quot;&gt;异常移至createUser方法未尾)&lt;/span&gt;&lt;/p&gt;

    &lt;p style=&quot;margin-left:0cm;&quot;&gt;&lt;span style=&quot;color:#000000;&quot;&gt;（&lt;/span&gt;&lt;span style=&quot;color:#000000;&quot;&gt;addAccount &lt;/span&gt;&lt;span style=&quot;color:#000000;&quot;&gt;方法称至当前类&lt;/span&gt;&lt;span style=&quot;color:#000000;&quot;&gt;）&lt;/span&gt;&lt;/p&gt;

    &lt;p style=&quot;margin-left:0cm;&quot;&gt; &lt;/p&gt;
    &lt;/td&gt;
    &lt;td style=&quot;vertical-align:top;width:113.9pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;required_new&lt;/p&gt;
    &lt;/td&gt;
    &lt;td style=&quot;vertical-align:top;width:123.25pt;&quot;&gt;
    &lt;p style=&quot;margin-left:0cm;&quot;&gt;user （不成功） Account（不成功）&lt;/p&gt;
    &lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p style=&quot;margin-left:0cm;&quot;&gt; &lt;/p&gt;</code></pre><div>
<h2 style="margin-left:0cm;"><strong>三、aop 事物底层实现原理</strong></h2>
</div>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;">讲事物原理之前我们先来做一个实验，当场景五的环境改变，把addAccount 方法移至UserService 类下，其它配置和代码不变：</p>

<pre>
<code class="language-java">@Override
@Transactional
public void createUser(String name) {
    jdbcTemplate.update("INSERT INTO `user` (name) VALUES(?)", name);
    addAccount(name, 10000);
    // 人为报错
    int i = 1 / 0;
}

@Transactional(propagation = Propagation.REQUIRES_NEW)
public void addAccount(String name, int initMoney) {
    String accountid = new SimpleDateFormat("yyyyMMddhhmmss").format(new Date());
    jdbcTemplate.update("insert INTO account (accountName,user,money) VALUES (?,?,?)", accountid, name, initMoney);
}
</code></pre>

<p style="margin-left:0cm;">经过演示我们发现得出的结果与场景五并不 一至，required_new 没有起到其对应的作用。原因在于spring 声明示事物使用动态代理实现，而当调用同一个类的方法时，是会不会走代理逻辑的，自然事物的配置也会失效。</p>

<p style="margin-left:0cm;">通过一个动态代理的实现来模拟这种场景</p>

<pre>
<code class="language-java">UserSerivce proxyUserSerivce = (UserSerivce) Proxy.newProxyInstance(TestTransaction.class.getClassLoader(),
        new Class[]{UserSerivce.class}, new InvocationHandler() {
            @Override
            public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                try {
                    System.out.println("开启事物:"+method.getName());
                    return method.invoke(userSerivce, args);
                } finally {
                    System.out.println("关闭事物:"+method.getName());
                }
            }
        });
proxyUserSerivce.createUser("test");
</code></pre>

<p style="margin-left:0cm;">当我们调用createUser 方法时 仅打印了 createUser  的事物开启、关闭，并没有打印addAccount 方法的事物开启、关闭，由此可见addAccount  的事物配置是失效的。</p>

<p style="margin-left:0cm;">如果业务当中上真有这种场景该如何实现呢？在spring xml中配置 暴露proxy 对象，然后在代码中用AopContext.currentProxy() 就可以获当前代理对象</p>

<p style="margin-left:0cm;">&lt;!-- 配置暴露proxy --&gt;</p>

<p style="margin-left:0cm;">&lt;aop:aspectj-autoproxy expose-proxy="true"/&gt;</p>

<p style="margin-left:0cm;">// 基于代理对象调用创建帐户，事物的配置又生效了</p>

<p style="margin-left:0cm;">((UserSerivce) AopContext.currentProxy()).addAccount(name, 10000);</p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>

<p style="margin-left:0cm;"> </p>
</td></tr></tbody></table></td></tr></tbody></table></div>
]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello</title>
    <url>/2020/03/20/Hello/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Git基本概念和底层原理</title>
    <url>/2020/03/20/Git%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h1 id="GIT和SVN的主要区别"><a href="#GIT和SVN的主要区别" class="headerlink" title="GIT和SVN的主要区别"></a>GIT和SVN的主要区别</h1><ol>
<li>存储方式不一样</li>
<li>使用方式不一样</li>
<li>管理模式不一样</li>
</ol>
<p><strong>1、存储方式区别</strong><br>   GIT把内容按元数据方式存储类似k/v数据库，而SVN是按文件(新版svn已改成元数据存储)<br>       演示git 存储过程演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> .git/objects/df/</span><br><span class="line">git cat-file -p df70460b4b4aece5915caf5c68d12f560a9fe3e4</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'version1'</span> &gt; text.txt</span><br><span class="line">git <span class="built_in">hash</span>-object -w text.txt</span><br></pre></td></tr></table></figure>

<p><strong>2、使用方式区别</strong><br>    从本地把文件推送远程服务，SVN只需要commint 而GIT需要 add、commint、push 三个步骤<br>SVN基本使用过程<br><img src="https://img-blog.csdnimg.cn/20200207220323296.png" alt="在这里插入图片描述"><br>Git基本使用过程<br><img src="https://img-blog.csdnimg.cn/2020020722041424.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzQ0Njk1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>3、版本管理模式区别</strong><br>git 是一个分布式的版本管理系统，而要SVN是一个远程集中式的管理系统</p>
<p>集中式<br><img src="https://img-blog.csdnimg.cn/202002072204584.png" alt="在这里插入图片描述"><br>分布式<br><img src="https://img-blog.csdnimg.cn/202002072205124.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzQ0Njk1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h1 id="二、GIT-核心命令使用"><a href="#二、GIT-核心命令使用" class="headerlink" title="二、GIT 核心命令使用"></a>二、GIT 核心命令使用</h1><p>主要内容:</p>
<ol>
<li>git 客户端安装配置</li>
<li>整体认识GIT的基本使用</li>
<li>分支管理</li>
<li>标签管理</li>
<li>远程仓库配置</li>
</ol>
<p><strong>1、安装git 客户端安装</strong><br>官方客户端： httpsd://git-scm.com/downloads<br>其它客户端：<a href="https://tortoisegit.org/download/" target="_blank" rel="external nofollow noopener noreferrer">https://tortoisegit.org/download/</a></p>
<p><strong>2、认识GIT的基本使用</strong></p>
<ol>
<li>git 项目创建与克隆</li>
<li>文件提交与推送<br>完整模拟从项目添加到push 过程<ul>
<li>创建项目 </li>
<li>初始化git仓库</li>
<li>提交文件 </li>
<li>远程关联 </li>
<li>push 至远程仓库</li>
</ul>
</li>
</ol>
<p><strong>本地初始化GIT 仓库:</strong><br>#基于远程仓库克隆至本地</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> &lt;remote_url&gt;</span><br></pre></td></tr></table></figure>
<p>#当前目录初始化为git 本地仓库</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git init  &lt;directory&gt;</span><br></pre></td></tr></table></figure>
<p>基于mvn 模板创建项目<br>mvn archetype:generate</p>
<p>本地添加<br>#添加指定文件至暂存区</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git add &lt;fileName&gt;</span><br></pre></td></tr></table></figure>
<p>#添加指定目录至暂存区</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git add &lt;directory&gt;</span><br></pre></td></tr></table></figure>
<p>#添加所有</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git add -A</span><br></pre></td></tr></table></figure>
<p>#将指定目录及子目录移除出暂存区</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git rm --cached &lt;target&gt; -r</span><br></pre></td></tr></table></figure>
<p>#将该文件从commit后撤回到add后</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git rm &lt;target&gt;</span><br></pre></td></tr></table></figure>
<p>#添加忽略配置文件 .gitignore</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 以'#'开始的行，被视为注释.                                                                                                                          </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略掉所有文件名是 foo.txt的文件.</span></span><br><span class="line"></span><br><span class="line">foo.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略所有生成的 html文件,</span></span><br><span class="line"></span><br><span class="line">*.html</span><br><span class="line"></span><br><span class="line"><span class="comment"># foo.html是手工维护的，所以例外.</span></span><br><span class="line"></span><br><span class="line">!foo.html</span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略所有.o和 .a文件.</span></span><br><span class="line"></span><br><span class="line">*.[oa]</span><br><span class="line">配置语法：</span><br><span class="line">以斜杠“/”开头表示目录；</span><br><span class="line">以星号“*”通配多个字符；</span><br><span class="line">以问号“?”通配单个字符</span><br><span class="line">以方括号“[]”包含单个字符的匹配列表；</span><br><span class="line">以叹号“!”表示不忽略(跟踪)匹配到的文件或目录；</span><br></pre></td></tr></table></figure>
<p>本地提交<br>#提交至本地仓库</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git commit &lt;file&gt; -m <span class="string">'提交评论'</span></span><br></pre></td></tr></table></figure>
<p>#快捷提交至本地仓库 <em>新增文件不能直接用此命令</em></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git commit -am <span class="string">'快添加与提交'</span></span><br></pre></td></tr></table></figure>
<p>#查看修改历史</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git blame 文件名 // 查看该文件的修改历史</span><br><span class="line">git blame -L 100,10 文件名 // 从100行开始，到110行 逐行查看文件的修改历史</span><br></pre></td></tr></table></figure>
<p>#对比工作区，暂存区，仓库的差异</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git diff // 查看变更 工作区与暂存区的差异比对</span><br><span class="line">git diff --cached // 暂存区与提交版本的差异</span><br><span class="line">git diff HEAD // 工作区与仓库中最后一次提交版本的差别</span><br><span class="line">git diff 版本哈希值 版本哈希值 // 查看这2个版本哈希之间的区别</span><br><span class="line">或者 git diff HEAD~数字 HEAD~数字</span><br><span class="line">git tag tt HEAD~4 给倒数第5次提交打一个tag tag名字是tt</span><br><span class="line">git diff tt 就是倒数第5个版本与第一个版本之间的差异</span><br><span class="line">git diff --cached tt 暂存区与倒数第5个版本之间的比对</span><br></pre></td></tr></table></figure>
<p>#回撤操作</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git commit --amend -m <span class="string">"提交信息"</span> // 回撤上一次提交并与本次工作区一起提交</span><br><span class="line">git reset HEAD~2 --hard // 回撤2步</span><br><span class="line">git reset --files // 从仓库回撤到暂存区</span><br><span class="line">git reset HEAD // 回撤暂存区内容到工作目录</span><br><span class="line">git reset HEAD --soft 回撤提交到暂存区</span><br><span class="line">git reset HEAD --hard // 回撤提交 放弃变更 (慎用)</span><br><span class="line">git reset HEAD^  // 回撤仓库最后一次提交</span><br><span class="line">git reset --hard commitid // 回撤到该次提交id的位置</span><br><span class="line"></span><br><span class="line">git push -f -u origin 分支名 所有内容都回撤完了 将回撤后的操作强制推送到远程分支</span><br></pre></td></tr></table></figure>
<p>#标签操作</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git tag // 查看列出所有打过的标签名</span><br><span class="line">git tag -d 标签名 // 删除对应标签</span><br><span class="line">git tag 标签名字 // 在当前仓库打个标签</span><br><span class="line">git tag foo -m <span class="string">"message"</span> // 在当前提交上，打标签foo 并给message信息注释</span><br><span class="line">git tag 标签名 哈希值 -m <span class="string">"message"</span> // 在某个哈希值上打标签并且写上标签的信息</span><br><span class="line">git tag foo HEAD~4 // 在当前提交之前的第4个版本上 打标签foo</span><br><span class="line">git push origin --tags // 把所有打好的标签推送到远程仓库</span><br><span class="line">git push origin 标签名 // 把指定标签推送到远程仓库</span><br><span class="line">git stash // 把暂存区的内容 暂时放在其他中 使暂存区变空</span><br><span class="line">git stash list // 查看stash了哪些存储</span><br><span class="line">git stash pop // 将stash中的内容恢复到当前目录，将缓存堆栈中的对应stash删除</span><br><span class="line">git stash apply // 将stash中的内容恢复到当前目录，不会将缓存堆栈中的对应stash删除</span><br><span class="line">git stash clear // 删除所有缓存的stash</span><br><span class="line">git pull --tags // 把远程仓库的标签也拉取下来</span><br><span class="line">git push origin :refs/tags/远程标签名 // 删除远程仓库的标签</span><br></pre></td></tr></table></figure>
<p>#日志管理</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">log</span> --pretty=format:<span class="string">'%h %ad | %s%d [%an]'</span> --graph --date=short</span><br><span class="line">// 获取git <span class="built_in">log</span>里的树形详细信息 包括hasg 日期 提交信息 提交人等</span><br><span class="line">git <span class="built_in">log</span> --oneline //拉出所有提交信息 q是退出</span><br><span class="line">git <span class="built_in">log</span> -5 // 查看前5次的提交记录</span><br><span class="line">git <span class="built_in">log</span> --oneline -5 // 打印出的日志里面只有哈希值和修改的内容备注</span><br><span class="line">git <span class="built_in">log</span> 文件名 // 查看该文件的提交</span><br><span class="line">git <span class="built_in">log</span> --grep // 想过滤看到的内容   过滤日志</span><br><span class="line">git <span class="built_in">log</span> -n // 查看近期提交的n条信息内容</span><br><span class="line">git <span class="built_in">log</span> -p // 查看详细提交记录</span><br><span class="line">git <span class="built_in">log</span> master..experiment  //比较两个版本的区别</span><br></pre></td></tr></table></figure>

<p><strong>3、分支管理</strong><br>#查看当前分支</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git branch [-avv]</span><br></pre></td></tr></table></figure>
<p>#基于当前分支新建分支</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git branch  &lt;branch name&gt;</span><br></pre></td></tr></table></figure>
<p>#基于提交新建分支</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git branch &lt;branch name&gt; &lt;commit id&gt;</span><br></pre></td></tr></table></figure>
<p>#把远程分支拉到本地</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git fetch origin dev（dev为远程仓库的分支名）</span><br></pre></td></tr></table></figure>

<p>#删除分支</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ git branch -d &lt;branch name&gt;</span><br></pre></td></tr></table></figure>
<p>#切换分支</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git checkout &lt;branch name&gt;</span><br></pre></td></tr></table></figure>
<p>#合并分支</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git merge &lt;merge target&gt;</span><br></pre></td></tr></table></figure>
<p>#解决冲突，如果因冲突导致自动合并失败，此时 status 为mergeing 状态.<br>#需要手动修改后重新提交（commit） </p>
<p><strong>4、远程仓库管理</strong><br>#查看远程配置 </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git remote [-v]</span><br></pre></td></tr></table></figure>
<p>#添加远程地址</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git remote add origin http:xxx.xxx</span><br></pre></td></tr></table></figure>
<p>#删除远程地址</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git remote remove origin</span><br></pre></td></tr></table></figure>
<p>#上传新分支至远程</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git push --<span class="built_in">set</span>-upstream origin master</span><br></pre></td></tr></table></figure>
<p>#将本地分支与远程建立关联</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git branch --track --<span class="built_in">set</span>-upstream-to=origin/<span class="built_in">test</span> <span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<h1 id="三、git-底层原理"><a href="#三、git-底层原理" class="headerlink" title="三、git 底层原理"></a>三、git 底层原理</h1><ul>
<li>GIT存储对像</li>
<li>GIT树对像</li>
<li>GIT提交对像</li>
<li>GIT引用</li>
</ul>
<p><strong>1、GIT存储对像(hashMap)</strong><br>Git 是一个内容寻址文件系统，其核心部分是一个简单的键值对数据库（key-value data store），你可以向数据库中插入任意内容，它会返回一个用于取回该值的hash 键。</p>
<p>#git 键值库中插入数据</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">'luban is good man'</span> | git <span class="built_in">hash</span>-object -w --stdin</span><br><span class="line">79362d07cf264f8078b489a47132afbc73f87b9a</span><br></pre></td></tr></table></figure>

<p>#基于键获取指定内容</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git cat-file -p 79362d07cf264f8078b489a47132afbc73f87b9a</span><br></pre></td></tr></table></figure>

<p>Git基于该功能 把每个文件的版本中内容都保存在数据库中，当要进行版本回滚的时候就通过其中一个键将期取回并替换。</p>
<p>    模拟演示git 版写入与回滚过程<br>#查找所有的git 对像</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find .git/objects/ -<span class="built_in">type</span> f</span><br></pre></td></tr></table></figure>

<p>#写入版本1</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">'version1'</span> &gt; README.MF; git <span class="built_in">hash</span>-object -w README.MF;</span><br></pre></td></tr></table></figure>

<p>#写入版本2</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">'version2'</span> &gt; README.MF; git <span class="built_in">hash</span>-object -w README.MF;</span><br></pre></td></tr></table></figure>

<p>#写入版本3</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">'version3'</span> &gt; README.MF; git <span class="built_in">hash</span>-object -w README.MF;</span><br></pre></td></tr></table></figure>

<p>#回滚指定版本</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git cat-file -p c11e96db44f7f3bc4c608aa7d7cd9ba4ab25066e &gt; </span><br><span class="line">README.MF</span><br></pre></td></tr></table></figure>

<p>所以我们平常用的 git add 其实就是把修改之后的内容 插入到键值库中。当我们执行 git add README.MF 等同于执行了 git hash-object -w README.MF 把文件写到数据库中。</p>
<p>我们解决了存储的问题，但其只能存储内容同并没有存储文件名，如果要进行回滚 怎么知道哪个内容对应哪个文件呢？接下要讲的就是树对象，它解决了文件名存储的问题 。</p>
<p><strong>2、GIT树对像</strong><br>树对像解决了文件名的问题，它的目的将多个文件名组织在一起，其内包含多个文件名称与其对应的Key和其它树对像的用引用，可以理解成操作系统当中的文件夹，一个文件夹包含多个文件和多个其它文件夹。<br><img src="https://img-blog.csdnimg.cn/20200208155735977.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzQ0Njk1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>每一个分支当中都关联了一个树对像，他存储了当前分支下所有的文件名及对应的 key.<br>通过以下命令即可查看<br>#查看分支树</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git cat-file -p master^&#123;tree&#125;</span><br></pre></td></tr></table></figure>
<p><strong>3、git提交对象</strong><br>一次提交即为当前版本的一个快照，该快照就是通过提交对像保存，其存储的内容为：一个顶级树对象、上一次提交的对像啥希、提交者用户名及邮箱、提交时间戳、提交评论。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ git cat-file -p b2395925b5f1c12bf8cb9602f05fc8d580311836</span><br><span class="line">tree 002adb8152f7cd49f400a0480ef2d4c09b060c07</span><br><span class="line">parent 8be903f5e1046b851117a21cdc3c80bdcaf97570</span><br><span class="line">author tommy &lt;tommy@tuling.com&gt; 1532959457 +0800</span><br><span class="line">committer tommy &lt;tommy@tuling.com&gt; 1532959457 +0800</span><br></pre></td></tr></table></figure>

<p>通过上面的知识，我们可以推测出从修改一个文件到提交的过程总共生成了三个对像：<br>一个内容对象 ==&gt; 存储了文件内容<br>一个树对像 ==&gt; 存储了文件名及内容对像的key<br>一个提交对像 ==&gt; 存储了树对像的key 及提交评论。 </p>
<p><strong>4、GIT引用</strong><br>当我们执行 git branch {branchName} 时创建了一个分支，其本质就是在git 基于指定提交创建了一个引用文件，保存在 .git\refs\heads\ 下。</p>
<p>    演示分支的创建</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git branch dev </span><br><span class="line">cat.git\refs\heads\dev</span><br></pre></td></tr></table></figure>

<p>git 总共 有三种类型的引用：</p>
<ol>
<li>分支引用</li>
<li>远程分支引用</li>
<li>标签引用</li>
</ol>
<p>#查询比较两个版本</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">log</span> master..experiment</span><br></pre></td></tr></table></figure>

<p>#版本提交历史网络</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">log</span> --pretty=format:<span class="string">'%h %s'</span> --graph</span><br></pre></td></tr></table></figure>

<p>#查看分支树</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git cat-file -p master^&#123;tree&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>java动态代理详解</title>
    <url>/2020/03/01/java%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<a id="more"></a>

<p id="main-toc"><strong>目录</strong></p>

<p id="-toc" style="margin-left:80px;"> </p>

<p id="1.%E5%9F%BA%E4%BA%8EJDK%E7%9A%84%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86-toc" style="margin-left:80px;"><a href="#1.%E5%9F%BA%E4%BA%8EJDK%E7%9A%84%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86">1.基于JDK的动态代理</a></p>

<p id="2.%E5%9F%BA%E4%BA%8ECGLIB%E7%9A%84%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86-toc" style="margin-left:80px;"><a href="#2.%E5%9F%BA%E4%BA%8ECGLIB%E7%9A%84%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86">2.基于CGLIB的动态代理</a></p>

<hr id="hr-toc"><p id="%E7%9B%AE%E5%89%8Djava%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%88%86%E4%B8%BA%E4%B8%A4%E7%A7%8D">目前java动态代理的实现分为两种</p>

<p><strong>1.基于JDK的动态代理</strong></p>

<p><strong>2.基于CGILB的动态代理</strong></p>

<p>在业务中使用动态代理，一般是为了给需要实现的方法添加预处理或者添加后续操作，但是不干预实现类的正常业务，把一些基本业务和主要的业务逻辑分离。我们一般所熟知的Spring的AOP原理就是基于动态代理实现的。</p>

<h3 id="1.%E5%9F%BA%E4%BA%8EJDK%E7%9A%84%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86"><strong>1.基于JDK的动态代理</strong></h3>

<p>基于JDK的动态代理就需要知道两个类：1.InvocationHandler（接口）、2.Proxy（类）</p>

<p>还要知道JDK是基于接口的动态代理</p>

<p>下面我们实际用代码来讲解这两个类的实际作用</p>

<p>1.第一步，创建一个接口</p>

<p>public interface Subject {<br>
    void hello(String param);<br>
}<br>
2.第二步，实现接口</p>

<p>public class SubjectImpl implements Subject {<br>
    @Override<br>
    public void hello(String param) {<br>
        System.out.println("hello  " + param);<br>
    }<br>
}<br>
3.第三步，创建SubjectImpl的代理类</p>

<p>public class SubjectProxy implements InvocationHandler {<br>
    private Subject subject;</p>

<p>    public SubjectProxy(Subject subject) {<br>
        this.subject = subject;<br>
    }</p>

<p>    @Override<br>
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {<br>
        System.out.println("--------------begin-------------");<br>
        Object invoke = method.invoke(subject, args);<br>
        System.out.println("--------------end-------------");<br>
        return invoke;<br>
    }<br>
}<br>
invoke方法的说明：</p>

<p><img alt src="https://img-blog.csdn.net/20180821150523827?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNTMyMzIx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>

<p>4.编写代理类实际的调用，利用Proxy类创建代理之后的Subject类。</p>

<p>public class Main {</p>

<p>    public static void main(String[] args) {<br>
        Subject subject = new SubjectImpl();<br>
        InvocationHandler subjectProxy = new SubjectProxy(subject);<br>
        Subject proxyInstance = (Subject) Proxy.newProxyInstance(subjectProxy.getClass().getClassLoader(), subject.getClass().getInterfaces(), subjectProxy);<br>
        proxyInstance.hello("world");<br>
    }</p>

<p>}</p>

<p><img alt src="https://img-blog.csdn.net/20180821150918418?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNTMyMzIx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"><br>
输出：</p>

<p>--------------begin-------------<br>
hello  world<br>
--------------end-------------</p>

<p>看这个结果，实际上在Subject类中只会输出一条hello world，但是在被代理之后，实际调用的方法是SubjectProxy的invoke方法，这样可以在不修改业务类的情况下对业务类增加一些日志等其他操作，甚至可以直接修改有返回值方法的返回值。</p>

<h3 id="2.%E5%9F%BA%E4%BA%8ECGLIB%E7%9A%84%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86"><strong>2.基于CGLIB的动态代理</strong></h3>

<p>本文主要讲的是CGLIB的动态代理，因为基于JDK的动态代理一定要继承一个接口，而绝大部分情况是基于POJO类的动态代理，那么CGLIB就是一个很好的选择，在Hibernate框架中PO的字节码生产工作就是靠CGLIB来完成的。还是先看代码。</p>

<p>1.引入CGLIB的jar包</p>

<p>2.创建代理类</p>

<p>public class CGsubject {<br>
    public void sayHello(){<br>
        System.out.println("hello world");<br>
    }<br>
}<br>
如果直接对这个类创建对象，那么调用sayHello方法，控制台就会输出hello world，现在我们还是要对输出添加前置和后置的log输出。来打印输出前和输出后的时间。</p>

<p>3.实现MethodInterceptor接口，对方法进行拦截处理。</p>

<p>public class HelloInterceptor implements MethodInterceptor{<br>
    @Override<br>
    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {<br>
        System.out.println("begin time -----&gt; "+ System.currentTimeMillis());<br>
        Object o1 = methodProxy.invokeSuper(o, objects);<br>
        System.out.println("end time -----&gt; "+ System.currentTimeMillis());<br>
        return o1;<br>
    }<br>
}</p>

<p><img alt src="https://img-blog.csdn.net/201808211529299?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNTMyMzIx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"><br>
4.创建被代理类</p>

<p>public class Main {</p>

<p>    public static void main(String[] args) {<br>
        Enhancer enhancer = new Enhancer();<br>
        enhancer.setSuperclass(CGsubject.class);<br>
        enhancer.setCallback(new HelloInterceptor());<br>
        CGsubject cGsubject = (CGsubject) enhancer.create();<br>
        cGsubject.sayHello();<br>
    }</p>

<p>}<br>
利用Enhancer来生产被代理类，这样可以拦截方法，对方法进行前置和后置log的添加。</p>

<p>输出：</p>

<p>begin time -----&gt; 1534836443741<br>
hello world<br>
end time -----&gt; 1534836443786<br>
 </p>
]]></content>
      <categories>
        <category>JavaWeb</category>
      </categories>
  </entry>
  <entry>
    <title>MyBatis源码解析(二)——动态代理实现函数调用</title>
    <url>/2020/03/01/MyBatis%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%BA%8C)%E2%80%94%E2%80%94%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8/</url>
    <content><![CDATA[<a id="more"></a>

<p>如果我们要使用MyBatis进行数据库操作的话，大致要做两件事情：</p>

<ol><li>定义DAO接口<br>
    在DAO接口中定义需要进行的数据库操作。</li>
    <li>创建映射文件<br>
    当有了DAO接口后，还需要为该接口创建映射文件。映射文件中定义了一系列SQL语句，这些SQL语句和DAO接口一一对应。</li>
</ol><p>MyBatis在初始化的时候会将映射文件与DAO接口一一对应，并根据映射文件的内容为每个函数创建相应的数据库操作能力。而我们作为MyBatis使用者，只需将DAO接口注入给Service层使用即可。<br>
那么MyBatis是如何根据映射文件为每个DAO接口创建具体实现的？答案是——动态代理。<br>
下面进入正题。</p>

<hr><p>首先来回顾一项MyBatis在初始化过程中所做的事情。<br>
MyBatis在初始化过程中，首先会读取我们的配置文件流程，并使用<code>XMLConfigBuilder</code>来解析配置文件。<code>XMLConfigBuilder</code>会依次解析配置文件中的各个子节点，如：<code>&lt;settings&gt;</code>、<code>&lt;typeAliases&gt;</code>、<code>&lt;mappers&gt;</code>等。这些子节点在解析完成后都会被注册进<code>configuration</code>对象。然后<code>configuration</code>对象将作为参数，创建<code>SqlSessionFactory</code>对象。至此，初始化过程完毕！<br>
下面我们重点分析<code>&lt;mapper&gt;</code>节点解析的过程。</p>

<p>PS：MyBatis详细的初始化过程请移步至：<a href="https://www.jianshu.com/p/7bc6d3b7fb45" target="_blank" rel="external nofollow noopener noreferrer">MyBatis源码解析(一)——MyBatis初始化过程解析</a></p>

<hr><h1>&lt;mapper&gt;节点解析过程</h1>

<p> </p>

<pre>
<code>XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments());
mapperParser.parse();
</code></pre>

<p>由上述代码可知，解析mapper节点的解析是由<code>XMLMapperBuilder</code>类的<code>parse()</code>函数来完成的，下面我们就详细看一下<code>parse()</code>函数。</p>

<p> </p>

<pre>
<code>  public void parse() {
    // 若当前Mapper.xml尚未加载，则加载
    if (!configuration.isResourceLoaded(resource)) {
      // 解析&lt;mapper&gt;节点
      configurationElement(parser.evalNode("/mapper"));
      // 将当前Mapper.xml标注为『已加载』（下回就不用再加载了）
      configuration.addLoadedResource(resource);
      // 【关键】将Mapper Class添加至Configuration中
      bindMapperForNamespace();
    }

    parsePendingResultMaps();
    parsePendingCacheRefs();
    parsePendingStatements();
  }
</code></pre>

<p>这个函数主要做了两件事：</p>

<ol><li>解析<code>&lt;mapper&gt;</code>节点，并将解析结果注册进<code>configuration</code>中；</li>
    <li>将当前映射文件所对应的DAO接口的Class对象注册进<code>configuration</code>中<br>
    这一步极为关键！是为了给DAO接口创建代理对象，下文会详细介绍。</li>
</ol><p>下面再进入<code>bindMapperForNamespace()</code>函数，看一看它做了什么：</p>

<p> </p>

<pre>
<code>  private void bindMapperForNamespace() {
    // 获取当前映射文件对应的DAO接口的全限定名
    String namespace = builderAssistant.getCurrentNamespace();
    if (namespace != null) {
      // 将全限定名解析成Class对象
      Class&lt;?&gt; boundType = null;
      try {
        boundType = Resources.classForName(namespace);
      } catch (ClassNotFoundException e) {
      }
      if (boundType != null) {
        if (!configuration.hasMapper(boundType)) {
          // 将当前Mapper.xml标注为『已加载』（下回就不用再加载了）
          configuration.addLoadedResource("namespace:" + namespace);
          // 将DAO接口的Class对象注册进configuration中
          configuration.addMapper(boundType);
        }
      }
    }
  }
</code></pre>

<p>这个函数主要做了两件事：</p>

<ol><li>将<code>&lt;mapper&gt;</code>节点上定义的<code>namespace</code>属性（即：当前映射文件所对应的DAO接口的权限定名）解析成Class对象</li>
    <li>将该Class对象存储在<code>configuration</code>对象的<code>MapperRegistry</code>容器中。</li>
</ol><p>可以看一下<code>MapperRegistry</code>：</p>

<p> </p>

<pre>
<code>public class MapperRegistry {
  private final Configuration config;
  private final Map&lt;Class&lt;?&gt;, MapperProxyFactory&lt;?&gt;&gt; knownMappers = new HashMap&lt;Class&lt;?&gt;, MapperProxyFactory&lt;?&gt;&gt;();
}
</code></pre>

<p><code>MapperRegistry</code>有且仅有两个属性：<code>Configuration</code>和<code>knownMappers</code>。<br>
其中，<code>knownMappers</code>的类型为<code>Map&lt;Class&lt;?&gt;, MapperProxyFactory&lt;?&gt;&gt;</code>，由此可见，它是一个Map，key为DAO接口的Class对象，而Value为该DAO接口代理对象的工厂。<br>
那么，这个代理对象工厂是何许人也？它又是如何产生的呢？我们先来看一下<code>MapperRegistry</code>的<code>addMapper()</code>函数。</p>

<p> </p>

<pre>
<code>  public &lt;T&gt; void addMapper(Class&lt;T&gt; type) {
    if (type.isInterface()) {
      if (hasMapper(type)) {
        throw new BindingException("Type " + type + " is already known to the MapperRegistry.");
      }
      boolean loadCompleted = false;
      try {
        // 创建MapperProxyFactory对象，并put进knownMappers中
        knownMappers.put(type, new MapperProxyFactory&lt;T&gt;(type));
        MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type);
        parser.parse();
        loadCompleted = true;
      } finally {
        if (!loadCompleted) {
          knownMappers.remove(type);
        }
      }
    }
  }
</code></pre>

<p>从这个函数可知，<code>MapperProxyFactory</code>是在这里创建，并put进<code>knownMappers</code>中的。<br>
下面我们就来看一下<code>MapperProxyFactory</code>这个类究竟有些啥：</p>

<p> </p>

<pre>
<code>public class MapperProxyFactory&lt;T&gt; {

  private final Class&lt;T&gt; mapperInterface;
  private final Map&lt;Method, MapperMethod&gt; methodCache = new ConcurrentHashMap&lt;Method, MapperMethod&gt;();

  public MapperProxyFactory(Class&lt;T&gt; mapperInterface) {
    this.mapperInterface = mapperInterface;
  }

  public Class&lt;T&gt; getMapperInterface() {
    return mapperInterface;
  }

  public Map&lt;Method, MapperMethod&gt; getMethodCache() {
    return methodCache;
  }

  @SuppressWarnings("unchecked")
  protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) {
    return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy);
  }

  public T newInstance(SqlSession sqlSession) {
    final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;T&gt;(sqlSession, mapperInterface, methodCache);
    return newInstance(mapperProxy);
  }
}
</code></pre>

<p>这个类有三个重要成员：</p>

<ol><li>mapperInterface属性<br>
    这个属性就是DAO接口的Class对象，当创建<code>MapperProxyFactory</code>对象的时候需要传入</li>
    <li>methodCache属性<br>
    这个属性用于存储当前DAO接口中所有的方法。</li>
    <li>newInstance函数<br>
    这个函数用于创建DAO接口的代理对象，它需要传入一个MapperProxy对象作为参数。而MapperProxy类实现了InvocationHandler接口，由此可知它是动态代理中的处理类，所有对目标函数的调用请求都会先被这个处理类截获，所以可以在这个处理类中添加目标函数调用前、调用后的逻辑。</li>
</ol><hr><h1>DAO函数调用过程</h1>

<p>当MyBatis初始化完毕后，<code>configuration</code>对象中存储了所有DAO接口的Class对象和相应的<code>MapperProxyFactory</code>对象（用于创建DAO接口的代理对象）。接下来，就到了使用DAO接口中函数的阶段了。</p>

<p> </p>

<pre>
<code>SqlSession sqlSession = sqlSessionFactory.openSession();
try {
    ProductMapper productMapper = sqlSession.getMapper(ProductMapper.class);
    List&lt;Product&gt; productList = productMapper.selectProductList();
    for (Product product : productList) {
        System.out.printf(product.toString());
    }
} finally {
    sqlSession.close();
}
</code></pre>

<p>我们首先需要从<code>sqlSessionFactory</code>对象中创建一个<code>SqlSession</code>对象，然后调用<code>sqlSession.getMapper(ProductMapper.class)</code>来获取代理对象。</p>

<p><code>sqlSessionFactory.openSession()</code>创建<code>SqlSession</code>对象</p>

<pre>
<code class="language-java">public SqlSession openSession() {
        return this.openSessionFromDataSource(this.configuration.getDefaultExecutorType(), (TransactionIsolationLevel)null, false);
    }</code></pre>

<p>会调用 openSessionFromDataSource 方法，其中执行器为初始化Configuration时默认的 SimpleExecutor，接下来看openSessionFromDataSource方法</p>

<pre>
<code class="language-java">private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) {
        Transaction tx = null;

        DefaultSqlSession var8;
        try {
            Environment environment = this.configuration.getEnvironment();
            TransactionFactory transactionFactory = this.getTransactionFactoryFromEnvironment(environment);
            tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);
            Executor executor = this.configuration.newExecutor(tx, execType);
            var8 = new DefaultSqlSession(this.configuration, executor, autoCommit);
        } catch (Exception var12) {
            this.closeTransaction(tx);
            throw ExceptionFactory.wrapException("Error opening session.  Cause: " + var12, var12);
        } finally {
            ErrorContext.instance().reset();
        }

        return var8;
    }</code></pre>

<p>会返回一个 DefaultSqlSession 对象，看一下其中的this.configuration.newExecutor(tx, execType);方法</p>

<pre>
<code class="language-java">public Executor newExecutor(Transaction transaction, ExecutorType executorType) {
        executorType = executorType == null ? this.defaultExecutorType : executorType;
        executorType = executorType == null ? ExecutorType.SIMPLE : executorType;
        Object executor;
        if (ExecutorType.BATCH == executorType) {
            executor = new BatchExecutor(this, transaction);
        } else if (ExecutorType.REUSE == executorType) {
            executor = new ReuseExecutor(this, transaction);
        } else {
            executor = new SimpleExecutor(this, transaction);
        }

        //缓存
        if (this.cacheEnabled) {
            executor = new CachingExecutor((Executor)executor);
        }
        //责任链模式拦截器 
        Executor executor = (Executor)this.interceptorChain.pluginAll(executor);
        return executor;
    }</code></pre>

<p>开启缓存这里SimpleExecutor就会被CachingExecutor替换</p>

<p><br>
我们再来看一下<code>sqlSession.getMapper()</code>是如何创建代理对象的？</p>

<p> </p>

<pre>
<code>  public &lt;T&gt; T getMapper(Class&lt;T&gt; type) {
    return configuration.&lt;T&gt;getMapper(type, this);
  }
</code></pre>

<p><code>sqlSession.getMapper()</code>调用了<code>configuration.getMapper()</code>，那我们再看一下<code>configuration.getMapper()</code>：</p>

<p> </p>

<pre>
<code>  public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) {
    return mapperRegistry.getMapper(type, sqlSession);
  }
</code></pre>

<p><code>configuration.getMapper()</code>又调用了<code>mapperRegistry.getMapper()</code>，那好，我们再深入看一下<code>mapperRegistry.getMapper()</code>：</p>

<p> </p>

<pre>
<code>  public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) {
    final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type);
    if (mapperProxyFactory == null) {
      throw new BindingException("Type " + type + " is not known to the MapperRegistry.");
    }
    try {
      return mapperProxyFactory.newInstance(sqlSession);
    } catch (Exception e) {
      throw new BindingException("Error getting mapper instance. Cause: " + e, e);
    }
  }
</code></pre>

<p>看到这里我们就恍然大悟了，原来它根据上游传递进来DAO接口的Class对象，从<code>configuration</code>中取出了该DAO接口对应的代理对象生成工厂：<code>MapperProxyFactory</code>；<br>
在有了这个工厂后，再通过<code>newInstance</code>函数创建该DAO接口的代理对象，并返回给上游。</p>

<p>OK，此时我们已经获取了代理对象，接下来就可以使用这个代理对象调用相应的函数了。</p>

<p> </p>

<pre>
<code>SqlSession sqlSession = sqlSessionFactory.openSession();
try {
    ProductMapper productMapper = sqlSession.getMapper(ProductMapper.class);
    List&lt;Product&gt; productList = productMapper.selectProductList();
    for (Product product : productList) {
        System.out.printf(product.toString());
    }
} finally {
    sqlSession.close();
}
</code></pre>

<p>以上述代码为例，当我们获取到<code>ProductMapper</code>的代理对象后，我们调用了它的<code>selectProductList()</code>函数。<br>
下面我们就来分析下代理函数调用过程。</p>

<hr><p>当调用了代理对象的某一个代理函数后，这个调用请求首先会被发送给代理对象处理类<code>MapperProxy</code>的<code>invoke()</code>函数：</p>

<p> </p>

<pre>
<code>  public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
    try {
      if (Object.class.equals(method.getDeclaringClass())) {
        return method.invoke(this, args);
      } else if (isDefaultMethod(method)) {
        return invokeDefaultMethod(proxy, method, args);
      }
    } catch (Throwable t) {
      throw ExceptionUtil.unwrapThrowable(t);
    }
    // 【核心代理在这里】
    final MapperMethod mapperMethod = cachedMapperMethod(method);
    return mapperMethod.execute(sqlSession, args);
  }
</code></pre>

<p>先来解释下invoke函数的几个参数：</p>

<ol><li><code>Object proxy</code>：代理对象</li>
    <li><code>Method method</code>：当前正在被调用的代理对象的函数对象</li>
    <li><code>Object[] args</code>：调用函数的所有入参</li>
</ol><p>然后，直接看invoke函数最核心的两行代码：</p>

<ol><li><code>cachedMapperMethod(method)</code>：从当前代理对象处理类<code>MapperProxy</code>的<code>methodCache</code>属性中获取method方法的详细信息（即：<code>MapperMethod</code>对象）。如果<code>methodCache</code>中没有就创建并加进去。</li>
    <li>有了<code>MapperMethod</code>对象后执行它的<code>execute()</code>方法，该方法就会调用JDBC执行相应的SQL语句，并将结果返回给上游调用者。至此，代理对象函数的调用过程结束！</li>
</ol><p>MapperMethod的execute方法</p>

<pre>
<code class="language-java">public Object execute(SqlSession sqlSession, Object[] args) {
        Object result;
        Object param;
        switch(this.command.getType()) {
        case INSERT:
            param = this.method.convertArgsToSqlCommandParam(args);
            result = this.rowCountResult(sqlSession.insert(this.command.getName(), param));
            break;
        case UPDATE:
            param = this.method.convertArgsToSqlCommandParam(args);
            result = this.rowCountResult(sqlSession.update(this.command.getName(), param));
            break;
        case DELETE:
            param = this.method.convertArgsToSqlCommandParam(args);
            result = this.rowCountResult(sqlSession.delete(this.command.getName(), param));
            break;
        case SELECT:
            if (this.method.returnsVoid() &amp;&amp; this.method.hasResultHandler()) {
                this.executeWithResultHandler(sqlSession, args);
                result = null;
            } else if (this.method.returnsMany()) {
                result = this.executeForMany(sqlSession, args);
            } else if (this.method.returnsMap()) {
                result = this.executeForMap(sqlSession, args);
            } else if (this.method.returnsCursor()) {
                result = this.executeForCursor(sqlSession, args);
            } else {
                param = this.method.convertArgsToSqlCommandParam(args);
                result = sqlSession.selectOne(this.command.getName(), param);
                if (this.method.returnsOptional() &amp;&amp; (result == null || !this.method.getReturnType().equals(result.getClass()))) {
                    result = Optional.ofNullable(result);
                }
            }
            break;
        case FLUSH:
            result = sqlSession.flushStatements();
            break;
        default:
            throw new BindingException("Unknown execution method for: " + this.command.getName());
        }

        if (result == null &amp;&amp; this.method.getReturnType().isPrimitive() &amp;&amp; !this.method.returnsVoid()) {
            throw new BindingException("Mapper method '" + this.command.getName() + " attempted to return null from a method with a primitive return type (" + this.method.getReturnType() + ").");
        } else {
            return result;
        }
    }</code></pre>

<p>可以看出是sqlsession通过xml中的sql id和参数在做CRUD操作，再看 result = this.executeForMany(sqlSession, args);方法</p>

<pre>
<code class="language-java">private &lt;E&gt; Object executeForMany(SqlSession sqlSession, Object[] args) {
        Object param = this.method.convertArgsToSqlCommandParam(args);
        List result;
        if (this.method.hasRowBounds()) {
            RowBounds rowBounds = this.method.extractRowBounds(args);
            result = sqlSession.selectList(this.command.getName(), param, rowBounds);
        } else {
            result = sqlSession.selectList(this.command.getName(), param);
        }

        if (!this.method.getReturnType().isAssignableFrom(result.getClass())) {
            return this.method.getReturnType().isArray() ? this.convertToArray(result) : this.convertToDeclaredCollection(sqlSession.getConfiguration(), result);
        } else {
            return result;
        }
    }</code></pre>

<p>进入 sqlSession.selectList(this.command.getName(), param, rowBounds);方法</p>

<pre>
<code class="language-java">public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds) {
        List var5;
        try {
            MappedStatement ms = this.configuration.getMappedStatement(statement);
            var5 = this.executor.query(ms, this.wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);
        } catch (Exception var9) {
            throw ExceptionFactory.wrapException("Error querying database.  Cause: " + var9, var9);
        } finally {
            ErrorContext.instance().reset();
        }

        return var5;
    }</code></pre>

<p>继续看 this.executor.query 方法</p>

<pre>
<code class="language-java">public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException {
        BoundSql boundSql = ms.getBoundSql(parameterObject);
        CacheKey key = this.createCacheKey(ms, parameterObject, rowBounds, boundSql);
        return this.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);
    }</code></pre>

<p>这里的cacheKey是通过 id +sql+limit+offsetxxx 等等参数确定一个缓存的key</p>

<p>接着看query方法：</p>

<pre>
<code class="language-java">public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
        // 获取二级缓存
        Cache cache = ms.getCache();
        if (cache != null) {
            // 根据ms来决定是否刷新缓存
            this.flushCacheIfRequired(ms);
            if (ms.isUseCache() &amp;&amp; resultHandler == null) {
                this.ensureNoOutParams(ms, boundSql);
                List&lt;E&gt; list = (List)this.tcm.getObject(cache, key);
                if (list == null) {
                    list = this.delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);
                    // 放入二级缓存
                    this.tcm.putObject(cache, key, list);
                }

                return list;
            }
        }

        return this.delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);
    }</code></pre>

<p>有缓存就从缓存中取，无缓存就调用初始化CachingExecutor时传入的SimpleExecutor的query方法，继续看 this.delegate.query 方法：</p>

<pre>
<code class="language-java">public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
        ErrorContext.instance().resource(ms.getResource()).activity("executing a query").object(ms.getId());
        if (this.closed) {
            throw new ExecutorException("Executor was closed.");
        } else {
            // 上一个查询执行完成 并且 &lt;select&gt;标签增加了flushCache="true" 刷新一级缓存
            if (this.queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) {
                this.clearLocalCache();
            }

            List list;
            try {
                ++this.queryStack;
                // 对于指定了resultHandler的查询，不走缓存。否则从缓存中查询。
                list = resultHandler == null ? (List)this.localCache.getObject(key) : null;
                if (list != null) {
                    // 如果存在缓存参数值，取出来覆盖当前参数值，只针对Callable
                    this.handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);
                } else {
                    // 缓存中没有，从数据库中查询放入缓存
                    list = this.queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);
                }
            } finally {
                --this.queryStack;
            }

            if (this.queryStack == 0) {
                Iterator var8 = this.deferredLoads.iterator();

                while(var8.hasNext()) {
                    BaseExecutor.DeferredLoad deferredLoad = (BaseExecutor.DeferredLoad)var8.next();
                    deferredLoad.load();
                }

                this.deferredLoads.clear();
                // 如果cacheScope配置了statement，查询完后清除缓存
                if (this.configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) {
                    this.clearLocalCache();
                }
            }

            return list;
        }
    }</code></pre>

<p>再看 queryFromDatabase 方法：</p>

<pre>
<code class="language-java">private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
        // 放入一个初始值
        this.localCache.putObject(key, ExecutionPlaceholder.EXECUTION_PLACEHOLDER);

        List list;
        try {
            list = this.doQuery(ms, parameter, rowBounds, resultHandler, boundSql);
        } finally {
            this.localCache.removeObject(key);
        }
        // 放入一级缓存
        this.localCache.putObject(key, list);
        if (ms.getStatementType() == StatementType.CALLABLE) {
            this.localOutputParameterCache.putObject(key, parameter);
        }

        return list;
    }</code></pre>

<p>可以看到上面的查询方法先是看&lt;select&gt;有没有flushCache=”true”，有就刷新一级缓存，没有的话先去从一级缓存取数据，如果一级缓存里没有结果，调用<code>queryFromDatabase</code>方法，从数据库查询结果并返回。</p>

<p>一级缓存的范围有 <code>SESSION</code> 和 <code>STATEMENT</code> 两种，默认是 <code>SESSION</code> ，如果我们不需要使用一级缓存，那么我们可以把一级缓存的范围指定为STATEMENT，这样每次执行完一个Mapper语句后都会将一级缓存清除。如果需要更改一级缓存的范围，请在Mybatis的配置文件中，在&lt;settings&gt;下通过localCacheScope指定。</p>

<p>至此，一次完整的Mybatis执行过程到此结束。</p>

<p> </p>

<p>需要注意的是与spring整合之后，mybatis的一级缓存就失效了</p>

<p>1.mybatis的一级缓存生效的范围是sqlsession，是为了在sqlsession没有关闭时，业务需要重复查询相同数据使用的。一旦sqlsession关闭，则由这个sqlsession缓存的数据将会被清空。</p>

<p>2.spring对mybatis的sqlsession的使用是由template控制的，sqlSessionTemplate又被spring当作resource放在当前线程的上下文里（threadlocal),spring通过mybatis调用数据库的过程如下：</p>

<blockquote>
<ol><li>我们需要访问数据</li>
    <li>spring检查到了这种需求，于是去申请一个mybatis的sqlsession（资源池），并将申请到的sqlsession与当前线程绑定，放入threadlocal里面</li>
    <li>sqlSessionTemplate从threadlocal获取到sqlsession，去执行查询</li>
    <li>查询结束，清空threadlocal中与当前线程绑定的sqlsession，释放资源</li>
    <li>我们又需要访问数据</li>
    <li>返回到步骤2</li>
</ol><p>通过以上步骤后发现，同一线程里面两次查询同一数据所使用的sqlsession是不相同的，所以，给人的印象就是结合spring后，mybatis的一级缓存失效了。</p>
</blockquote>

<p>对于spring开启事务时，getSqlSession方法里面维护了个SqlSessionHolder，关联了事务与session，如果存在则直接取出，否则则新建个session，所以在有事务的里，每个session都是同一个，故能用上缓存了。</p>

<p> </p>
]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
  </entry>
  <entry>
    <title>MyBatis源码解析(一)——MyBatis初始化过程解析</title>
    <url>/2020/03/01/MyBatis%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%80)%E2%80%94%E2%80%94MyBatis%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<a id="more"></a>

<h1>1. 准备工作</h1>

<p>为了看清楚MyBatis的整个初始化过程，先创建一个简单的Java项目，目录结构如下图所示：</p>

<p> </p>

<p><img alt src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yOTk0NjA0LTk0Y2EzOTk4YmVlMGFiYjcucG5nP2ltYWdlTW9ncjIvYXV0by1vcmllbnQvc3RyaXB8aW1hZ2VWaWV3Mi8yL3cvMjk0L2Zvcm1hdC93ZWJw?x-oss-process=image/format,png"></p>

<h2>1.1 Product 产品实体类</h2>

<p> </p>

<pre>
<code>public class Product {
    private long id;
    private String productName;
    private String productContent;
    private String price;
    private int sort;
    private int falseSales;
    private long category_id;
    private byte type;
    private byte state;
    // PS：省略setter、getter函数
}
</code></pre>

<h2>1.2 ProductMapper 产品持久化接口</h2>

<p> </p>

<pre>
<code>public interface ProductMapper {
    /**
     * 查询所有的产品
     * @return
     */
    List&lt;Product&gt; selectProductList();
}
</code></pre>

<h2>1.3 ProductMapper.xml 产品映射文件</h2>

<p> </p>

<pre>
<code>&lt;?xml version="1.0" encoding="UTF-8" ?&gt;
&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" &gt;

&lt;mapper namespace="team.njupt.mapper.ProductMapper"&gt;
    &lt;select id="selectProductList" resultType="team.njupt.entity.Product"&gt;
        select * from product
    &lt;/select&gt;
&lt;/mapper&gt;
</code></pre>

<h2>1.4 db.properties 数据库配置文件</h2>

<p> </p>

<pre>
<code>driver=com.mysql.jdbc.Driver
url=jdbc:mysql://127.0.0.1:3306/waimai?useUnicode=true&amp;characterEncoding=utf8
username=root
password=xxxxxx
</code></pre>

<h2>1.5 mybatis.xml MyBatis的配置文件</h2>

<p> </p>

<pre>
<code>&lt;?xml version="1.0" encoding="UTF-8" ?&gt;
&lt;!DOCTYPE configuration
        PUBLIC "-//mybatis.org//DTD Config 3.0//EN"
        "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;
&lt;configuration&gt;
    &lt;properties resource="db.properties"&gt;
        &lt;!--&lt;property name="username" value="dev_user"/&gt;--&gt;
        &lt;!--&lt;property name="password" value="F2Fa3!33TYyg"/&gt;--&gt;
    &lt;/properties&gt;

    &lt;environments default="development"&gt;
        &lt;environment id="development"&gt;
            &lt;transactionManager type="JDBC"/&gt;
            &lt;dataSource type="POOLED"&gt;
                &lt;property name="driver" value="${driver}"/&gt;
                &lt;property name="url" value="${url}"/&gt;
                &lt;property name="username" value="${username}"/&gt;
                &lt;property name="password" value="${password}"/&gt;
            &lt;/dataSource&gt;
        &lt;/environment&gt;
    &lt;/environments&gt;
    &lt;mappers&gt;
        &lt;mapper resource="team/njupt/mapper/ProductMapper.xml"/&gt;
    &lt;/mappers&gt;
&lt;/configuration&gt;
</code></pre>

<h2>1.6 Main 主函数</h2>

<p> </p>

<pre>
<code>public class Main {
    public static void main(String[] args) throws IOException {

        String resource = "mybatis.xml";
        InputStream inputStream = Resources.getResourceAsStream(resource);
        SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);

        SqlSession sqlSession = sqlSessionFactory.openSession();
        try {
            ProductMapper productMapper = sqlSession.getMapper(ProductMapper.class);
            List&lt;Product&gt; productList = productMapper.selectProductList();
            for (Product product : productList) {
                System.out.printf(product.toString());
            }
        } finally {
            sqlSession.close();
        }
    }
}
</code></pre>

<hr><h1>2. MyBatis初始化过程</h1>

<h2>2.1 获取配置文件</h2>

<p>当系统初始化时，首先会读取配置文件，并将其解析成InputStream</p>

<p> </p>

<pre>
<code>String resource = "mybatis.xml";
InputStream inputStream = Resources.getResourceAsStream(resource);
</code></pre>

<h2>2.2 创建SqlSessionFactoryBuilder对象</h2>

<p>从<code>SqlSessionFactoryBuilder</code>的名字中可以看出，<code>SqlSessionFactoryBuilder</code>是用来创建<code>SqlSessionFactory</code>对象的。<br>
来看一下SqlSessionFactoryBuilder源码：</p>

<p><img alt src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yOTk0NjA0LWIwZjNlOTk1YWM1NmYyMGEucG5nP2ltYWdlTW9ncjIvYXV0by1vcmllbnQvc3RyaXB8aW1hZ2VWaWV3Mi8yL3cvMzQ5L2Zvcm1hdC93ZWJw?x-oss-process=image/format,png"></p>

<p><br>
SqlSessionFactoryBuilder中只有一些重载的build函数，这些build函数的入参都是MyBatis配置文件的输入流，返回值都是SqlSessionFactory；由此可见，SqlSessionFactoryBuilder的作用很纯粹，就是用来通过配置文件创建SqlSessionFactory对象的。</p>

<p> </p>

<h2>2.3 SqlSessionFactory创建过程</h2>

<p>下面具体来看一下，build函数是如何创建SqlSessionFactory对象的。</p>

<p> </p>

<pre>
<code>public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) {
  try {
    XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties);
    return build(parser.parse());
  } catch (Exception e) {
    throw ExceptionFactory.wrapException("Error building SqlSession.", e);
  } finally {
    ErrorContext.instance().reset();
    try {
      inputStream.close();
    } catch (IOException e) {
      // Intentionally ignore. Prefer previous error.
    }
  }
}
</code></pre>

<p>2.3.1 构造XMLConfigBuilder对象</p>

<p>build函数首先会构造一个<code>XMLConfigBuilder</code>对象，从名字上大致可以猜到，该对象是用来解析XML配置文件的。下面来看一下<code>XMLConfigBuilder</code>的体系结构。</p>

<p><img alt src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yOTk0NjA0LTM5OThmOTcyYTZhNGUyNTEucG5nP2ltYWdlTW9ncjIvYXV0by1vcmllbnQvc3RyaXB8aW1hZ2VWaWV3Mi8yL3cvNzQ4L2Zvcm1hdC93ZWJw?x-oss-process=image/format,png"></p>

<p> </p>

<ul><li>
    <p><code>XMLxxxBuilder</code>是用来解析XML配置文件的，不同类型<code>XMLxxxBuilder</code>用来解析MyBatis配置文件的不同部位。比如：<code>XMLConfigBuilder</code>用来解析MyBatis的配置文件，<code>XMLMapperBuilder</code>用来解析MyBatis中的映射文件（如上文提到的<code>ProductMapper.xml</code>），<code>XMLStatementBuilder</code>用来解析映射文件中的SQL语句。</p>
    </li>
    <li>
    <p>这些<code>XMLxxxBuilder</code>都有一个共同的父类——<code>BaseBuilder</code>。这个父类维护了一个全局的<code>Configuration</code>对象，MyBatis的配置文件解析后就以<code>Configuration</code>对象的形式存储。</p>
    </li>
    <li>
    <p>当创建<code>XMLConfigBuilder</code>对象时，就会初始化<code>Configuration</code>对象，并且在初始化<code>Configuration</code>对象的时候，一些别名会被注册到<code>Configuration</code>的<code>typeAliasRegistry</code>容器中。</p>

<pre><code>&lt;pre&gt;</code></pre><p><code>private XMLConfigBuilder(XPathParser parser, String environment, Properties props) {<br>super(new Configuration());<br>ErrorContext.instance().resource("SQL Mapper Configuration");<br>this.configuration.setVariables(props);<br>this.parsed = false;<br>this.environment = environment;<br>this.parser = parser;<br>}<br></code></p>
<pre><code>&lt;pre&gt;</code></pre><p><code>public Configuration() {<br>typeAliasRegistry.registerAlias("JDBC", JdbcTransactionFactory.class);<br>typeAliasRegistry.registerAlias("MANAGED", ManagedTransactionFactory.class);</code></p>
<p>typeAliasRegistry.registerAlias("JNDI", JndiDataSourceFactory.class);<br>typeAliasRegistry.registerAlias("POOLED", PooledDataSourceFactory.class);<br>typeAliasRegistry.registerAlias("UNPOOLED", UnpooledDataSourceFactory.class);</p>
<p>typeAliasRegistry.registerAlias("PERPETUAL", PerpetualCache.class);<br>typeAliasRegistry.registerAlias("FIFO", FifoCache.class);<br>typeAliasRegistry.registerAlias("LRU", LruCache.class);<br>typeAliasRegistry.registerAlias("SOFT", SoftCache.class);<br>typeAliasRegistry.registerAlias("WEAK", WeakCache.class);<br>……<br>}<br><br>    </p></li><p></p>
</ul><h3>2.3.2 解析配置文件</h3>

<p>当有了<code>XMLConfigBuilder</code>对象之后，接下来就可以用它来解析配置文件了。</p>

<p> </p>

<pre>
<code>  private void parseConfiguration(XNode root) {
  try {
    // 解析&lt;properties&gt;节点
    propertiesElement(root.evalNode("properties"));
    // 解析&lt;settings&gt;节点
    Properties settings = settingsAsProperties(root.evalNode("settings"));
    loadCustomVfs(settings);
    // 解析&lt;typeAliases&gt;节点
    typeAliasesElement(root.evalNode("typeAliases"));
    // 解析&lt;plugins&gt;节点
    pluginElement(root.evalNode("plugins"));
    // 解析&lt;objectFactory&gt;节点
    objectFactoryElement(root.evalNode("objectFactory"));
    objectWrapperFactoryElement(root.evalNode("objectWrapperFactory"));
    // 解析&lt;reflectorFactory&gt;节点
    reflectorFactoryElement(root.evalNode("reflectorFactory"));
    settingsElement(settings);
    // 解析&lt;environments&gt;节点
    environmentsElement(root.evalNode("environments"));
    databaseIdProviderElement(root.evalNode("databaseIdProvider"));
    typeHandlerElement(root.evalNode("typeHandlers"));
    // 解析&lt;mappers&gt;节点
    mapperElement(root.evalNode("mappers"));
  } catch (Exception e) {
    throw new BuilderException("Error parsing SQL Mapper Configuration. Cause: " + e, e);
  }
}
</code></pre>

<p>从上述代码中可以看到，<code>XMLConfigBuilder</code>会依次解析配置文件中的<code>&lt;properties&gt;</code>、<code>&lt; settings &gt;</code>、<code>&lt; environments&gt;</code>、<code>&lt; typeAliases &gt;</code>、<code>&lt; plugins &gt;</code>、<code>&lt; mappers &gt;</code>等属性。下面介绍下几个重要属性的解析过程。</p>

<p>2.3.2.1 &lt;properties&gt;节点的解析过程</p>

<ul><li>
    <p>&lt;properties&gt;节点的定义如下：</p>

<pre><code>&lt;pre&gt;</code></pre><p><code class="language-java">&lt;properties resource="org/mybatis/example/config.properties"&gt;<br>  &lt;property name="username" value="dev_user"/&gt;<br>  &lt;property name="password" value="F2Fa3!33TYyg"/&gt;<br>&lt;/properties&gt;<br></code><br>    </p></li><p></p>
</ul><p> </p>

<ul><li>
    <p>&lt;properties&gt;节点的解析过程：</p>

<pre><code>&lt;pre&gt;</code></pre><p><code>/**</code></p>
<ul>
<li><p>@Param context &lt;properties&gt;节点</p>
</li>
<li><p>/<br>private void propertiesElement(XNode context) throws Exception {<br>if (context != null) {<br> // 获取&lt;properties&gt;节点的所有子节点<br> Properties defaults = context.getChildrenAsProperties();<br> // 获取&lt;properties&gt;节点上的resource属性<br> String resource = context.getStringAttribute("resource");<br> // 获取&lt;properties&gt;节点上的url属性<br> String url = context.getStringAttribute("url");<br> // resource和url不能同时存在<br> if (resource != null &amp;&amp; url != null) {<br>   throw new BuilderException("The properties element cannot specify both a URL and a resource based property file reference.  Please specify one or the other.");<br> }<br> if (resource != null) {<br>   // 获取resource属性值对应的properties文件中的键值对，并添加至defaults容器中<br>   defaults.putAll(Resources.getResourceAsProperties(resource));<br> } else if (url != null) {<br>   // 获取url属性值对应的properties文件中的键值对，并添加至defaults容器中<br>   defaults.putAll(Resources.getUrlAsProperties(url));<br> }<br> // 获取configuration中原本的属性，并添加至defaults容器中<br> Properties vars = configuration.getVariables();<br> if (vars != null) {<br>   defaults.putAll(vars);<br> }<br> parser.setVariables(defaults);<br> // 将defaults容器添加至configuration中<br> configuration.setVariables(defaults);<br>}<br>}<br></p>
 <p>如果属性在不只一个地方进行了配置，那么 MyBatis 将按照下面的顺序来加载：</p>
 </li>
 <li>在 properties 元素体内指定的属性首先被读取。</li>
 <li>然后根据 properties 元素中的 resource 属性读取类路径下属性文件或根据 url 属性指定的路径读取属性文件，并覆盖已读取的同名属性。</li>
</ul><p>因此，通过方法参数传递的属性具有最高优先级，resource/url 属性中指定的配置文件次之，最低优先级的是 properties 属性中指定的属性。</p>

</li>
</ul>
<ul><li>最终，携带所有属性的<code>Properties</code>对象会被存储在<code>Configuration</code>对象中。</li>
</ul><p>2.3.2.2 &lt;settings&gt;节点的解析过程</p>

<ul><li>&lt;settings&gt;节点的定义如下：
    <pre>
<code>&lt;settings&gt;
  &lt;setting name="cacheEnabled" value="true"/&gt;
  &lt;setting name="lazyLoadingEnabled" value="true"/&gt;
  &lt;setting name="multipleResultSetsEnabled" value="true"/&gt;
&lt;/settings&gt;
</code></pre>
    </li>
    <li>&lt;settings&gt;节点的解析过程：<br><code>&lt;settings&gt;</code>属性的解析过程和 <code>&lt;properties&gt;</code>属性的解析过程极为类似，这里不再赘述。最终，所有的setting属性都被存储在<code>Configuration</code>对象中。</li>
</ul><p>2.3.2.3 &lt;typeAliases&gt;属性的解析过程</p>

<p><code>&lt;typeAliases&gt;</code>属性的定义方式有如下两种：</p>

<ul><li>方式1：
    <pre>
<code>&lt;typeAliases&gt;
  &lt;typeAlias alias="Author" type="domain.blog.Author"/&gt;
  &lt;typeAlias alias="Blog" type="domain.blog.Blog"/&gt;
&lt;/typeAliases&gt;
</code></pre>
    </li>
    <li>方式2：
    <pre>
<code>&lt;typeAliases&gt;
  &lt;package name="domain.blog"/&gt;
&lt;/typeAliases&gt;
</code></pre>
    采用这种方式时，MyBatis会为指定包下的所有类起一个别名，该别名为首字母小写的类名。</li>
</ul><p><code>&lt;typeAliases&gt;</code>节点的解析过程如下：</p>

<p> </p>

<pre>
<code>  private void typeAliasesElement(XNode parent) {
  if (parent != null) {
    // 遍历&lt;typeAliases&gt;下的所有子节点
    for (XNode child : parent.getChildren()) {
      // 若当前结点为&lt;package&gt;
      if ("package".equals(child.getName())) {
        // 获取&lt;package&gt;上的name属性（包名）
        String typeAliasPackage = child.getStringAttribute("name");
        // 为该包下的所有类起个别名，并注册进configuration的typeAliasRegistry中          
        configuration.getTypeAliasRegistry().registerAliases(typeAliasPackage);
      } 
      // 如果当前结点为&lt; typeAlias &gt;
      else {
        // 获取alias和type属性
        String alias = child.getStringAttribute("alias");
        String type = child.getStringAttribute("type");
        // 注册进configuration的typeAliasRegistry中
        try {
          Class&lt;?&gt; clazz = Resources.classForName(type);
          if (alias == null) {
            typeAliasRegistry.registerAlias(clazz);
          } else {
            typeAliasRegistry.registerAlias(alias, clazz);
          }
        } catch (ClassNotFoundException e) {
          throw new BuilderException("Error registering typeAlias for '" + alias + "'. Cause: " + e, e);
        }
      }
    }
  }
}
</code></pre>

<ul><li>如果<code>&lt;typeAliases&gt;</code>节点下定义了<code>&lt;package&gt;</code>节点，那么MyBatis会给该包下的所有类起一个别名（以类名首字母小写作为别名）</li>
    <li>如果<code>&lt;typeAliases&gt;</code>节点下定义了<code>&lt;typeAlias&gt;</code>节点，那么MyBatis就会给指定的类起指定的别名。</li>
    <li>这些别名都会被存入<code>configuration</code>的<code>typeAliasRegistry</code>容器中。</li>
</ul><p>2.3.2.4 &lt;mappers&gt;节点的解析过程</p>

<p><code>&lt;mappers&gt;</code>节点的定义方式有如下四种：</p>

<ul><li>方式1：</li>
</ul><p> </p>

<pre>
<code>&lt;mappers&gt;
  &lt;package name="org.mybatis.builder"/&gt;
&lt;/mappers&gt;
</code></pre>

<ul><li>方式2：</li>
</ul><p> </p>

<pre>
<code>&lt;mappers&gt;
  &lt;mapper resource="org/mybatis/builder/AuthorMapper.xml"/&gt;
&lt;/mappers&gt;
</code></pre>

<ul><li>方式3：</li>
</ul><p> </p>

<pre>
<code>&lt;mappers&gt;
  &lt;mapper url="file:///var/mappers/AuthorMapper.xml"/&gt;
&lt;/mappers&gt;
</code></pre>

<ul><li>方式4：</li>
</ul><p> </p>

<pre>
<code>&lt;mappers&gt;
  &lt;mapper class="org.mybatis.builder.AuthorMapper"/&gt;
&lt;/mappers&gt;
</code></pre>

<p><code>&lt;mappers&gt;</code>节点的解析过程如下：</p>

<p> </p>

<pre>
<code>  private void mapperElement(XNode parent) throws Exception {
  if (parent != null) {
    // 遍历&lt;mappers&gt;下所有子节点
    for (XNode child : parent.getChildren()) {
      // 如果当前节点为&lt;package&gt;
      if ("package".equals(child.getName())) {
        // 获取&lt;package&gt;的name属性（该属性值为mapper class所在的包名）
        String mapperPackage = child.getStringAttribute("name");
        // 将该包下的所有Mapper Class注册到configuration的mapperRegistry容器中
        configuration.addMappers(mapperPackage);
      } 
      // 如果当前节点为&lt;mapper&gt;
      else {
        // 依次获取resource、url、class属性
        String resource = child.getStringAttribute("resource");
        String url = child.getStringAttribute("url");
        String mapperClass = child.getStringAttribute("class");
        // 解析resource属性（Mapper.xml文件的路径）
        if (resource != null &amp;&amp; url == null &amp;&amp; mapperClass == null) {
          ErrorContext.instance().resource(resource);
          // 将Mapper.xml文件解析成输入流
          InputStream inputStream = Resources.getResourceAsStream(resource);
          // 使用XMLMapperBuilder解析Mapper.xml，并将Mapper Class注册进configuration对象的mapperRegistry容器中
          XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments());
          mapperParser.parse();
        } 
        // 解析url属性（Mapper.xml文件的路径）
        else if (resource == null &amp;&amp; url != null &amp;&amp; mapperClass == null) {
          ErrorContext.instance().resource(url);
          InputStream inputStream = Resources.getUrlAsStream(url);
          XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, url, configuration.getSqlFragments());
          mapperParser.parse();
        } 
        // 解析class属性（Mapper Class的全限定名）
        else if (resource == null &amp;&amp; url == null &amp;&amp; mapperClass != null) {
          // 将Mapper Class的权限定名转化成Class对象
          Class&lt;?&gt; mapperInterface = Resources.classForName(mapperClass);
          // 注册进configuration对象的mapperRegistry容器中
          configuration.addMapper(mapperInterface);
        } else {
          throw new BuilderException("A mapper element may only specify a url, resource or class, but not more than one.");
        }
      }
    }
  }
}
</code></pre>

<ul><li>MyBatis会遍历<code>&lt;mappers&gt;</code>下所有的子节点，如果当前遍历到的节点是<code>&lt;package&gt;</code>，则MyBatis会将该包下的所有Mapper Class注册到<code>configuration</code>的<code>mapperRegistry</code>容器中。</li>
    <li>如果当前节点为<code>&lt;mapper&gt;</code>，则会依次获取resource、url、class属性，解析映射文件，并将映射文件对应的Mapper Class注册到<code>configuration</code>的<code>mapperRegistry</code>容器中。</li>
</ul><p>其中，<code>&lt;mapper&gt;</code>节点的解析过程如下：</p>

<p> </p>

<pre>
<code>XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments());
mapperParser.parse();
</code></pre>

<ul><li>
    <p>在解析前，首先需要创建<code>XMLMapperBuilder</code>，创建过程如下：</p>

<pre><code>&lt;pre&gt;</code></pre><p><code>private XMLMapperBuilder(XPathParser parser, Configuration configuration, String resource, Map&lt;String, XNode&gt; sqlFragments) {<br>  // 将configuration赋给BaseBuilder<br>  super(configuration);<br>  // 创建MapperBuilderAssistant对象（该对象为MapperBuilder的协助者）<br>  this.builderAssistant = new  MapperBuilderAssistant(configuration, resource);<br>  this.parser = parser;<br>  this.sqlFragments = sqlFragments;<br>  this.resource = resource;<br>}<br></code></p>
<pre><code>&lt;ul&gt;&lt;li&gt;首先会初始化父类&lt;code&gt;BaseBuilder&lt;/code&gt;，并将&lt;code&gt;configuration&lt;/code&gt;赋给BaseBuilder；&lt;/li&gt;
    &lt;li&gt;然后创建&lt;code&gt;MapperBuilderAssistant&lt;/code&gt;对象，该对象为&lt;code&gt;XMLMapperBuilder&lt;/code&gt;的协助者，用来协助&lt;code&gt;XMLMapperBuilder&lt;/code&gt;完成一些解析映射文件的动作。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;当有了&lt;code&gt;XMLMapperBuilder&lt;/code&gt;后，便可进入解析&lt;code&gt;&amp;lt;mapper&amp;gt;&lt;/code&gt;的过程：&lt;/p&gt;

&lt;pre&gt;</code></pre><p><code>public void parse() {<br>  // 若当前的Mapper.xml尚未被解析，则开始解析<br>  // PS：若&lt;mappers&gt;节点下有相同的&lt;mapper&gt;节点，那么就无需再次解析了<br>  if (!configuration.isResourceLoaded(resource)) {<br>    // 解析&lt;mapper&gt;节点<br>    configurationElement(parser.evalNode("/mapper"));<br>    // 将该Mapper.xml添加至configuration的LoadedResource容器中，下回无需再解析<br>    configuration.addLoadedResource(resource);<br>    // 将该Mapper.xml对应的Mapper Class注册进configuration的mapperRegistry容器中<br>    bindMapperForNamespace();<br>  }</code></p>
<p>  parsePendingResultMaps();<br>  parsePendingCacheRefs();<br>  parsePendingStatements();<br>}<br><br>    </p></li><br>    <li><br>    <p><code>configurationElement</code>函数</p><p></p>
<pre><code>&lt;pre&gt;</code></pre><p><code>private void configurationElement(XNode context) {<br>try {<br>  // 获取&lt;mapper&gt;节点上的namespace属性，该属性必须存在，表示当前映射文件对应的Mapper Class是谁<br>  String namespace = context.getStringAttribute("namespace");<br>  if (namespace == null || namespace.equals("")) {<br>    throw new BuilderException("Mapper's namespace cannot be empty");<br>  }<br>  // 将namespace属性值赋给builderAssistant<br>  builderAssistant.setCurrentNamespace(namespace);<br>  // 解析&lt;cache-ref&gt;节点<br>  cacheRefElement(context.evalNode("cache-ref"));<br>  // 解析&lt;cache&gt;节点<br>  cacheElement(context.evalNode("cache"));<br>  // 解析&lt;parameterMap&gt;节点<br>  parameterMapElement(context.evalNodes("/mapper/parameterMap"));<br>  // 解析&lt;resultMap&gt;节点<br>  resultMapElements(context.evalNodes("/mapper/resultMap"));<br>  // 解析&lt;sql&gt;节点<br>  sqlElement(context.evalNodes("/mapper/sql"));<br>  // 解析sql语句<br>  buildStatementFromContext(context.evalNodes("select|insert|update|delete"));<br>} catch (Exception e) {<br>  throw new BuilderException("Error parsing Mapper XML. Cause: " + e, e);<br>}<br>}<br></code><br>    </p></li><br>    <li><br>    <p><code>resultMapElements</code>函数<br><br>    该函数用于解析映射文件中所有的<code>&lt;resultMap&gt;</code>节点，这些节点会被解析成<code>ResultMap</code>对象，存储在<code>Configuration</code>对象的<code>resultMaps</code>容器中。</p><p></p>
<pre><code>&lt;ul&gt;&lt;li&gt;&lt;code&gt;&amp;lt;resultMap&amp;gt;&lt;/code&gt;节点定义如下：&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;</code></pre><p><code> &lt;resultMap id="userResultMap" type="User"&gt;<br>  &lt;constructor&gt;<br>     &lt;idArg column="id" javaType="int"/&gt;<br>     &lt;arg column="username" javaType="String"/&gt;<br>  &lt;/constructor&gt;<br>  &lt;result property="username" column="user_name"/&gt;<br>  &lt;result property="password" column="hashed_password"/&gt;<br>&lt;/resultMap&gt;<br></code></p>
<pre><code>&lt;ul&gt;&lt;li&gt;&lt;code&gt;&amp;lt;resultMap&amp;gt;&lt;/code&gt;节点的解析过程：&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;</code></pre><p><code>private ResultMap resultMapElement(XNode resultMapNode, List&lt;ResultMapping&gt; additionalResultMappings) throws Exception {<br>  ErrorContext.instance().activity("processing " + resultMapNode.getValueBasedIdentifier());<br>  // 获取&lt;ResultMap&gt;上的id属性<br>  String id = resultMapNode.getStringAttribute("id",<br>    resultMapNode.getValueBasedIdentifier());<br>  // 获取&lt;ResultMap&gt;上的type属性（即resultMap的返回值类型）<br>  String type = resultMapNode.getStringAttribute("type",<br>    resultMapNode.getStringAttribute("ofType",<br>        resultMapNode.getStringAttribute("resultType",<br>            resultMapNode.getStringAttribute("javaType"))));<br>  // 获取extends属性<br>  String extend = resultMapNode.getStringAttribute("extends");<br>  // 获取autoMapping属性<br>  Boolean autoMapping = resultMapNode.getBooleanAttribute("autoMapping");<br>  // 将resultMap的返回值类型转换成Class对象<br>  Class&lt;?&gt; typeClass = resolveClass(type);<br>  Discriminator discriminator = null;<br>  // resultMappings用于存储&lt;resultMap&gt;下所有的子节点<br>  List&lt;ResultMapping&gt; resultMappings = new ArrayList&lt;ResultMapping&gt;();<br>  resultMappings.addAll(additionalResultMappings);<br>  // 获取并遍历&lt;resultMap&gt;下所有的子节点<br>  List&lt;XNode&gt; resultChildren = resultMapNode.getChildren();<br>  for (XNode resultChild : resultChildren) {<br>    // 若当前节点为&lt;constructor&gt;，则将它的子节点们添加到resultMappings中去<br>    if ("constructor".equals(resultChild.getName())) {<br>      processConstructorElement(resultChild, typeClass, resultMappings);<br>    }<br>    // 若当前节点为&lt;discriminator&gt;，则进行条件判断，并将命中的子节点添加到resultMappings中去<br>    else if ("discriminator".equals(resultChild.getName())) {<br>      discriminator = processDiscriminatorElement(resultChild, typeClass, resultMappings);<br>    }<br>    // 若当前节点为&lt;result&gt;、&lt;association&gt;、&lt;collection&gt;，则将其添加到resultMappings中去<br>    else {<br>      // PS:flags仅用于区分当前节点是否是&lt;id&gt;或&lt;idArg&gt;，因为这两个节点的属性名为name，而其他节点的属性名为property<br>      List&lt;ResultFlag&gt; flags = new ArrayList&lt;ResultFlag&gt;();<br>      if ("id".equals(resultChild.getName())) {<br>        flags.add(ResultFlag.ID);<br>      }<br>      resultMappings.add(buildResultMappingFromContext(resultChild, typeClass, flags));<br>    }<br>  }<br>  // ResultMapResolver的作用是生成ResultMap对象，并将其加入到Configuration对象的resultMaps容器中（具体过程见下）<br>  ResultMapResolver resultMapResolver = new ResultMapResolver(builderAssistant, id, typeClass, extend, discriminator, resultMappings, autoMapping);<br>  try {<br>    return resultMapResolver.resolve();<br>  } catch (IncompleteElementException  e) {<br>    configuration.addIncompleteResultMap(resultMapResolver);<br>    throw e;<br>  }<br>}<br></code></p>
<pre><code>&lt;p&gt;&lt;code&gt;ResultMapResolver&lt;/code&gt;这个类很纯粹，有且仅有一个函数&lt;code&gt;resolve&lt;/code&gt;，用于构造&lt;code&gt;ResultMap&lt;/code&gt;对象，并将其存入Configuration对象的resultMaps容器中；而这个过程是借助于&lt;code&gt;MapperBuilderAssistant.addResultMap&lt;/code&gt;完成的。&lt;/p&gt;

&lt;pre&gt;</code></pre><p><code>public ResultMap resolve() {<br>  return assistant.addResultMap(this.id, this.type, this.extend,  this.discriminator, this.resultMappings, this.autoMapping);<br>}<br></code><br>    </p></li><br>    <li><br>    <p><code>sqlElement</code>函数<br><br>    该函数用于解析映射文件中所有的<code>&lt;sql&gt;</code>节点，并将这些节点存储在当前映射文件所对应的XMLMapperBuilder对象的sqlFragments容器中，供解析sql语句时使用。</p><p></p>
<pre><code>&lt;pre&gt;</code></pre><p><code>&lt;sql id="userColumns"&gt; ${alias}.id,${alias}.username,${alias}.password &lt;/sql&gt;<br></code><br>    </p></li><p></p>
</ul><ul><li><code>buildStatementFromContext</code>函数<br>
    该函数会将映射文件中的sql语句解析成<code>MappedStatement</code>对象，并存在<code>configuration</code>的<code>mappedStatements</code>。</li>
</ul><h3>2.3.3 创建SqlSessionFactory对象</h3>

<p> </p>

<pre>
<code>public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) {
  try {
    XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties);
    return build(parser.parse());
  } catch (Exception e) {
    throw ExceptionFactory.wrapException("Error building SqlSession.", e);
  } finally {
    ErrorContext.instance().reset();
    try {
      inputStream.close();
    } catch (IOException e) {
      // Intentionally ignore. Prefer previous error.
    }
  }
}
</code></pre>

<p>回过头来再看一下<code>SqlSessionFactory</code>的<code>build</code>函数，刚才说了半天，介绍了<code>XMLConfigBuilder</code>解析映射文件的过程，解析完成之后<code>parser.parse()</code>函数会返回一个包含了映射文件解析结果的<code>configuration</code>对象，紧接着，这个对象将作为参数传递给另一个build函数，如下：</p>

<p> </p>

<pre>
<code>  public SqlSessionFactory build(Configuration config) {
    return new DefaultSqlSessionFactory(config);
  }
</code></pre>

<p>这个函数将<code>configuration</code>作为参数，创建了<code>DefaultSqlSessionFactory</code>对象。<br><code>DefaultSqlSessionFactory</code>是接口<code>SqlSessionFactory</code>的一个实现类，<code>SqlSessionFactory</code>的体系结构如下图所示：</p>

<p><img alt src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yOTk0NjA0LWRhMmRiZDhmMWYyYWM4NDQucG5nP2ltYWdlTW9ncjIvYXV0by1vcmllbnQvc3RyaXB8aW1hZ2VWaWV3Mi8yL3cvNDM2L2Zvcm1hdC93ZWJw?x-oss-process=image/format,png"></p>

<p> </p>

<p>此时，<code>SqlSessionFactory</code>创建完毕！</p>
]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
  </entry>
  <entry>
    <title>Nginx的反向代理和负载均衡</title>
    <url>/2019/12/08/Nginx%E7%9A%84%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</url>
    <content><![CDATA[<a id="more"></a>

<h2>一、Nginx配置虚拟主机</h2>

<ul><li>什么是虚拟主机？ </li>
</ul><p>       虚拟主机是一种特殊的软硬件技术，它可以将网络上的每一台计算机分成多个虚拟主机，每个虚拟主机可以独立对外提供www服务，这样就可以实现一台主机对外提供多个web服务，每个虚拟主机之间是独立的，互不影响的。 </p>

<p>     通过nginx可以实现虚拟主机的配置，nginx支持三种类型的虚拟主机配置，1、基于ip的虚拟主机， 2、基于域名的虚拟主机 3、基于端口的虚拟主机。</p>

<h3><strong>1.1  基于ip的虚拟主机配置</strong></h3>

<p>      Linux操作系统允许添加IP别名，IP别名就是在一块物理网卡上绑定多个lP地址。这样就能够在使用单一网卡的同一个服务器上运行多个基于IP的虚拟主机。</p>

<p>一台nginx服务器绑定两个ip：192.168.101.3、192.168.101.103   </p>

<p>访问不同的ip请求不同的html目录，即：</p>

<p style="margin-left:0cm;">访问http://192.168.101.3将访问“html3”目录下的html网页</p>

<p>访问http://192.168.101.103将访问“html103”目录下的html网页</p>

<p><strong>1.1.1 创建html文件夹</strong></p>

<p>将原来nginx的html目录拷贝两个目录 “html3”和“html103”，为了方便测试需要修改每个目录下的index.html内容使之个性化。</p>

<p><strong>1.1.2 绑定多ip：</strong></p>

<p style="margin-left:0cm;">1、将/etc/sysconfig/network-scripts/ifcfg-eth0文件复制一份，命名为ifcfg-eth0:1</p>

<p style="margin-left:0cm;">修改其中内容：</p>

<p style="margin-left:0cm;">DEVICE=eth0:1</p>

<p style="margin-left:0cm;">IPADDR=192.168.25.103</p>

<p style="margin-left:0cm;">其他项不用修改</p>

<p style="margin-left:0cm;">2、重启系统</p>

<p style="margin-left:0cm;"><strong>1.1.3 配置虚拟主机</strong></p>

<p style="margin-left:0cm;">修改/usr/local/nginx/conf/nginx.conf文件，添加两个虚拟主机，如下：</p>

<pre class="has">
<code class="language-bash">#user  nobody;
worker_processes  1;

events {
    worker_connections  1024;
}

http {
    include       mime.types;
    default_type  application/octet-stream;

    sendfile        on;

    keepalive_timeout  65;
    #配置虚拟主机192.168.101.3
    server {
    #监听的ip和端口，配置192.168.101.3:80
        listen       80;
    #虚拟主机名称这里配置ip地址
        server_name  192.168.101.3;
    #所有的请求都以/开始，所有的请求都可以匹配此location
        location / {
        #使用root指令指定虚拟主机目录即网页存放目录
        #比如访问http://ip/test.html将找到/usr/local/html3/test.html
        #比如访问http://ip/item/test.html将找到/usr/local/html3/item/test.html

            root   /usr/local/nginx/html3;
        #指定欢迎页面，按从左到右顺序查找
            index  index.html index.htm;
        }

    }
    #配置虚拟主机192.168.101.103
    server {
        listen       80;
        server_name  192.168.101.103;

        location / {
            root   /usr/local/nginx/html103;
            index  index.html index.htm;
        }

    }

}
</code></pre>

<h3>1.2 基于端口的虚拟主机 </h3>

<p style="margin-left:0cm;">nginx对外提供80和8080两个端口监听服务。</p>

<p style="margin-left:0cm;">请求80端口则请求html80目录下的html</p>

<p style="margin-left:0cm;">请求8080端口则请求html8080目录下的html</p>

<p style="margin-left:0cm;"><strong>1.2.1 创建html目录</strong></p>

<p style="margin-left:0cm;">将原来nginx的html目录拷贝两个目录 “html80”和“html8080”，为了方便测试需要修改每个目录下的index.html内容使之个性化。</p>

<p style="margin-left:0cm;"><strong>1.2.2 配置虚拟主机</strong></p>

<p style="margin-left:0cm;">修改/usr/local/nginx/conf/nginx.conf文件，添加两个虚拟主机，如下：</p>

<pre class="has">
<code class="language-bash">#user  nobody;
worker_processes  1;
events {
    worker_connections  1024;
}

http {
    include       mime.types;
    default_type  application/octet-stream;

    sendfile        on;

    keepalive_timeout  65;
    #配置虚拟主机
    server {
    #监听的ip和端口，配置80
        listen       80;
    #虚拟主机名称这里配置ip地址
        server_name  192.168.101.3;
    #所有的请求都以/开始，所有的请求都可以匹配此location
        location / {
        #使用root指令指定虚拟主机目录即网页存放目录
        #比如访问http://ip/test.html将找到/usr/local/html3/test.html
        #比如访问http://ip/item/test.html将找到/usr/local/html3/item/test.html

            root   /usr/local/nginx/html80;
        #指定欢迎页面，按从左到右顺序查找
            index  index.html index.htm;
        }

    }
    #配置虚拟主机
    server {
        listen       8080;
        server_name  192.168.101.3;

        location / {
            root   /usr/local/nginx/html8080;
            index  index.html index.htm;
        }

    }

}
</code></pre>

<h3>1.3 基于域名的虚拟主机</h3>

<p style="margin-left:0cm;">两个域名指向同一台nginx服务器，用户访问不同的域名显示不同的网页内容。</p>

<p style="margin-left:0cm;">两个域名是aaa.test.com和bbb.test.com</p>

<p style="margin-left:0cm;">nginx服务器使用虚拟机192.168.101.3</p>

<p style="margin-left:0cm;"><strong>1.3.1 创建html目录</strong></p>

<p style="margin-left:0cm;">在192.168.101.3上创建/usr/local/aaa_html，此目录为aaa.test.com域名访问的目录</p>

<p style="margin-left:0cm;">在192.168.101.3上创建/usr/local/bbb_html，此目录为bbb.test.com域名访问的目录</p>

<p style="margin-left:0cm;">目录中的内容使用nginx自带的html文件，将/usr/local/nginx/html中的内容拷贝分别拷贝到上边两个目录中，并且将aaa_html目录中的index.html内容改为：“Welcome to aaa nginx!”</p>

<p style="margin-left:0cm;">将bbb_html目录中的index.html内容改为“Welcome to bbb nginx!”</p>

<p style="margin-left:0cm;"><strong>1.3.2 配置虚拟主机</strong></p>

<p style="margin-left:0cm;">修改/usr/local/nginx/conf/nginx.conf文件，添加两个虚拟主机，如下： </p>

<pre class="has">
<code>#配置虚拟主机aaa.test.com 
server {
        #监听的ip和端口，配置本机ip和端口
        listen 192.168.101.3:80;        
        #虚拟主机名称是aaa.test.com，请求域名aaa.test.com的url将由此server配置解析
        server_name aaa.test.com;     
        #所有的请求都以/开始，所有的请求都可以匹配此location
        location / {
        #使用root指令指定虚拟主机目录即网页存放目录
        #比如访问http://ip/test.html将找到/usr/local/aaa_html/test.html
        #比如访问http://ip/item/test.html将找到/usr/local/aaa_html/item/test.html
                root /usr/local/aaa_html;    
                #指定欢迎页面，按从左到右顺序查找
                index index.html index.htm;    
        }
    }

#配置虚拟主机bbb.test.com
    server {
        listen 192.168.101.3:80;
        server_name bbb.test.com;
        location / {
                root /usr/local/bbb_html;
                index index.html index.htm;
        }
    }

</code></pre>

<p style="margin-left:0cm;"> </p>

<h2 style="margin-left:0cm;">二 、Nginx反向代理</h2>

<ol><li style="margin-left:0cm;">什么是反向代理？</li>
</ol><p style="margin-left:0cm;">      通常的代理服务器，只用于代理内部网络对Internet的连接请求，客户机必须指定代理服务器,并将本来要直接发送到Web服务器上的http请求发送到代理服务器中由代理服务器向Internet上的web服务器发起请求，最终达到客户机上网的目的。</p>

<p style="margin-left:0cm;">      而反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。</p>

<p style="margin-left:0cm;">两个tomcat服务通过nginx反向代理，本例子使用三台虚拟机进行测试，</p>

<p style="margin-left:0cm;">         nginx服务器：192.168.101.3</p>

<p style="margin-left:0cm;">         tomcat1服务器：192.168.101.5</p>

<p style="margin-left:0cm;">         tomcat2服务器：192.168.101.6</p>

<p style="margin-left:0cm;"><strong>Nginx反向代理配置</strong></p>

<p style="margin-left:0cm;">根据上边的需求在nginx.conf文件中配置反向代理，如下：</p>

<pre class="has">
<code>#配置一个代理即tomcat1服务器
upstream tomcat_server1 {
            server 192.168.101.5:8080;
        }
#配置一个代理即tomcat2服务器
    upstream tomcat_server2 {
            server 192.168.101.6:8080;
        }

#配置一个虚拟主机
    server {
        listen 80;
        server_name aaa.test.com;
        location / {
                #域名aaa.test.com的请求全部转发到tomcat_server1即tomcat1服务上
                proxy_pass http://tomcat_server1;
                #欢迎页面，按照从左到右的顺序查找页面
                index index.jsp index.html index.htm;
        }

    }

    server {
        listen 80;
        server_name bbb.test.com;

        location / {
                 #域名bbb.test.com的请求全部转发到tomcat_server2即tomcat2服务上
                  proxy_pass http://tomcat_server2;
                  index index.jsp index.html index.htm;
        }
    }
</code></pre>

<p style="margin-left:0cm;">如果在同一个域名下有多台服务器提供服务，此时需要nginx负载均衡。</p>

<h2 style="margin-left:0cm;">三、Nginx负载均衡</h2>

<ol><li>什么是负载均衡？</li>
</ol><p style="margin-left:0cm;">       负载均衡 建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。</p>

<p style="margin-left:0cm;">       负载均衡，英文名称为Load Balance，其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。</p>

<p style="margin-left:0cm;">nginx作为负载均衡服务器，用户请求先到达nginx，再由nginx根据负载配置将请求转发至 tomcat服务器。</p>

<p style="margin-left:0cm;">         nginx负载均衡服务器：192.168.101.3</p>

<p style="margin-left:0cm;">         tomcat1服务器：192.168.101.5</p>

<p style="margin-left:0cm;">         tomcat2服务器：192.168.101.6</p>

<p style="margin-left:0cm;"><strong>Nginx负载均衡配置</strong></p>

<p style="margin-left:0cm;">根据上边的需求在nginx.conf文件中配置负载均衡，如下：</p>

<pre class="has">
<code>upstream tomcat_server_pool{
        server 192.168.101.5:8080 weight=10;
        server 192.168.101.6:8080 weight=10;
        }

    server {
        listen 80;
        server_name aaa.test.com;
        location / {
                 proxy_pass http://tomcat_server_pool;
                 index index.jsp index.html index.htm;
        }
    }
</code></pre>

<pre class="has">
<code>节点说明：
在http节点里添加:

#定义负载均衡设备的 Ip及设备状态 
upstream myServer {   

    server 127.0.0.1:9090 down; 
    server 127.0.0.1:8080 weight=2; 
    server 127.0.0.1:6060; 
    server 127.0.0.1:7070 backup; 
}

在需要使用负载的Server节点下添加

proxy_pass http://myServer;

upstream 每个设备的状态:

down 表示单前的server暂时不参与负载 
weight  默认为1.weight越大，负载的权重就越大。 
max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误 
fail_timeout:max_fails 次失败后，暂停的时间。 
backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。
</code></pre>

<p style="margin-left:0cm;">解决高可用的方案就是添加冗余。</p>

<p style="margin-left:0cm;"> </p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Java通过序列化实现深度复制</title>
    <url>/2019/11/05/Java%E9%80%9A%E8%BF%87%E5%BA%8F%E5%88%97%E5%8C%96%E5%AE%9E%E7%8E%B0%E6%B7%B1%E5%BA%A6%E5%A4%8D%E5%88%B6/</url>
    <content><![CDATA[<a id="more"></a>

<pre class="has">
<code class="language-java">package beanCopy;

import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.io.ObjectInputStream;
import java.io.ObjectOutputStream;
import java.io.Serializable;
import java.util.ArrayList;
import java.util.List;

public class SerializeTest {

    public static void main(String[] args) throws IOException, ClassNotFoundException {

        Son son=new Son("qwer", "15");
        List sons=new ArrayList&lt;Son&gt;();
        sons.add(son);
        Person p1=new Person("zs", "30",sons);

        ByteArrayOutputStream bos=new ByteArrayOutputStream();
        ObjectOutputStream oos=new ObjectOutputStream(bos);

        oos.writeObject(p1);

        ByteArrayInputStream bis=new ByteArrayInputStream(bos.toByteArray());
        ObjectInputStream ois=new ObjectInputStream(bis);

        Person p2=(Person) ois.readObject();

        System.out.println(p1);
        System.out.println(p2);


    }

}


class Person implements Serializable{

    private String name;

    private String age;

    private List&lt;Son&gt; sons;


    /*@Override
    public String toString() {
        return "Person [name=" + name + ", age=" + age + ", sons=" + sons + "]";
    }*/



    public Person(String name, String age, List&lt;Son&gt; sons) {
        super();
        this.name = name;
        this.age = age;
        this.sons = sons;
    }



    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public String getAge() {
        return age;
    }

    public void setAge(String age) {
        this.age = age;
    }



}


class Son implements Serializable{
    private String name;

    private String age;



    /*@Override
    public String toString() {
        return "Son [name=" + name + ", age=" + age + "]";
    }*/

    public Son(String name, String age) {
        super();
        this.name = name;
        this.age = age;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public String getAge() {
        return age;
    }

    public void setAge(String age) {
        this.age = age;
    }


}</code></pre>

<p>输出</p>

<p><img alt class="has" height="74" src="https://img-blog.csdnimg.cn/20191105233038132.png" width="378"></p>
]]></content>
      <categories>
        <category>Java学习笔记</category>
      </categories>
  </entry>
  <entry>
    <title>（Linux）远程挂载网络磁盘详解---nfs共享</title>
    <url>/2019/06/11/%EF%BC%88Linux%EF%BC%89%E8%BF%9C%E7%A8%8B%E6%8C%82%E8%BD%BD%E7%BD%91%E7%BB%9C%E7%A3%81%E7%9B%98%E8%AF%A6%E8%A7%A3---nfs%E5%85%B1%E4%BA%AB/</url>
    <content><![CDATA[<a id="more"></a>

<h1><strong>前言</strong></h1>

<hr><p>在Linux或Windows乃至其他的系统，我们经常会需要进行磁盘的挂载。通常从挂载的方式的上分为本地挂载和远程挂载。Linux的本地挂载就不介绍了，这篇文章介绍的是远程挂载网络磁盘。</p>

<hr><h1> </h1>

<h1><strong>远程挂载网络磁盘</strong></h1>

<hr><p>实际上，这个操作与使用nfs共享一个文件的方法是相同的。思路是服务端将一块磁盘空间本地挂载到一个目录，然后通过网络使用nfs将这个目录进行共享，客户端最后将服务端共享的目录挂载到自己本地的一个目录，这样就使客户端拥有了一块网络磁盘。</p>

<p>优点是:服务端的同一块磁盘可以挂载到不同的客户端，实现文件的共享；可以扩充客户端的存储空间。<br>
缺点是：依赖网络，当网络联通失败，客户端挂载的网络磁盘会无法使用。</p>

<p>做网络挂载，服务端与客户端网络要联通，最好是在同一局域网内，还要注意防火墙的设置。<br>
 </p>

<hr><h2><strong>NFS简介</strong></h2>

<ul><li>
    <p>Sun公司于1984年发布。</p>
    </li>
    <li>
    <p>NFS 是一种可分散式的网络文件系统。</p>
    </li>
    <li>
    <p>可以通过网络使不同的机器、不同的操作系统，能够分享资料，使客户端能通过网络访问并分享文件到位于服务端的磁盘中。</p>
    </li>
    <li>NFS在文件传送或信息传送过程中依赖于RPC协议。RPC负责负责信息的传输。</li>
</ul><hr><h2> </h2>

<h2><strong>服务端操作</strong></h2>

<hr><p>【1】安装NFS程序</p>

<p>yum -y install nfs*</p>

<p>rpcbind,在centos6以前自带的yum源中为portmap。<br>
使用yum安装nfs时会下载依赖，因此只要下载nfs即可，无需再下载rpcbind.</p>

<p>【2】查看是否安装了nfs与rpcbind</p>

<p>rpm -qa |grep nfs<br>
rpm -qa |grep rpcbind<br><img alt="è¿éåå¾çæè¿°" class="has" src="https://img-blog.csdn.net/20180915190249681?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0dYXzFfMTFfcmVhbA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>

<p>【3】创建共享的目录并共享</p>

<p>如要共享的目录已存在请跳过创建</p>

<p>&lt;1&gt;mkdir /mnt/nfs01</p>

<p>&lt;2&gt;vim /etc/exports<br>
/mnt/nfs01 10.10.10.0/24 (rw,no_root_squash,no_all_squash,sync)<br>
 </p>

<pre class="has">
<code class="language-bash">
配置


/mnt/nfs01      10.10.10.0/24    (rw,no_root_squash,no_all_squash,sync)

要共享的目录     要分享给的客户端   客户端对此共享目录的权限

----------


客户端指定


192.168.1.125           指定特定的的IP可以共享nfs目录

*                       指定所有网段及ip都可以共享nfs目录

192.168.1.0/24          指定子网中的所有主机都可以共享nfs目录

2018fs.wxyonghe.com     指定域名的主机可以共享nfs目录

----------


权限


rw                      可读可写     

ro                      只读(还与文件系统的rwx有关)

sync　　                 数据同步写入到内存与硬盘中

async                   数据先暂存于内存当中，不会直接写入硬盘

wdelay                  当有写操作，就会检查是否有相关的写操作，并在一起执行(默认设置)

no_wdelay               当有写操作就立即执行，通常要与sync配合使用

root_squash             当客户端登陆NFS的身份为root用户时，将客户端的root用户及所属组都映射为匿名用户或用户组（默认设置） 

no_root_squash　　       使客户端可以使用root身份及权限来操作共享的目录

all_squash              无论客户端登陆NFS的身份为何，都将映射为匿名用户

no_all_squash           无论客户端登陆NFS的身份为何，都将映射为root用户（默认设置）

anonuid                 将远程访问的所有用户都映射为匿名用户，并指定该用户为本地用户

anongid                 将远程访问的所有用户组都映射为匿名用户组账户，并指定该匿名用户组账户为本地用户组账户

secure                  使客户端只能从小于1024的tcp/ip端口连接服务端(默认设置)

insecure                允许客户端从大于1024的tcp/ip端口连接服务端

subtree                 当共享的目录是一个子目录，服务端会检查其父目录的权限(默认设置)

no_subtree              当共享的目录是一个子目录，服务端不检查其父目录的权限
</code></pre>

<p>【4】启动nfs,rpcbind,并设为开机自启</p>

<p>(centos7)<br>
systemctl start nfs<br>
systemctl start rpcbind<br>
systemctl enable nfs<br>
systemclt enable rpcbind</p>

<p>(centos6)<br>
service nfs start<br>
service rpcbind start</p>

<p>【5】查看是否共享成功</p>

<p>showmount -e localhost<br><img alt="è¿éåå¾çæè¿°" class="has" src="https://img-blog.csdn.net/2018091520415162?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0dYXzFfMTFfcmVhbA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>

<p>可看到共享的目录及客户端，即为成功</p>

<hr><p> </p>

<h2><strong>客户端操作</strong></h2>

<hr><p>【1】安装NFS程序</p>

<p>yum -y install nfs*</p>

<p>【2】启动nfs</p>

<p>(centos7)<br>
systemctl start nfs<br>
systemctl start rpcbind<br>
systemctl enable nfs<br>
systemctl enable rpcbind</p>

<p>(centos6)<br>
service nfs start<br>
service rpcbind start<br>
chkconfig nfs on<br>
chkconfig rpcbind on</p>

<p>【3】创建挂载目录</p>

<p>mkdir /data/nfsone</p>

<p>【4】查看是否共享成功</p>

<p>showmount -e nfs服务端IP</p>

<p>showmount -e 10.10.20.212<br><img alt="è¿éåå¾çæè¿°" class="has" src="https://img-blog.csdn.net/20180915205422918?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0dYXzFfMTFfcmVhbA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>

<p>【5】网络挂载</p>

<p>mount -t nfs -o nolock 服务端IP:共享目录绝对路径 本地挂载目录<br>
mount -t nfs -o nolock 10.10.20.212:/mnt/nfs01 /data/nfsone</p>

<p>centos7的nfs默认使用的是nfs4,所以mount -t 无需指定nfs4也可以</p>

<p>【6】查看是否成功</p>

<p>df -Th<br><img alt="è¿éåå¾çæè¿°" class="has" src="https://img-blog.csdn.net/20180915211531532?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0dYXzFfMTFfcmVhbA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>

<p>【7】卸载网络磁盘</p>

<p>与卸载本地挂载相同</p>

<p>umount /data/nfsone<br>
或<br>
umount 10.10.20.212:/mnt/nfs01</p>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Java导出CSV格式文件</title>
    <url>/2019/03/19/Java%E5%AF%BC%E5%87%BACSV%E6%A0%BC%E5%BC%8F%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<a id="more"></a>

<p>导出csv格式文件的本质是导出以逗号为分隔的文本数据</p>

<pre class="has">
<code>import java.io.BufferedWriter;  
import java.io.File;  
import java.io.FileInputStream;  
import java.io.FileNotFoundException;  
import java.io.FileOutputStream;  
import java.io.IOException;  
import java.io.InputStream;  
import java.io.OutputStream;  
import java.io.OutputStreamWriter;  
import java.net.URLEncoder;  
import java.util.ArrayList;  
import java.util.Iterator;  
import java.util.LinkedHashMap;  
import java.util.List;  
import java.util.Map;  

import javax.servlet.http.HttpServletResponse;  

import com.alibaba.druid.util.StringUtils;



/** 
 * 文件操作 
 */  
public class CSVUtils {  


    /**
    * 功能说明：获取UTF-8编码文本文件开头的BOM签名。
    * BOM(Byte Order Mark)，是UTF编码方案里用于标识编码的标准标记。例：接收者收到以EF BB BF开头的字节流，就知道是UTF-8编码。
    * @return UTF-8编码文本文件开头的BOM签名
    */
    public static String getBOM() {

         byte b[] = {(byte)0xEF, (byte)0xBB, (byte)0xBF};
         return new String(b);
    }


  /** 
   * 生成CVS文件
   * @param exportData 
   *       源数据List 
   * @param map 
   *       csv文件的列表头map 
   * @param outPutPath 
   *       文件路径 
   * @param fileName 
   *       文件名称 
   * @return 
      */  
    @SuppressWarnings("rawtypes")  
    public static File createCSVFile(List exportData, LinkedHashMap map, String outPutPath,  
                   String fileName) {  

    File csvFile = null;  
    BufferedWriter csvFileOutputStream = null;  
    try {  
      File file = new File(outPutPath);  
      if (!file.exists()) {  
        file.mkdirs();  
      }  
      //定义文件名格式并创建  
      csvFile =new File(outPutPath+fileName+".csv");
      file.createNewFile();  
      // UTF-8使正确读取分隔符","  
      //如果生产文件乱码，windows下用gbk，linux用UTF-8
      csvFileOutputStream = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(  
        csvFile), "UTF-8"), 1024);  

      //写入前段字节流，防止乱码
      csvFileOutputStream.write(getBOM());
      // 写入文件头部
      for (Iterator propertyIterator = map.entrySet().iterator(); propertyIterator.hasNext();) {  
        java.util.Map.Entry propertyEntry = (java.util.Map.Entry) propertyIterator.next();  
        csvFileOutputStream.write((String) propertyEntry.getValue() != null ? (String) propertyEntry.getValue() : "" );  
        if (propertyIterator.hasNext()) {  
          csvFileOutputStream.write(",");  
        }  
      }  
      csvFileOutputStream.newLine();  
      // 写入文件内容  
      for (Iterator iterator = exportData.iterator(); iterator.hasNext();) {  
          Object row = (Object) iterator.next();
        for (Iterator propertyIterator = map.entrySet().iterator(); propertyIterator  
          .hasNext();) {  
          java.util.Map.Entry propertyEntry = (java.util.Map.Entry) propertyIterator  
            .next();  
          String str=row!=null?((String)((Map)row).get( propertyEntry.getKey())):"";

          if(StringUtils.isEmpty(str)){
              str="";
          }else{
              str=str.replaceAll("\"","\"\"");
              if(str.indexOf(",")&gt;=0){
                  str="\""+str+"\"";
              }
          }
          csvFileOutputStream.write(str);  
          if (propertyIterator.hasNext()) {  
            csvFileOutputStream.write(",");  
          }  
        }  
        if (iterator.hasNext()) {  
          csvFileOutputStream.newLine();  
        }  
      }  
      csvFileOutputStream.flush();  
    } catch (Exception e) {  
      e.printStackTrace();  
    } finally {  
      try {  
        csvFileOutputStream.close();  
      } catch (IOException e) {  
        e.printStackTrace();  
      }  
    }  
    return csvFile;  
  }  

  /**
   *     生成并下载csv文件
   * @param response
   * @param exportData
   * @param map
   * @param outPutPath
   * @param fileName
   * @throws IOException
      */
    @SuppressWarnings("rawtypes")
    public static void exportDataFile(HttpServletResponse response,List exportData, LinkedHashMap map, String outPutPath,String fileName) throws IOException{
      File csvFile = null;  
        BufferedWriter csvFileOutputStream = null;  
        try {  
          File file = new File(outPutPath);  
          if (!file.exists()) {  
            file.mkdirs();  
          }  
          //定义文件名格式并创建  
          csvFile =new File(outPutPath+fileName+".csv");
          if(csvFile.exists()){
             csvFile.delete(); 
          }
          csvFile.createNewFile();  
          // UTF-8使正确读取分隔符","  
          //如果生产文件乱码，windows下用gbk，linux用UTF-8
          csvFileOutputStream = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(csvFile), "UTF-8"), 1024);  
          //写入前段字节流，防止乱码
          csvFileOutputStream.write(getBOM());
          // 写入文件头部  
          for (Iterator propertyIterator = map.entrySet().iterator(); propertyIterator.hasNext();) {  
            java.util.Map.Entry propertyEntry = (java.util.Map.Entry) propertyIterator.next();  
            csvFileOutputStream.write((String) propertyEntry.getValue() != null ? (String) propertyEntry.getValue() : "" );  
            if (propertyIterator.hasNext()) {  
              csvFileOutputStream.write(",");  
            }  
          }  
          csvFileOutputStream.newLine();  
          // 写入文件内容  
          for (Iterator iterator = exportData.iterator(); iterator.hasNext();) {  
            Object row = (Object) iterator.next();  
            for (Iterator propertyIterator = map.entrySet().iterator(); propertyIterator  
              .hasNext();) {  
              java.util.Map.Entry propertyEntry = (java.util.Map.Entry) propertyIterator  
                .next();  
              String str=row!=null?((String)((Map)row).get( propertyEntry.getKey())):"";
              if(StringUtils.isEmpty(str)){
                  str="";
              }else{
                  str=str.replaceAll("\"","\"\"");
                  if(str.indexOf(",")&gt;=0){
                      str="\""+str+"\"";
                  }
              }
              csvFileOutputStream.write(str);  
              if (propertyIterator.hasNext()) {  
                csvFileOutputStream.write(",");  
              }  
            }  
            if (iterator.hasNext()) {  
              csvFileOutputStream.newLine();  
            }  
          }  
          csvFileOutputStream.flush();  
        } catch (Exception e) {  
          e.printStackTrace();  
        } finally {  
          try {  
            csvFileOutputStream.close();  
          } catch (IOException e) {  
            e.printStackTrace();  
          }  
        }  




        InputStream in = null;  
        try {  
          in = new FileInputStream(outPutPath+fileName+".csv");  
          int len = 0;  
          byte[] buffer = new byte[1024];  

          OutputStream out = response.getOutputStream(); 
          response.reset(); 

          response.setContentType("application/csv;charset=UTF-8");  
          response.setHeader("Content-Disposition","attachment; filename=" + URLEncoder.encode(fileName+".csv", "UTF-8"));  
          response.setCharacterEncoding("UTF-8"); 
          while ((len = in.read(buffer)) &gt; 0) {  
            out.write(new byte[] { (byte) 0xEF, (byte) 0xBB, (byte) 0xBF });  
            out.write(buffer, 0, len);  
          }
          out.close();
        } catch (FileNotFoundException e) {  
        } finally {  
          if (in != null) {  
            try {  
              in.close();  
            } catch (Exception e) {  
              throw new RuntimeException(e);  
            }  
          }  
        }


  }

  /** 
   * 删除该目录filePath下的所有文件 
   * @param filePath 
   *      文件目录路径 
      */  
    public static void deleteFiles(String filePath) {  

    File file = new File(filePath);  
    if (file.exists()) {  
      File[] files = file.listFiles();  
      for (int i = 0; i &lt; files.length; i++) {  
        if (files[i].isFile()) {  
          files[i].delete();  
        }  
      }  
    }  
  }  

  /** 
   * 删除单个文件 
   * @param filePath 
   *     文件目录路径 
   * @param fileName 
   *     文件名称 
      */  
    public static void deleteFile(String filePath, String fileName) {  

    File file = new File(filePath);  
    if (file.exists()) {  
      File[] files = file.listFiles();  
      for (int i = 0; i &lt; files.length; i++) {  
        if (files[i].isFile()) {  
          if (files[i].getName().equals(fileName)) {  
            files[i].delete();  
            return;  
          }  
        }  
      }  
    }  
  }  

  /** 
   * 测试数据 
   * @param args 
      */  
    @SuppressWarnings({ "rawtypes", "unchecked" })  
    public static void main(String[] args) {  

    List exportData = new ArrayList&lt;Map&gt;();  
    Map row1 = new LinkedHashMap&lt;String, String&gt;();  
    row1.put("1", "11");  
    row1.put("2", "12");  
    row1.put("3", "13");  
    row1.put("4", "14");  
    exportData.add(row1);  
    row1 = new LinkedHashMap&lt;String, String&gt;();  
    row1.put("1", "21");  
    row1.put("2", "22");  
    row1.put("3", "23");  
    row1.put("4", "24");  
    exportData.add(row1);  
    LinkedHashMap map = new LinkedHashMap();  

    //设置列名
    map.put("1", "第一列名称");  
    map.put("2", "第二列名称");  
    map.put("3", "第三列名称");  
    map.put("4", "第四列名称");  
    //这个文件上传到路径，可以配置在数据库从数据库读取，这样方便一些！
    String path = "E:/";  

   //文件名=生产的文件名称+时间戳
    String fileName = "文件导出";  
    File file = CSVUtils.createCSVFile(exportData, map, path, fileName);  
    String fileName2 = file.getName();  
    System.out.println("文件名称：" + fileName2);  
  }  
}</code></pre>

<p><img alt class="has" src="https://images2018.cnblogs.com/blog/1443172/201808/1443172-20180813231232388-1283590677.png"></p>

<p>转自<a href="https://www.cnblogs.com/hanfengyeqiao/p/9471694.html" target="_blank" rel="external nofollow noopener noreferrer">https://www.cnblogs.com/hanfengyeqiao/p/9471694.html</a></p>

<p> </p>

<p>需要注意的是生成的csv其中的数字若过长，csv中查看没有问题，但是用excel打开数字就会变成科学计数法 </p>

<p>解决方法是在生成csv的时候,在数字的前面或后面加上"\t"制表符，再用excel打开问题解决！如 “1234567890\ t”,“\ t1213212312”</p>
]]></content>
      <categories>
        <category>Java学习笔记</category>
      </categories>
  </entry>
  <entry>
    <title>Redis笔记</title>
    <url>/2018/11/22/Redis%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<a id="more"></a>

<h2>在分布式数据库中CAP原理CAP+BASE:</h2>

<p>传统的ACID分别是什么：A（Atomicity）原子性  C(Consistency)一致性  I（Isolation）隔离性  D（Durability）持久性<br>
CAP:  C（Consistency）强一致性   A（Availability）可用性    P（Partition tolerance）分区容错性<br>
CAP理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个要求；<br>
CA-单点集群，满足一致性，可用性的系统，通常在可扩展性上不太强大（RDBMS）<br>
CP-满足一致性，分区容错性的系统，通常性能不是特别高(MongoDB，HBase,redis)<br>
AP-满足可用性，分区容错性的系统，通常可能对一致性要求低一些,大多数网站架构的选择(CouchDB CASSANDRA)<br>
BASE:基本可用（basically available）<br>
软状态 （soft state）<br>
最终一致性（eventually consistent）<br>
它的思想是通过让系统轻松对某一时刻数据一致性的要求来换取系统整体伸缩性和性能上改观。为什么这么说呢，缘由就在于大型系统旺旺由于地域分布和级高性能的要求，不可能采用分布式失误来完成这些指标，要想获得这些指标，我们必须采用另外一种方式来完成，这里BASE就是来解决这个问题的办法<br>
 </p>

<p><strong>分布式和集群介绍</strong>：</p>

<p>分布式：不同的多态服务器上面部署不同的服务器块，他们之间通过Rpc/Rmi之间通信和调用，对外提供服务和组内协作<br>
集群：不同的多台服务器上面部署相同的服务模块，通过分布式调度软件进行统一的调度，对外提供服务和访问</p>

<p> </p>

<h3>Redis介绍</h3>

<p>Redis：Remote Dictionary Server（远程字典服务器），是完全开源免费的，用C语言编写的，遵守BSD协议。是一个高性能的（key/value）分布式内存数据库，基于内存运行并支持持久化的NoSQL数据库，也被人们称为数据结构服务器。</p>

<p>Redis及其他key/value缓存产品有以下三个特点：</p>

<p>       1.Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用；</p>

<p>       2.Redis不仅仅支持简单的key-value类型的数据，同时还支持list、set、zset、hash等数据结构的存储。</p>

<p>       3.Redis支持数据的备份，及master-slave模式的数据备份。</p>

<p>功能：</p>

<p>      内存存储和持久化：redis支持异步将内存中的数据写到硬盘上，同时不影响继续服务</p>

<p>      取最新N个数据的操作：如：将最新10条评论的ID放入Redis的list集合中</p>

<p>      模拟类似于HttpSession这种需要设定过期时间的功能</p>

<p>      发布、订阅消息系统</p>

<p>       定时器、计数器</p>

<p><strong>基础命令</strong></p>

<p>Key：</p>

<p>       keys * ：列出当前库所有key</p>

<p>       exists key的名字：判断某个key是否存在</p>

<p>       move key db ：当前库没有，被移除</p>

<p>       exire key 秒钟 ：为给定key设置过期时间</p>

<p>       ttl key：查看还有多少秒过期，-1永不过期，-2表示已过期即移除内存</p>

<p>       type key：查看key的类型</p>

<p> </p>

<p>String：</p>

<p>          set/get：set  k1  qwer, get  k1     set k2  123</p>

<p>          del:del  k1</p>

<p>          append: append k1 123      (qwer123)</p>

<p>          incr、decr、incrby、decrby  ： incrby  k2  2  一定要是数字才能加减</p>

<p>          getrange、setrange ： getrange k1 0 -1 (qwer)   getrange 0 2 (qwe)    setrange k1 0 xx （xxer）</p>

<p>          setex：设置过期时间  setex k3 10 v3</p>

<p>          setnx：不存在就set成功  存在就返回0  不会覆盖之前的  setnx  k1  zxcvv  返回0</p>

<p>          mset、mget、msetnx：mset k1 v1 k2 v2 k3 v3    mget k1 k2 k3     msetnx有一个存在就会set失败</p>

<p>List：</p>

<p>        rpush  mylist  1 2 3 4 5      rpush  list   123</p>

<p>        lpush、rpush、lrange   ：l先进后出 r先进先出</p>

<p>        lpop、rpop：出栈  同上   </p>

<p>        lindex：按下标获取元素   lindex  mylist  1   （2）</p>

<p>        llen：长度</p>

<p>        lrem key  n  val ：删除n个val</p>

<p>        ltrim  key  start  end  截取指定范围的值赋给key</p>

<p>        rpoplpush   源列表  目的列表   rpoplpush  mylist  list   （5123）</p>

<p>        lset  key  index   value    覆盖列表中下标位置的值</p>

<p>        linsert  key  before/after  val1  val2  在val1前/后插入val2</p>

<p>Set：</p>

<p>      sadd、smembers、sismember    sadd set1 1 1 2 2 3 3 （1 2 3） 、  smembers  set1（1 2 3） </p>

<p>      scard：获取集合元素个数</p>

<p>      srem  key  val  ：删除集合中某个元素</p>

<p>      srandmember  key  n  随机列出n个元素</p>

<p>      spop  key：随机出栈</p>

<p>      smove  k1  k2   在k1中的某个值 ：将k1中某个值移除赋给k2</p>

<p>      sdiff  k1   k2  ：在k1中不在k2中的元素</p>

<p>      sinter  k1  k2  ：k1  k2  的交集</p>

<p>      sunion k1  k2 ：并集</p>

<p><strong>Hash</strong>：kv模式不变  v为键值对</p>

<p>            hset  user name  zs  、  hget  user  name</p>

<p>            hmset   customer  id 1  name  zz  age  20  、hmget  customer  id  name  age</p>

<p>            hgetall   customer   (id 1 name zz age 20)</p>

<p>            hdel  user  name</p>

<p>            hlen  长度</p>

<p>            hexists  key  在key中某个值的key  ：  hexists  customer  id</p>

<p>            hkeys、hvals ：hkeys  customer  （id name age）</p>

<p>            hincrby、hincrbyfloat</p>

<p>            hsetnx</p>

<p>Zset（sorted set）：</p>

<p>            zadd  zset01  60 v1  70  v2  80  v3  、zrange  zset01   0  -1 (withscores) （v1  v2  v3）</p>

<p>            zrangebyscore  key  score1   score2  （limit  index1  index2 ）：  “（score”表示不包含 </p>

<p>            zrem  key   val   删除</p>

<p>            zcard  key  统计</p>

<p>            zcount  key  val1  val2   统计分数段中的个数</p>

<p>            zrank   key  val   返回val的下标</p>

<p>            zscore  key  val  返回val对应的score</p>

<p>            zrevrank  key  val   逆序获得下标</p>

<p>            zrevrange  key  0  -1   逆序获得 （v3  v2  v1）</p>

<p>            zrevrangebyscore  key  score1   score2   结束分数到开始分数</p>

<p>           </p>

<p><strong>Maxmemory-policy</strong></p>

<p>     1.volatile-lru：使用LRU算法移除key，只对设置了过期时间的key</p>

<p>     2.allkeys-lru：使用LRU算法移除key</p>

<p>     3.volatile-random：在过期集合中移除随机的key，只对设置了过期时间的key</p>

<p>     4.allkeys-random：移除随机的key</p>

<p>     5.volatile-ttl：移除那些TTL值最小的key，即那些最近要过期的key</p>

<p>     6.noeviction：不进行移除，针对写操作，只是返回错误信息</p>

<p>       </p>

<h3><strong>Redis的持久化机制</strong></h3>

<p><strong>RDB</strong></p>

<p>          RDB持久化是把当前进程数据生成快照保存到硬盘的过程，触发RDB持久化过程分为手动触发和自动触发。</p>

<p>手动触发分别对应save和bgsave命令。</p>

<p>save：阻塞当前redis服务器，直到RDB过程完成为止。对于内存较大的实例会产生长时间的阻塞，线上环境不建议使用。</p>

<p>bgsave：redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束，阻塞只发生在fork阶段，时间很短。所以一般使用bgsave。</p>

<p>自动触发机制场景：</p>

<p>     1 ) 使用save相关配置，如‘save m n’表示m秒之内数据集存在n次修改时，自动触发bgsave。<br>
     2）如果从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点。<br>
     3）执行debug reload命令重新加载Redis时，也会自动触发save操作。<br>
     4）默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则自动执行bgsave。</p>

<p>RDB优点：RDB是一个紧凑压缩的二进制文件，代表Redis在某一个时间点上的数据快照。非常适合用于备份，全量复制等场景。<br>
                  Redis加载RDB恢复数据远远快于AOF方式。</p>

<p>      缺点：RDB方式数据没办法做到实时持久化/秒级持久化。因为bgsave每次运行都要执行fork操作创建子进程，属于重量级操  作，频繁执行成本过高。<br>
RDB文件使用特定二进制格式保存，Redis版本演进过程中有多个格式的RDB版本，存在老版本Redis服务无法兼容新版RDB格式的问题。</p>

<p><strong>AOF</strong></p>

<p>      AOF(append only file)持久化：以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中命令达到恢复数据的目的。AOF的主要作用是解决了数据持久化的实时性，目前已经是Redis持久化的主流方式。</p>

<p>     开启AOF功能需要设置配置：appendonly yes,默认不开启。AOF文件通过appendfilename 配置设置，默认文件名是appendonly.aof。保存路径同RDB持久化方式一致。通过dir配置指定。AOF的工作流程操作：命令写入（append）、文件同步（sync）、文件重写（rewrite）、重启加载（load）。</p>

<p>    流程如下：<br>
         1） 所有的写入命令会追加到aof_buf（缓冲区）中。<br>
         2） AOF缓冲区根据对应的策略向硬盘做同步操作。<br>
         3） 随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的。<br>
         4） 当Redis服务重启时，可以加载AOF文件进行数据恢复。</p>

<p>   AOF为什么把命令追加到aof_buf中？</p>

<p>       Redis使用单线程响应命令，如果每次写AOF文件命令都直接追加到硬盘，那么性能完全取决于当前硬盘负载。先写入缓冲区aof_buf中，还有另一个好处，Redis可以提供多种缓冲区同步硬盘的策略，在性能和安全性方面做出平衡。</p>

<p> </p>

<p>Redis提供了多种AOF缓冲区同步文件策略，由参数appendfsync控制</p>

<p>     write操作在写入系统缓冲区后直接返回。同步硬盘操作依赖于系统调度机制，列如：缓冲区页空间写满或达到特定时间周期。同步文件之前，如果此时系统故障宕机，缓冲区内数据将丢失。<br>
      fsync针对单个文件操作（比如AOF文件），做强制硬盘同步，fsync将阻塞知道写入硬盘完成后返回，保证了数据持久化。</p>

<p>       默认配置为everysec，做到兼顾性能和数据安全性，理论上只有在系统突然宕机的情况下丢失1s的数据。</p>

<p> </p>

<p>随着命令不断写入AOF，文件会越来越大，为了解决这个问题，Redis引入了AOF重写机制压缩文件体积。AOF文件重写是把Redis进程内的数据转化为写命令同步到新AOF文件的过程。<br>
重写后的AOF文件为什么可以变小？有如下原因：<br>
1） 进程内已经超时的数据不再写文件。<br>
2）旧的AOF文件含有无效命令，如del key1、 hdel key2、srem keys、set a 111、set a 222等。重写使用进程内数据直接生成，这样新的AOF文件只保留最终数据的写入命令。<br>
3) 多条写命令可以合并为一个，如lpush list a、lpush list b、 lpush list c 可以转化为：lpush list a b c。为了防止但挑明了过大造成客户端缓冲区溢出，对于list、set、hash、zset等类型曹组，以64个元素为界拆分为多条。 <br>
AOF重写降低了文件占用空间，除此之外，另一个目的是：更小的AOF文件可以更快地被Redis加载。<br>
AOF重写过程可以手动触发和自动触发：</p>

<p>手动触发：直接调用bgrewriteaof命令</p>

<p>自动触发：更具auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定自动触发时机</p>

<p>AOF和RDB文件都可以用于服务器重启时的数据恢复。<br>
1） AOF持久化开启且存在AOF文件时，优先加载AOF文件<br>
2） AOF关闭或者AOF文件不存在时，加载RDB文件<br>
3） 加载AOF/RDB文件完成后，Redis启动成功。<br>
4） AOF/RDB文件存在错误时，Redis启动失败并打印错误信息</p>

<p><strong>Redis的事务</strong></p>

<p><strong>    </strong>  可以一次执行多个命令，本质是一组命令的集合，一个事务中的所有命令都会被序列化，按顺序的串行化执行而不会被其他命令插入，不许加塞。</p>

<p>multi：开启事务</p>

<p>exec：执行</p>

<p>discard：放弃事务</p>

<p>watch：监视一个或多个key，如果在事务执行之前这个key被其他命令所改动，那么事务将被打断。</p>

<p>unwatch：取消watch命令对所有key的监控</p>

<p>redis的事务是部分支持，比如出现set  key这样严重错误的语句时，会直接报error，但还是可以继续往队列里添加命令，只是执行的时候所有命令都不会成功执行；但是出现incr key（其中key所对应的value不为数字时），不会报错，执行时只有这条命令不能成功执行。</p>

<p>watch监控：</p>

<p>悲观锁：每次拿数据都认为别人会修改，所以每次拿数据都会上锁。</p>

<p>乐观锁：每次拿数据的时候认为别人不会修改，所以不会上锁，就是在更新的时候会判断在此期间别人有没有修改数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量。</p>

<p>乐观锁策略：提交版本必须大于当前记录版本才能更新。</p>

<p>一旦执行exec之前的监控锁都会被取消。</p>

<p>watch命令类似于乐观锁，事务提交时，如果key的值被别的客户端改变，整个事务队列都不会被执行，通过watch命令在事务执行之前监控了多个keys，倘若在watch之后有任何key的值发生了变化，exec执行的事务都将被放弃。</p>

<p><strong>Redis的发布订阅</strong></p>

<p>subscribe：订阅</p>

<p>publish：发布</p>

<p>mset  k1 v1 k2 v2 k3 v3</p>

<p>subscribe k1 k2 k3</p>

<p>publish k1 qwer</p>

<h3><strong>Redis主从复制</strong></h3>

<p>1.配从（库）不配主（库）</p>

<p>2.从库配置：slaveof  主库ip  主库端口     每次与master断开连接后，都需要重新连接，除非配置进redis.conf文件</p>

<p>3.修改配置文件细节操作</p>

<p>      拷贝多个redis.conf文件、开启daemonize   yes、pid文件名、指定端口、log文件名字、dump.rdb文件名</p>

<p>4.常用</p>

<p>一主二仆</p>

<p>一个master，两个slave，slave只要一连接就会把master所有数据（包括未连接时的数据）都记录下来。</p>

<p>读写分离：只有master可以读写操作，slave只能读不能写。</p>

<p>master挂掉后，slave保留了之前的数据，角色仍是slave，master重新连接后可继续正常工作。</p>

<p>slave挂掉后，重新连接后角色为master，也就没有了之前的数据，需要重新连接，除非配置进redis.conf。</p>

<p> </p>

<p>薪火相传</p>

<p>上一个slave可以是下一个slave的master，slave同样可以接收其他slaves的连接和同步请求，那么该slave作为了链条中下一个的master，可以有效减轻master的压力。中途变更转向：会清楚之前的数据，重新建立拷贝最新的。</p>

<p> </p>

<p>反客为主</p>

<p>slaveof no one 使当前数据库停止与其他数据库的同步，角色转为master，会保留之前的数据。</p>

<p> </p>

<p>复制原理</p>

<p>slave启动成功连接到master会发送一个sync命令<br>
Master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集的命令，在后台进程执行完成之后，master将传动整个数据文件到slave，以完成一次完全同步操作。<br>
全量复制：slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。<br>
增量复制：master继续将新的所有收集到的修改命令依次传给slave，完成同步<br>
但是只要是重新连接master，依次完全同步（全量复制）将被自动执行。</p>

<p> </p>

<p><strong>哨兵模式</strong>（反客为主自动版）<br>
反客为主不够智能，需手动将slave转为master并手动将其他slave连接过来，哨兵模式解决了这些问题。</p>

<p>在redis安装目录下新建sentinel.conf文件，添加内容：sentinel  monitor  redis-6379（自己起的数据库名）  127.0.0.1  6379  1。</p>

<p>1表示得票大于一的当master。</p>

<p>运行redis-sentinel   ./redis/sentinel.conf命令    </p>

<p>哨兵会监控6379端口的master，如果这个master挂了，会自动在剩下的slave选出一个转为master并将其他slave连接到新的master，如果挂掉的master重新连接回来，哨兵会将其转为slave连接到新的master。</p>

<p>一组sentinel可以同时监控多个master</p>

<p> </p>

<p>复制的缺点</p>

<p>由于所有的写操作都是现在master上操作，然后同步更新到slave上，所以从master同步到slave上有一定的延迟，当系统繁忙的时候，延迟问题会更加严重，slave机器数量的增加也会使这个问题更加严重。</p>

<p> </p>

<p>Java连接redis</p>

<p>１.修改redis.conf配置文件，将绑定的ip地址端口号给注释</p>

<p>２.由于Linux上的redis处于安全保护模式，这就让你无法从虚拟机外部去轻松建立连接，这里就有两种解决方法，一种是在redis.conf中设置保护模式为no</p>

<p>3.另外一种方式是加上安全认证，即redis默认是没有密码的可以直接登录，修改requirepass添加密码。用jedis的auth方法输入密码。</p>

<p>  Connect  time  out ：systemctl stop firewalld.service    </p>

<p> </p>

<p>   单台机器伪分布式集群：<a href="https://blog.csdn.net/baidu_38558076/article/details/90707045" target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/baidu_38558076/article/details/90707045</a></p>

<p>    多机部署redis5.0集群：<a href="https://www.cnblogs.com/Dev0ps/p/10206604.html" target="_blank" rel="external nofollow noopener noreferrer">https://www.cnblogs.com/Dev0ps/p/10206604.html</a></p>

<p> </p>

<p> </p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
</search>
